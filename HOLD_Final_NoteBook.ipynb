{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtwRK3wRgIfv"
      },
      "source": [
        "# Initial Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2U_nlqxQqbH",
        "outputId": "d8f08336-46b2-4366-8396-83d9fc03efae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:13.658100Z",
          "iopub.status.busy": "2023-12-11T01:03:13.657374Z",
          "iopub.status.idle": "2023-12-11T01:03:13.670554Z",
          "shell.execute_reply": "2023-12-11T01:03:13.669428Z",
          "shell.execute_reply.started": "2023-12-11T01:03:13.658068Z"
        },
        "id": "-Qm5ocD-sPOp",
        "outputId": "c003179d-0814-4ab8-8727-43f7e794e136",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7.33 s, sys: 1.16 s, total: 8.5 s\n",
            "Wall time: 15.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "np.random.seed(42)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "import nltk, string, re, spacy,unicodedata, random\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:13.720667Z",
          "iopub.status.busy": "2023-12-11T01:03:13.720065Z",
          "iopub.status.idle": "2023-12-11T01:03:13.725543Z",
          "shell.execute_reply": "2023-12-11T01:03:13.724635Z",
          "shell.execute_reply.started": "2023-12-11T01:03:13.720637Z"
        },
        "id": "kP8UVjUcQkww",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn3ZdEkqwFuf"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8ZiYlrE_RbRv"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Colab Notebooks/HOLD/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:13.849150Z",
          "iopub.status.busy": "2023-12-11T01:03:13.848830Z",
          "iopub.status.idle": "2023-12-11T01:03:14.455858Z",
          "shell.execute_reply": "2023-12-11T01:03:14.454983Z",
          "shell.execute_reply.started": "2023-12-11T01:03:13.849123Z"
        },
        "id": "x2mJ2HY_srqA",
        "outputId": "1fcb7604-96ea-4023-a4b3-41ac44d24003",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of training samples: 4000\n",
            "Total number of test samples: 499\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_excel(folder_path + \"training_data_telugu-hate.xlsx\")\n",
        "test_df= pd.read_excel(folder_path + \"telugu-hate-speech-test.xlsx\")\n",
        "test_with_label = pd.read_excel(folder_path + \"telugu-english-test-data-with-labels.xlsx\")\n",
        "print(\"Total number of training samples:\", len(train_df))\n",
        "print(\"Total number of test samples:\", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.457821Z",
          "iopub.status.busy": "2023-12-11T01:03:14.457536Z",
          "iopub.status.idle": "2023-12-11T01:03:14.469373Z",
          "shell.execute_reply": "2023-12-11T01:03:14.468416Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.457797Z"
        },
        "id": "vq4axTvl_KdJ",
        "outputId": "ab2658cd-5d8e-4e76-d569-6fa91d129dbf",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>à°à°¨à±à°¨à°¿ à°¸à°¾à°°à±à°²à± à°…à°¯à°¿à°¨ à°µà°¿à°¨à°¾à°²à°¨à°¿ à°‰à°‚à°¦à°¿ à°šà°¿à°Ÿà±à°Ÿà°¿ à°¤à°²à±à°²à°¿ à°¸à±‚...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°¬à°¾à°— work out à°…à°µà±à°¤à±à°‚à°¦à°¿ à°¸à±‚à°ªà°°à±.</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>à°‡à°¦à°¿ à°¬à±†à°‚à°¡à°ªà±‚à°¡à°¿ à°—à°µà±à°¨à°®à±†à°‚à°Ÿà± à°¸à±à°Ÿà±‚à°¡à±†à°‚à°Ÿà±à°¸à± à°•à°¿ à°®à°¾à°¤à±à°°à°®à±‡ ...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à°¿à°¨à°ªà±à°ªà±à°¡à± à°šà°¾à°²à°¾ à°…à°‚à°¦à°‚à°—à°¾ à°µà°¿à°¨à°¸à±Šà°‚à°ªà±à°—...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>à°¸à±‚à°ªà°°à± à°¸à°¿à°¸à±à°Ÿà°°à± à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°°à±ˆà°²à±à°µà±‡ à°²à±‹ à°œà°¾à°¬à± à°°à°¾à°µà°¾à°²à°¨...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>496</td>\n",
              "      <td>à°¡à°¬à±à°¬à± à°‡à°¸à±à°¤à±‡ à°¨à°¿à°¨à±à°¨à±à°•à±‚à°¡ à°à°¸à±à°¤à°¾à°¡à±</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>497</td>\n",
              "      <td>à°¨à°¿à°¦à°¿ à°šà±‚à°ªà°¿à°‚à°šà± à°¦à±†à°¬à±à°¬à°•à°¿ à°¸à±†à°Ÿà± à°à°ªà±‹à°¯à°¿à°¦à°¿ à°°à±‹à°œà°¾à°•à±</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>498</td>\n",
              "      <td>à°à°¦à°¿ à°¨à°¾à°•à°¿à°¨ à°¨à±€à°¦à°¿ à°®à°¾à°¤à±à°°à°‚ à°•à°šà±à°šà°¿à°¤à°‚à°—à°¾ à°¨à°¾à°•à°¡à± à°šà±€ à°°à±†à°¡à±à°¡à°¿</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>499</td>\n",
              "      <td>à°‡à°ªà±à°ªà±à°¡à± à°¨à°¿à°¦à°¿à°à°¨ à°¨à°•à±à°¤à°¾à°¡à± à°¡à°¬à±à°¬à±à°²à± à°‡à°¸à±à°¤à±‡</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>500</td>\n",
              "      <td>Emi echavaa  Andaru neelagaa nakaru</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text     label\n",
              "0      1  à°à°¨à±à°¨à°¿ à°¸à°¾à°°à±à°²à± à°…à°¯à°¿à°¨ à°µà°¿à°¨à°¾à°²à°¨à°¿ à°‰à°‚à°¦à°¿ à°šà°¿à°Ÿà±à°Ÿà°¿ à°¤à°²à±à°²à°¿ à°¸à±‚...  non-hate\n",
              "1      2            à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°¬à°¾à°— work out à°…à°µà±à°¤à±à°‚à°¦à°¿ à°¸à±‚à°ªà°°à±.  non-hate\n",
              "2      3  à°‡à°¦à°¿ à°¬à±†à°‚à°¡à°ªà±‚à°¡à°¿ à°—à°µà±à°¨à°®à±†à°‚à°Ÿà± à°¸à±à°Ÿà±‚à°¡à±†à°‚à°Ÿà±à°¸à± à°•à°¿ à°®à°¾à°¤à±à°°à°®à±‡ ...  non-hate\n",
              "3      4  à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à°¿à°¨à°ªà±à°ªà±à°¡à± à°šà°¾à°²à°¾ à°…à°‚à°¦à°‚à°—à°¾ à°µà°¿à°¨à°¸à±Šà°‚à°ªà±à°—...  non-hate\n",
              "4      5  à°¸à±‚à°ªà°°à± à°¸à°¿à°¸à±à°Ÿà°°à± à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°°à±ˆà°²à±à°µà±‡ à°²à±‹ à°œà°¾à°¬à± à°°à°¾à°µà°¾à°²à°¨...  non-hate\n",
              "..   ...                                                ...       ...\n",
              "495  496                      à°¡à°¬à±à°¬à± à°‡à°¸à±à°¤à±‡ à°¨à°¿à°¨à±à°¨à±à°•à±‚à°¡ à°à°¸à±à°¤à°¾à°¡à±      hate\n",
              "496  497           à°¨à°¿à°¦à°¿ à°šà±‚à°ªà°¿à°‚à°šà± à°¦à±†à°¬à±à°¬à°•à°¿ à°¸à±†à°Ÿà± à°à°ªà±‹à°¯à°¿à°¦à°¿ à°°à±‹à°œà°¾à°•à±      hate\n",
              "497  498    à°à°¦à°¿ à°¨à°¾à°•à°¿à°¨ à°¨à±€à°¦à°¿ à°®à°¾à°¤à±à°°à°‚ à°•à°šà±à°šà°¿à°¤à°‚à°—à°¾ à°¨à°¾à°•à°¡à± à°šà±€ à°°à±†à°¡à±à°¡à°¿      hate\n",
              "498  499               à°‡à°ªà±à°ªà±à°¡à± à°¨à°¿à°¦à°¿à°à°¨ à°¨à°•à±à°¤à°¾à°¡à± à°¡à°¬à±à°¬à±à°²à± à°‡à°¸à±à°¤à±‡      hate\n",
              "499  500               Emi echavaa  Andaru neelagaa nakaru       hate\n",
              "\n",
              "[500 rows x 3 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_with_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.470910Z",
          "iopub.status.busy": "2023-12-11T01:03:14.470558Z",
          "iopub.status.idle": "2023-12-11T01:03:14.484678Z",
          "shell.execute_reply": "2023-12-11T01:03:14.483811Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.470879Z"
        },
        "id": "cqESVQY3Qkw0",
        "outputId": "0f4a561c-9e3c-4b9b-8ce5-b639189d51df",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>à°à°¨à±à°¨à°¿ à°¸à°¾à°°à±à°²à± à°…à°¯à°¿à°¨ à°µà°¿à°¨à°¾à°²à°¨à°¿ à°‰à°‚à°¦à°¿ à°šà°¿à°Ÿà±à°Ÿà°¿ à°¤à°²à±à°²à°¿ à°¸à±‚à°ªà°°à± à°®à°¾,,</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°¬à°¾à°— work out à°…à°µà±à°¤à±à°‚à°¦à°¿ à°¸à±‚à°ªà°°à±.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>à°‡à°¦à°¿ à°¬à±†à°‚à°¡à°ªà±‚à°¡à°¿ à°—à°µà±à°¨à°®à±†à°‚à°Ÿà± à°¸à±à°Ÿà±‚à°¡à±†à°‚à°Ÿà±à°¸à± à°•à°¿ à°®à°¾à°¤à±à°°à°®à±‡ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à°¿à°¨à°ªà±à°ªà±à°¡à± à°šà°¾à°²à°¾ à°…à°‚à°¦à°‚à°—à°¾ à°µà°¿à°¨à°¸à±Šà°‚à°ªà±à°—...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>à°¸à±‚à°ªà°°à± à°¸à°¿à°¸à±à°Ÿà°°à± à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°°à±ˆà°²à±à°µà±‡ à°²à±‹ à°œà°¾à°¬à± à°°à°¾à°µà°¾à°²à°¨...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>à°µà°¾à°µà± à°¸à±‚à°ªà°°à± à°…à°®à±à°® god bless u à°¤à°²à±à°²à°¿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>496</td>\n",
              "      <td>à°¡à°¬à±à°¬à± à°‡à°¸à±à°¤à±‡ à°¨à°¿à°¨à±à°¨à±à°•à±‚à°¡ à°à°¸à±à°¤à°¾à°¡à±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>497</td>\n",
              "      <td>à°¨à°¿à°¦à°¿ à°šà±‚à°ªà°¿à°‚à°šà± à°¦à±†à°¬à±à°¬à°•à°¿ à°¸à±†à°Ÿà± à°à°ªà±‹à°¯à°¿à°¦à°¿ à°°à±‹à°œà°¾à°•à±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>498</td>\n",
              "      <td>à°à°¦à°¿ à°¨à°¾à°•à°¿à°¨ à°¨à±€à°¦à°¿ à°®à°¾à°¤à±à°°à°‚ à°•à°šà±à°šà°¿à°¤à°‚à°—à°¾ à°¨à°¾à°•à°¡à± à°šà±€ à°°à±†à°¡à±à°¡à°¿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>499</td>\n",
              "      <td>à°‡à°ªà±à°ªà±à°¡à± à°¨à°¿à°¦à°¿à°à°¨ à°¨à°•à±à°¤à°¾à°¡à± à°¡à°¬à±à°¬à±à°²à± à°‡à°¸à±à°¤à±‡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>500</td>\n",
              "      <td>Emi echavaa  Andaru neelagaa nakaru</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       1 à°à°¨à±à°¨à°¿ à°¸à°¾à°°à±à°²à± à°…à°¯à°¿à°¨ à°µà°¿à°¨à°¾à°²à°¨à°¿ à°‰à°‚à°¦à°¿ à°šà°¿à°Ÿà±à°Ÿà°¿ à°¤à°²à±à°²à°¿ à°¸à±‚à°ªà°°à± à°®à°¾,,\n",
              "0      2            à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°¬à°¾à°— work out à°…à°µà±à°¤à±à°‚à°¦à°¿ à°¸à±‚à°ªà°°à±.    \n",
              "1      3  à°‡à°¦à°¿ à°¬à±†à°‚à°¡à°ªà±‚à°¡à°¿ à°—à°µà±à°¨à°®à±†à°‚à°Ÿà± à°¸à±à°Ÿà±‚à°¡à±†à°‚à°Ÿà±à°¸à± à°•à°¿ à°®à°¾à°¤à±à°°à°®à±‡ ...    \n",
              "2      4  à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à°¿à°¨à°ªà±à°ªà±à°¡à± à°šà°¾à°²à°¾ à°…à°‚à°¦à°‚à°—à°¾ à°µà°¿à°¨à°¸à±Šà°‚à°ªà±à°—...    \n",
              "3      5  à°¸à±‚à°ªà°°à± à°¸à°¿à°¸à±à°Ÿà°°à± à°«à±à°¯à±‚à°šà°°à± à°²à±‹ à°°à±ˆà°²à±à°µà±‡ à°²à±‹ à°œà°¾à°¬à± à°°à°¾à°µà°¾à°²à°¨...    \n",
              "4      6                  à°µà°¾à°µà± à°¸à±‚à°ªà°°à± à°…à°®à±à°® god bless u à°¤à°²à±à°²à°¿    \n",
              "..   ...                                                ...    \n",
              "494  496                      à°¡à°¬à±à°¬à± à°‡à°¸à±à°¤à±‡ à°¨à°¿à°¨à±à°¨à±à°•à±‚à°¡ à°à°¸à±à°¤à°¾à°¡à±    \n",
              "495  497           à°¨à°¿à°¦à°¿ à°šà±‚à°ªà°¿à°‚à°šà± à°¦à±†à°¬à±à°¬à°•à°¿ à°¸à±†à°Ÿà± à°à°ªà±‹à°¯à°¿à°¦à°¿ à°°à±‹à°œà°¾à°•à±    \n",
              "496  498    à°à°¦à°¿ à°¨à°¾à°•à°¿à°¨ à°¨à±€à°¦à°¿ à°®à°¾à°¤à±à°°à°‚ à°•à°šà±à°šà°¿à°¤à°‚à°—à°¾ à°¨à°¾à°•à°¡à± à°šà±€ à°°à±†à°¡à±à°¡à°¿    \n",
              "497  499               à°‡à°ªà±à°ªà±à°¡à± à°¨à°¿à°¦à°¿à°à°¨ à°¨à°•à±à°¤à°¾à°¡à± à°¡à°¬à±à°¬à±à°²à± à°‡à°¸à±à°¤à±‡    \n",
              "498  500               Emi echavaa  Andaru neelagaa nakaru     \n",
              "\n",
              "[499 rows x 2 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRU1aKz253-Q"
      },
      "source": [
        "# Data Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.486837Z",
          "iopub.status.busy": "2023-12-11T01:03:14.486539Z",
          "iopub.status.idle": "2023-12-11T01:03:14.494507Z",
          "shell.execute_reply": "2023-12-11T01:03:14.493601Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.486814Z"
        },
        "id": "JfF5fuQgtpMZ",
        "outputId": "eb7e7802-2782-45f2-b6f7-5c5772da79eb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4000, 3)\n",
            "(500, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape)\n",
        "print(test_with_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.496227Z",
          "iopub.status.busy": "2023-12-11T01:03:14.495600Z",
          "iopub.status.idle": "2023-12-11T01:03:14.511869Z",
          "shell.execute_reply": "2023-12-11T01:03:14.511016Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.496170Z"
        },
        "id": "S_Z-wsapu-gQ",
        "outputId": "84877a3e-d6fd-450a-de12-0518189024b0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HATE_1001</td>\n",
              "      <td>Thappu chesina vaallaku vanike kaadu inka anni...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HATE_1002</td>\n",
              "      <td>Dhusta chaathuryam!  Meeru ilantivi enni chesi...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HATE_1003</td>\n",
              "      <td>Vetakaram super. Govt ki siggu seram radu. End...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HATE_1004</td>\n",
              "      <td>Only rajakiyam ga vadukovatanike ee dharidrapu...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HATE_1005</td>\n",
              "      <td>Katam hogaya narayana pedda bokada college</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HATE_1006</td>\n",
              "      <td>TELUGU DESAM PARTY ONLY GOOD ADMINISTRATION IN...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HATE_1007</td>\n",
              "      <td>Nenu aite Jabardast show chudadam manesanu TV ...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HATE_1008</td>\n",
              "      <td>Jagan meeda jaganke visvasam ledu anduke ea lo...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HATE_1009</td>\n",
              "      <td>Students tho adukovtam thappu</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HATE_1010</td>\n",
              "      <td>Srinivasa gaaru endukee panikamaalina debate.....</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HATE_1011</td>\n",
              "      <td>Meru mi media published cheyadam vallane elant...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>HATE_1012</td>\n",
              "      <td>One of the Great Leader, A Big Salute Sir.,,</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>HATE_1013</td>\n",
              "      <td>Mogavalla face luu mathram manchiga chupisthar...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>HATE_1014</td>\n",
              "      <td>Paniki malina chana</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>HATE_1015</td>\n",
              "      <td>Rosayya garu is a real, Good and true politici...</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>HATE_1016</td>\n",
              "      <td>Telangana gujju gulam kadu</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>HATE_1017</td>\n",
              "      <td>Disevulera mundamopi</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>HATE_1018</td>\n",
              "      <td>Anta manchi job chestu govt ki tala vanchi bra...</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>HATE_1019</td>\n",
              "      <td>Down To Earth Man Rosaiah Garu</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>HATE_1020</td>\n",
              "      <td>Jagan is unstoppable</td>\n",
              "      <td>non-hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         S.No                                           Comments     Label\n",
              "0   HATE_1001  Thappu chesina vaallaku vanike kaadu inka anni...      hate\n",
              "1   HATE_1002  Dhusta chaathuryam!  Meeru ilantivi enni chesi...      hate\n",
              "2   HATE_1003  Vetakaram super. Govt ki siggu seram radu. End...      hate\n",
              "3   HATE_1004  Only rajakiyam ga vadukovatanike ee dharidrapu...      hate\n",
              "4   HATE_1005         Katam hogaya narayana pedda bokada college      hate\n",
              "5   HATE_1006  TELUGU DESAM PARTY ONLY GOOD ADMINISTRATION IN...  non-hate\n",
              "6   HATE_1007  Nenu aite Jabardast show chudadam manesanu TV ...  non-hate\n",
              "7   HATE_1008  Jagan meeda jaganke visvasam ledu anduke ea lo...      hate\n",
              "8   HATE_1009                      Students tho adukovtam thappu  non-hate\n",
              "9   HATE_1010  Srinivasa gaaru endukee panikamaalina debate.....      hate\n",
              "10  HATE_1011  Meru mi media published cheyadam vallane elant...  non-hate\n",
              "11  HATE_1012       One of the Great Leader, A Big Salute Sir.,,  non-hate\n",
              "12  HATE_1013  Mogavalla face luu mathram manchiga chupisthar...      hate\n",
              "13  HATE_1014                                Paniki malina chana      hate\n",
              "14  HATE_1015  Rosayya garu is a real, Good and true politici...  non-hate\n",
              "15  HATE_1016                         Telangana gujju gulam kadu      hate\n",
              "16  HATE_1017                               Disevulera mundamopi      hate\n",
              "17  HATE_1018  Anta manchi job chestu govt ki tala vanchi bra...      hate\n",
              "18  HATE_1019                     Down To Earth Man Rosaiah Garu  non-hate\n",
              "19  HATE_1020                              Jagan is unstoppable   non-hate"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.513618Z",
          "iopub.status.busy": "2023-12-11T01:03:14.513071Z",
          "iopub.status.idle": "2023-12-11T01:03:14.676929Z",
          "shell.execute_reply": "2023-12-11T01:03:14.675911Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.513590Z"
        },
        "id": "2DH-h-3IwUdb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_corpus = train_df[\"Comments\"].sum()\n",
        "test_corpus = test_with_label['text'].sum()\n",
        "#test_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.678778Z",
          "iopub.status.busy": "2023-12-11T01:03:14.678380Z",
          "iopub.status.idle": "2023-12-11T01:03:14.861352Z",
          "shell.execute_reply": "2023-12-11T01:03:14.860397Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.678745Z"
        },
        "id": "o9DHSoRN5-0u",
        "outputId": "f2bacfeb-adb4-4f8b-b36b-75ad91ba54b7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique words in training data: 17097\n",
            "Number of unique words in test data: 2365\n",
            "Number of out-of-vocabulary (OOV) words: 1167\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "train_corpus = train_df[\"Comments\"].sum()\n",
        "test_corpus = test_with_label[\"text\"].sum()\n",
        "\n",
        "# Remove punctuations\n",
        "chars_to_ignore = '[-,\\.:;\\'\"\\!?à¥¤]'\n",
        "\n",
        "train_corpus = re.sub(chars_to_ignore, ' ', train_corpus)\n",
        "train_vocab = set(train_corpus.split())\n",
        "\n",
        "test_corpus = re.sub(chars_to_ignore, ' ', test_corpus)\n",
        "test_vocab = set(test_corpus.split())\n",
        "\n",
        "oov = test_vocab - train_vocab\n",
        "\n",
        "print(\"Number of unique words in training data:\", len(train_vocab))\n",
        "print(\"Number of unique words in test data:\", len(test_vocab))\n",
        "print(\"Number of out-of-vocabulary (OOV) words:\", len(oov))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.863457Z",
          "iopub.status.busy": "2023-12-11T01:03:14.862730Z",
          "iopub.status.idle": "2023-12-11T01:03:14.880637Z",
          "shell.execute_reply": "2023-12-11T01:03:14.879753Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.863419Z"
        },
        "id": "B_6WCeew6G33",
        "outputId": "da1da987-e84f-4ecc-ba93-65f783568416",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3981</th>\n",
              "      <td>HATE_4982</td>\n",
              "      <td>Roja chala goranga ayipothundh</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3983</th>\n",
              "      <td>HATE_4984</td>\n",
              "      <td>Telugu rastrala nayakulu matlade matalaku pichilestundi</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3985</th>\n",
              "      <td>HATE_4986</td>\n",
              "      <td>Roja lanj...donga mund.</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3988</th>\n",
              "      <td>HATE_4989</td>\n",
              "      <td>à°¨à±€ expression à°šà±‚à°¸à±à°¤à±à°‚à°Ÿà±‡ à°à°¦à±‹ à°®à°°à±à°¡à°°à±, à°°à±‡à°ªà± à°œà°°à°¿à°—à°¿à°¨à°Ÿà±à°Ÿà±.</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>HATE_4996</td>\n",
              "      <td>à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨à±à°¨à°¾à°¯à°‚à°Ÿ.</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           S.No                                                 Comments Label\n",
              "3981  HATE_4982  Roja chala goranga ayipothundh                           hate\n",
              "3983  HATE_4984  Telugu rastrala nayakulu matlade matalaku pichilestundi  hate\n",
              "3985  HATE_4986  Roja lanj...donga mund.                                  hate\n",
              "3988  HATE_4989  à°¨à±€ expression à°šà±‚à°¸à±à°¤à±à°‚à°Ÿà±‡ à°à°¦à±‹ à°®à°°à±à°¡à°°à±, à°°à±‡à°ªà± à°œà°°à°¿à°—à°¿à°¨à°Ÿà±à°Ÿà±.     hate\n",
              "3995  HATE_4996  à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨à±à°¨à°¾à°¯à°‚à°Ÿ.    hate"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "filtered_train = train_df[lambda x: x[\"Comments\"].str.contains(\"[A-Za-z0-9]\")]\n",
        "\n",
        "with pd.option_context('display.max_colwidth', 0):\n",
        "    display(filtered_train.tail(n=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.882062Z",
          "iopub.status.busy": "2023-12-11T01:03:14.881786Z",
          "iopub.status.idle": "2023-12-11T01:03:14.890827Z",
          "shell.execute_reply": "2023-12-11T01:03:14.889782Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.882039Z"
        },
        "id": "GqKOGDtd6UQE",
        "outputId": "43c655c8-cdad-4ab1-bd76-49bacd7dc5b2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2664, 3)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.893987Z",
          "iopub.status.busy": "2023-12-11T01:03:14.893683Z",
          "iopub.status.idle": "2023-12-11T01:03:14.900649Z",
          "shell.execute_reply": "2023-12-11T01:03:14.899620Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.893960Z"
        },
        "id": "3w868NUb53-a",
        "outputId": "7f5e17da-5ebc-4c4d-ff10-4ee237d41b25",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Pure Tamil Sentence =  1336\n"
          ]
        }
      ],
      "source": [
        "print(\"Total Pure Tamil Sentence = \", train_df.shape[0] - filtered_train.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hphD1uHEv9_0"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.902914Z",
          "iopub.status.busy": "2023-12-11T01:03:14.902059Z",
          "iopub.status.idle": "2023-12-11T01:03:14.917868Z",
          "shell.execute_reply": "2023-12-11T01:03:14.916992Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.902880Z"
        },
        "id": "OyfV6dRn6eJa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def text_to_word_list(text):\n",
        "    text = text.split()\n",
        "    return text\n",
        "\n",
        "def replace_strings(text):\n",
        "    emoj = re.compile(\"[\"         # this emoj is to remove all emojis\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           u\"\\u00C0-\\u017F\"          #latin\n",
        "                           u\"\\u2000-\\u206F\"          #generalPunctuations\n",
        "\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "    text = re.sub(url_pattern, ' ', text)\n",
        "\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "    text = re.sub(r'(https|http|www)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' ', text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "    text = emoji_pattern.sub(r' ', text)\n",
        "    text = emoj.sub(r' ',text)\n",
        "\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('â€”', ' ')\n",
        "    text = text.replace('_', ' ')\n",
        "    text = text.replace('\\r', ' ')\n",
        "    text = text.replace('\\w', ' ')\n",
        "\n",
        "    text = re.sub(r'(\\\\)[a-zA-Z]+', ' ',text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)  #replace multiple space with single space\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_punctuations(my_str):\n",
        "    # define punctuation\n",
        "    #punctuations = '''```\u0012\u0010\u0002\b`\u0007\bÂ£|Â¢|\u0007Ã‘+-*/=à§³à§¦à§§à§¨à§©à§ªà§«à§¬à§­à§®à§¯012â€“34567â€¢89à¥¤!()-[]{};:'\"â€œ\\â€™,<>./?@#$%^&*_~â€˜â€”à¥¥â€â€°ğŸ¤£âš½ï¸âœŒğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ˜…ğŸ˜‚ğŸ¤£ğŸ˜ŠğŸ˜‡ğŸ™‚ğŸ™ƒğŸ˜‰ğŸ˜ŒğŸ˜ğŸ˜˜ğŸ˜—ğŸ˜™ğŸ˜šğŸ˜‹ğŸ˜›ğŸ˜ğŸ˜œğŸ¤ªğŸ¤¨ğŸ§ğŸ¤“ğŸ˜ğŸ¤©ğŸ¥³ğŸ˜ğŸ˜’ğŸ˜ğŸ˜”ğŸ˜ŸğŸ˜•ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜©ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬ğŸ˜ˆğŸ‘¿ğŸ’€â˜ ï¸ğŸ’©ğŸ¤¡ğŸ‘¹ğŸ‘ºğŸ‘»ğŸ‘½ğŸ‘¾ğŸ¤–ğŸ’‹ğŸ’ŒğŸ’˜ğŸ’ğŸ’–ğŸ’—ğŸ’“ğŸ’ğŸ’•ğŸ’Ÿâ£ï¸ğŸ’”â¤ï¸â€ğŸ”¥ğŸ–¤ğŸ¤ğŸ’¯ğŸ’¢ğŸ’¥ğŸ’«ğŸ’¦ğŸ’¨ğŸ•³ï¸ğŸ’£ğŸ’¬ğŸ‘ï¸â€ğŸ—¨ï¸ğŸ—¨ï¸ğŸ—¯ï¸ğŸ’­ğŸ’¤ğŸ‘‹ğŸ¤šğŸ–ï¸âœ‹ğŸ––ğŸ‘ŒâœŒï¸ğŸ¤ğŸ¤ŸğŸ¤˜ğŸ¤™ğŸ‘ˆğŸ‘‰ğŸ‘†ğŸ‘‡â˜ï¸âœï¸ğŸ‘ğŸ‘ğŸ»ğŸ‘ğŸ¼ğŸ‘ğŸ½ğŸ‘ğŸ¾ğŸ‘ğŸ¿ğŸ‘ğŸ‘ğŸ»ğŸ‘ğŸ¼ğŸ‘ğŸ½ğŸ‘ğŸ¾ğŸ‘ğŸ¿ğŸ‘ğŸ‘ğŸ»ğŸ‘ğŸ¼ğŸ‘ğŸ½ğŸ‘ğŸ¾ğŸ‘ğŸ¿âœŠâœŠğŸ»âœŠğŸ¼âœŠğŸ½âœŠğŸ¾âœŠğŸ¿ğŸ¤›ğŸ¤›ğŸ»ğŸ¤›ğŸ¼ğŸ¤›ğŸ½ğŸ¤›ğŸ¾ğŸ¤›ğŸ¿ğŸ¤œğŸ¤œğŸ»ğŸ¤œğŸ¼ğŸ¤œğŸ½ğŸ¤œğŸ¾ğŸ¤œğŸ¿ğŸ¤ğŸ™ğŸ™ğŸ»ğŸ™ğŸ¼ğŸ™ğŸ½ğŸ™ğŸ¾ğŸ™ğŸ¿âœï¸ğŸ’…ğŸ’…ğŸ»ğŸ’…ğŸ¼ğŸ’…ğŸ½ğŸ’…ğŸ¾ğŸ’…ğŸ¿ğŸ¤³ğŸ’ªğŸ’ªğŸ»ğŸ’ªğŸ¼ğŸ’ªğŸ½ğŸ’ªğŸ¾ğŸ’ªğŸ¿ğŸ¦¾ğŸ¦µğŸ¦¿ğŸ¦¶ğŸ‘‚ğŸ‘‚ğŸ»ğŸ‘‚ğŸ¼ğŸ‘‚ğŸ½ğŸ‘‚ğŸ¾ğŸ‘‚ğŸ¿ğŸ‘ƒğŸ‘ƒğŸ»ğŸ‘ƒğŸ¼ğŸ‘ƒğŸ½ğŸ‘ƒğŸ¾ğŸ‘ƒğŸ¿ğŸ‘€ğŸ§ ğŸ«€ğŸ«ğŸ¦·ğŸ¦´ğŸ‘…ğŸ‘„ğŸ¦»ğŸ¦»ğŸ»ğŸ¦»ğŸ¼ğŸ¦»ğŸ½ğŸ¦»ğŸ¾ğŸ¦»ğŸ¿ğŸ‘¶ğŸ‘¶ğŸ»ğŸ‘¶ğŸ¼ğŸ‘¶ğŸ½ğŸ‘¶ğŸ¾ğŸ‘¶ğŸ¿ğŸ§’ğŸ§’ğŸ»ğŸ§’ğŸ¼ğŸ§’ğŸ½ğŸ§’ğŸ¾ğŸ§’ğŸ¿ğŸ‘¦ğŸ‘¦ğŸ»ğŸ‘¦ğŸ¼ğŸ‘¦ğŸ½ğŸ‘¦ğŸ¾ğŸ‘¦ğŸ¿ğŸ‘§ğŸ‘§ğŸ»ğŸ‘§ğŸ¼ğŸ‘§ğŸ½ğŸ‘§ğŸ¾ğŸ‘§ğŸ¿ğŸ§‘ğŸ§‘ğŸ»ğŸ§‘ğŸ¼ğŸ§‘ğŸ½ğŸ§‘ğŸ¾ğŸ§‘ğŸ¿ğŸ‘¨ğŸ‘¨ğŸ»ğŸ‘¨ğŸ¼ğŸ‘¨ğŸ½ğŸ‘¨ğŸ¾ğŸ‘¨ğŸ¿ğŸ‘©ğŸ‘©ğŸ»ğŸ‘©ğŸ¼ğŸ‘©ğŸ½ğŸ‘©ğŸ¾ğŸ‘©ğŸ¿ğŸ§“ğŸ§“ğŸ»ğŸ§“ğŸ¼ğŸ§“ğŸ½ğŸ§“ğŸ¾ğŸ§“ğŸ¿ğŸ‘´ğŸ‘´ğŸ»ğŸ‘´ğŸ¼ğŸ‘´ğŸ½ğŸ‘´ğŸ¾ğŸ‘´ğŸ¿ğŸ‘µğŸ‘µğŸ»ğŸ‘µğŸ¼ğŸ‘µğŸ½ğŸ‘µğŸ¾ğŸ‘µğŸ¿ğŸ‘©â€ğŸ¦°ğŸ‘©ğŸ»â€ğŸ¦°ğŸ‘©ğŸ¼â€ğŸ¦°ğŸ‘©ğŸ½â€ğŸ¦°ğŸ‘©ğŸ¾â€ğŸ¦°ğŸ‘©ğŸ¿â€ğŸ¦°ğŸ‘©â€ğŸ¦±ğŸ‘©ğŸ»â€ğŸ¦±ğŸ‘©ğŸ¼â€ğŸ¦±ğŸ‘©ğŸ½â€ğŸ¦±ğŸ‘©ğŸ¾â€ğŸ¦±ğŸ‘©ğŸ¿â€ğŸ¦±ğŸ‘©â€ğŸ¦³ğŸ‘©ğŸ»â€ğŸ¦³ğŸ‘©ğŸ¼â€ğŸ¦³ğŸ‘©ğŸ½â€ğŸ¦³ğŸ‘©ğŸ¾â€ğŸ¦³ğŸ‘©ğŸ¿â€ğŸ¦³ğŸ‘©â€ğŸ¦²ğŸ‘©ğŸ»â€ğŸ¦²ğŸ‘©ğŸ¼â€ğŸ¦²ğŸ‘©ğŸ½â€ğŸ¦²ğŸ‘©ğŸ¾â€ğŸ¦²ğŸ‘©ğŸ¿â€ğŸ¦²ğŸ‘¨â€ğŸ¦°ğŸ‘¨ğŸ»â€ğŸ¦°ğŸ‘¨ğŸ¼â€ğŸ¦°ğŸ‘¨ğŸ½â€ğŸ¦°ğŸ‘¨ğŸ¾â€ğŸ¦°ğŸ‘¨ğŸ¿â€ğŸ¦°ğŸ‘¨â€ğŸ¦±ğŸ‘¨ğŸ»â€ğŸ¦±ğŸ‘¨ğŸ¼â€ğŸ¦±ğŸ‘¨ğŸ½â€ğŸ¦±ğŸ‘¨ğŸ¾â€ğŸ¦±ğŸ‘¨ğŸ¿â€ğŸ¦±ğŸ‘¨â€ğŸ¦³ğŸ‘¨ğŸ»â€ğŸ¦³ğŸ‘¨ğŸ¼ğŸ‘¨ğŸ½â€ğŸ¦³ğŸ‘¨ğŸ¾â€ğŸ¦³ğŸ‘¨ğŸ¿â€ğŸ¦³ğŸ‘¨â€ğŸ¦²ğŸ‘¨ğŸ»â€ğŸ¦²ğŸ‘¨ğŸ¼â€ğŸ¦²ğŸ‘¨ğŸ½â€ğŸ¦²ğŸ‘¨ğŸ¾â€ğŸ¦²ğŸ‘¨ğŸ¿â€ğŸ¦²ğŸ¦°ğŸ¦±ğŸ¦³ğŸ¦²ğŸ‘±â€â™€ï¸ğŸ‘±ğŸ»â€â™€ï¸â¤ï¸â€ğŸ©¹â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ©¹ğŸ§¡ğŸ’›ğŸ’šğŸ’™ğŸ’œğŸ¤ï¿½ï¿°à§·ï¿°'''\n",
        "    punctuations = '|Â¢|\u0007Ã‘+-à§³à§¦à§§à§¨à§©à§ªà§«à§¬à§­à§®à§¯à¥¤()-[]{}<>@#$%^&*_~â€”à¥¥ğŸ¤£âš½ï¸âœŒğŸ˜€ğŸ’‰ï¿½ï¿°à§·ï¿°'\n",
        "    no_punct = \"\"\n",
        "    for char in my_str:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "\n",
        "    # display the unpunctuated string\n",
        "    return no_punct\n",
        "\n",
        "\n",
        "\n",
        "def joining(text):\n",
        "    out=' '.join(text)\n",
        "    return out\n",
        "\n",
        "def preprocessing(text):\n",
        "    out=remove_punctuations(replace_strings(text))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:14.919106Z",
          "iopub.status.busy": "2023-12-11T01:03:14.918871Z",
          "iopub.status.idle": "2023-12-11T01:03:15.389741Z",
          "shell.execute_reply": "2023-12-11T01:03:15.388951Z",
          "shell.execute_reply.started": "2023-12-11T01:03:14.919085Z"
        },
        "id": "dGEkuz8_6jOj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df['cleanText'] = train_df.Comments.apply(lambda x: preprocessing(str(x)))\n",
        "test_with_label['text'] = test_with_label.text.apply(lambda x: preprocessing(str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.391142Z",
          "iopub.status.busy": "2023-12-11T01:03:15.390862Z",
          "iopub.status.idle": "2023-12-11T01:03:15.435824Z",
          "shell.execute_reply": "2023-12-11T01:03:15.434780Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.391117Z"
        },
        "id": "_Lzlzuzz7H5O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_corpus = train_df[\"cleanText\"].sum()\n",
        "# train_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.439487Z",
          "iopub.status.busy": "2023-12-11T01:03:15.439055Z",
          "iopub.status.idle": "2023-12-11T01:03:15.452423Z",
          "shell.execute_reply": "2023-12-11T01:03:15.451524Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.439450Z"
        },
        "id": "HE-twu9S7mca",
        "outputId": "d101c235-22db-4367-85f1-3e4ab4172be7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.No</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3990</th>\n",
              "      <td>HATE_4991</td>\n",
              "      <td>à°¨à±à°µà±à°µà± à°¨à±€ à°“à°µà°°à± à°¯à°¾à°•à±à°·à°¨à± .... à°®à±‚à°µà±€à°¸à± à°²à±‹ à°›à°¾à°¨à±à°¸à± à°•...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°¨à±à°µà±à°µà± à°¨à±€ à°“à°µà°°à± à°¯à°¾à°•à±à°·à°¨à± .... à°®à±‚à°µà±€à°¸à± à°²à±‹ à°›à°¾à°¨à±à°¸à± à°•...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991</th>\n",
              "      <td>HATE_4992</td>\n",
              "      <td>à°‡à°• à°¨à±‡à°¨à± à°¨à±à°µà±à°µà± à°‡à°‚à°Ÿà°°à±à°µà±à°¯à±‚ à°šà±‡à°¸à°¿à°¨à°¾ à°šà±‚à°¡à°¨à±</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°‡à°• à°¨à±‡à°¨à± à°¨à±à°µà±à°µà± à°‡à°‚à°Ÿà°°à±à°µà±à°¯à±‚ à°šà±‡à°¸à°¿à°¨à°¾ à°šà±‚à°¡à°¨à±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3992</th>\n",
              "      <td>HATE_4993</td>\n",
              "      <td>à°’à°• à°¸à°¾à°°à°¿ à°¨à±€ à°®à±€à°¦ à°à°¨à±à°¨à°¿ à°•à°¾à°®à±†à°‚à°Ÿà±à°²à±  à°°à°¾à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à±‹ à°š...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°’à°• à°¸à°¾à°°à°¿ à°¨à±€ à°®à±€à°¦ à°à°¨à±à°¨à°¿ à°•à°¾à°®à±†à°‚à°Ÿà±à°²à± à°°à°¾à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à±‹ à°šà±‚...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3993</th>\n",
              "      <td>HATE_4994</td>\n",
              "      <td>à°¤à°ªà±à°ªà± à°šà±‡à°¸à°¿à°¨ à°¤à°°à±à°µà°¾à°¤ à°µà°šà±à°šà°¿ à°–à°®à± à°—à°¾ à°¨à±‡ à°•à±‚à°°à±à°šà±à°‚à°Ÿà°¾à°°à±</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°¤à°ªà±à°ªà± à°šà±‡à°¸à°¿à°¨ à°¤à°°à±à°µà°¾à°¤ à°µà°šà±à°šà°¿ à°–à°®à± à°—à°¾ à°¨à±‡ à°•à±‚à°°à±à°šà±à°‚à°Ÿà°¾à°°à±</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>HATE_4995</td>\n",
              "      <td>à°šà±†à°ªà±à°ªà±à°¤à±‹ à°•à±Šà°Ÿà±à°Ÿà°¿à°¨à°Ÿà±à°Ÿà± à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°šà±à°šà°µà±à°—à°¾</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°šà±†à°ªà±à°ªà±à°¤à±‹ à°•à±Šà°Ÿà±à°Ÿà°¿à°¨à°Ÿà±à°Ÿà± à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°šà±à°šà°µà±à°—à°¾</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>HATE_4996</td>\n",
              "      <td>à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>HATE_4997</td>\n",
              "      <td>à°“à°¹à±‹ à°ˆ à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à±ˆà°¨ à°°à°µà°¿ à°ªà±à°°à°•à°¾à°·à± à°²à±‹ à°ªà°µà°¨à± à°²à°•à±à°·à°£...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°“à°¹à±‹ à°ˆ à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à±ˆà°¨ à°°à°µà°¿ à°ªà±à°°à°•à°¾à°·à± à°²à±‹ à°ªà°µà°¨à± à°²à°•à±à°·à°£...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>HATE_4998</td>\n",
              "      <td>à°µà±€à°¡à±€ à°ªà±‡à°°à± à°°à°¾à°‚à°—à±‹à°ªà°¾à°²à± à°µà°°à±à°®! à°µà±€à°¡à°¿ à°šà±‡à°¤à°¿à°²à±‹ à°ªà°¡à±à°¡ à°…à°®à±...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°µà±€à°¡à±€ à°ªà±‡à°°à± à°°à°¾à°‚à°—à±‹à°ªà°¾à°²à± à°µà°°à±à°®! à°µà±€à°¡à°¿ à°šà±‡à°¤à°¿à°²à±‹ à°ªà°¡à±à°¡ à°…à°®à±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>HATE_4999</td>\n",
              "      <td>à°¨à±à°µà±à°µà± à°®à°¾à°¤à±à°°à°‚ à°¡à°¬à±à°¬à±à°²à±‡à°¸à±à°¤à±‡ à°®à±à°·à±à°Ÿà°¿ à°µà°¾à°¡à°¿ à°ªà°•à±à°•à°¨ à°…à°¯...</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°¨à±à°µà±à°µà± à°®à°¾à°¤à±à°°à°‚ à°¡à°¬à±à°¬à±à°²à±‡à°¸à±à°¤à±‡ à°®à±à°·à±à°Ÿà°¿ à°µà°¾à°¡à°¿ à°ªà°•à±à°•à°¨ à°…à°¯...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>HATE_5000</td>\n",
              "      <td>à°µà°šà±à°šà°¿à°‚à°¦à°‚à°¡à°¿... à°®à°¾ à°¤à±à°—à±à°²à°•à± à°—à°¾à°¡à°¿ à°®à°¿à°¡à± à°¨à±ˆà°Ÿà± à°¦à±†à°µà°¤</td>\n",
              "      <td>hate</td>\n",
              "      <td>à°µà°šà±à°šà°¿à°‚à°¦à°‚à°¡à°¿... à°®à°¾ à°¤à±à°—à±à°²à°•à± à°—à°¾à°¡à°¿ à°®à°¿à°¡à± à°¨à±ˆà°Ÿà± à°¦à±†à°µà°¤</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           S.No                                           Comments Label  \\\n",
              "3990  HATE_4991  à°¨à±à°µà±à°µà± à°¨à±€ à°“à°µà°°à± à°¯à°¾à°•à±à°·à°¨à± .... à°®à±‚à°µà±€à°¸à± à°²à±‹ à°›à°¾à°¨à±à°¸à± à°•...  hate   \n",
              "3991  HATE_4992              à°‡à°• à°¨à±‡à°¨à± à°¨à±à°µà±à°µà± à°‡à°‚à°Ÿà°°à±à°µà±à°¯à±‚ à°šà±‡à°¸à°¿à°¨à°¾ à°šà±‚à°¡à°¨à±  hate   \n",
              "3992  HATE_4993  à°’à°• à°¸à°¾à°°à°¿ à°¨à±€ à°®à±€à°¦ à°à°¨à±à°¨à°¿ à°•à°¾à°®à±†à°‚à°Ÿà±à°²à±  à°°à°¾à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à±‹ à°š...  hate   \n",
              "3993  HATE_4994     à°¤à°ªà±à°ªà± à°šà±‡à°¸à°¿à°¨ à°¤à°°à±à°µà°¾à°¤ à°µà°šà±à°šà°¿ à°–à°®à± à°—à°¾ à°¨à±‡ à°•à±‚à°°à±à°šà±à°‚à°Ÿà°¾à°°à±  hate   \n",
              "3994  HATE_4995              à°šà±†à°ªà±à°ªà±à°¤à±‹ à°•à±Šà°Ÿà±à°Ÿà°¿à°¨à°Ÿà±à°Ÿà± à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°šà±à°šà°µà±à°—à°¾  hate   \n",
              "3995  HATE_4996  à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨...  hate   \n",
              "3996  HATE_4997  à°“à°¹à±‹ à°ˆ à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à±ˆà°¨ à°°à°µà°¿ à°ªà±à°°à°•à°¾à°·à± à°²à±‹ à°ªà°µà°¨à± à°²à°•à±à°·à°£...  hate   \n",
              "3997  HATE_4998  à°µà±€à°¡à±€ à°ªà±‡à°°à± à°°à°¾à°‚à°—à±‹à°ªà°¾à°²à± à°µà°°à±à°®! à°µà±€à°¡à°¿ à°šà±‡à°¤à°¿à°²à±‹ à°ªà°¡à±à°¡ à°…à°®à±...  hate   \n",
              "3998  HATE_4999  à°¨à±à°µà±à°µà± à°®à°¾à°¤à±à°°à°‚ à°¡à°¬à±à°¬à±à°²à±‡à°¸à±à°¤à±‡ à°®à±à°·à±à°Ÿà°¿ à°µà°¾à°¡à°¿ à°ªà°•à±à°•à°¨ à°…à°¯...  hate   \n",
              "3999  HATE_5000       à°µà°šà±à°šà°¿à°‚à°¦à°‚à°¡à°¿... à°®à°¾ à°¤à±à°—à±à°²à°•à± à°—à°¾à°¡à°¿ à°®à°¿à°¡à± à°¨à±ˆà°Ÿà± à°¦à±†à°µà°¤  hate   \n",
              "\n",
              "                                              cleanText  \n",
              "3990  à°¨à±à°µà±à°µà± à°¨à±€ à°“à°µà°°à± à°¯à°¾à°•à±à°·à°¨à± .... à°®à±‚à°µà±€à°¸à± à°²à±‹ à°›à°¾à°¨à±à°¸à± à°•...  \n",
              "3991              à°‡à°• à°¨à±‡à°¨à± à°¨à±à°µà±à°µà± à°‡à°‚à°Ÿà°°à±à°µà±à°¯à±‚ à°šà±‡à°¸à°¿à°¨à°¾ à°šà±‚à°¡à°¨à±  \n",
              "3992  à°’à°• à°¸à°¾à°°à°¿ à°¨à±€ à°®à±€à°¦ à°à°¨à±à°¨à°¿ à°•à°¾à°®à±†à°‚à°Ÿà±à°²à± à°°à°¾à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à±‹ à°šà±‚...  \n",
              "3993     à°¤à°ªà±à°ªà± à°šà±‡à°¸à°¿à°¨ à°¤à°°à±à°µà°¾à°¤ à°µà°šà±à°šà°¿ à°–à°®à± à°—à°¾ à°¨à±‡ à°•à±‚à°°à±à°šà±à°‚à°Ÿà°¾à°°à±  \n",
              "3994              à°šà±†à°ªà±à°ªà±à°¤à±‹ à°•à±Šà°Ÿà±à°Ÿà°¿à°¨à°Ÿà±à°Ÿà± à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°šà±à°šà°µà±à°—à°¾  \n",
              "3995  à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à°‚à°Ÿ....same à°¬à°¾à°¸à± à°•à±à°µà°¾à°²à°¿à°Ÿà±€à°¸à± à°šà°¾à°²à°¾ à°‰à°¨...  \n",
              "3996  à°“à°¹à±‹ à°ˆ à°¨à°¿à°œà°¾à°¯à°¿à°¤à±€à°ªà°°à±à°¡à±ˆà°¨ à°°à°µà°¿ à°ªà±à°°à°•à°¾à°·à± à°²à±‹ à°ªà°µà°¨à± à°²à°•à±à°·à°£...  \n",
              "3997  à°µà±€à°¡à±€ à°ªà±‡à°°à± à°°à°¾à°‚à°—à±‹à°ªà°¾à°²à± à°µà°°à±à°®! à°µà±€à°¡à°¿ à°šà±‡à°¤à°¿à°²à±‹ à°ªà°¡à±à°¡ à°…à°®à±...  \n",
              "3998  à°¨à±à°µà±à°µà± à°®à°¾à°¤à±à°°à°‚ à°¡à°¬à±à°¬à±à°²à±‡à°¸à±à°¤à±‡ à°®à±à°·à±à°Ÿà°¿ à°µà°¾à°¡à°¿ à°ªà°•à±à°•à°¨ à°…à°¯...  \n",
              "3999       à°µà°šà±à°šà°¿à°‚à°¦à°‚à°¡à°¿... à°®à°¾ à°¤à±à°—à±à°²à°•à± à°—à°¾à°¡à°¿ à°®à°¿à°¡à± à°¨à±ˆà°Ÿà± à°¦à±†à°µà°¤  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.453903Z",
          "iopub.status.busy": "2023-12-11T01:03:15.453569Z",
          "iopub.status.idle": "2023-12-11T01:03:15.465492Z",
          "shell.execute_reply": "2023-12-11T01:03:15.464687Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.453878Z"
        },
        "id": "ebfoV9BD8LZ9",
        "outputId": "8b81b462-6d34-4d3d-a949-951ba2e48ce9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "non-hate    2061\n",
              "hate        1939\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.466681Z",
          "iopub.status.busy": "2023-12-11T01:03:15.466434Z",
          "iopub.status.idle": "2023-12-11T01:03:15.479654Z",
          "shell.execute_reply": "2023-12-11T01:03:15.478763Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.466659Z"
        },
        "id": "e1dAzvPe8P4n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df['enc_label'] = train_df['Label'].replace({'hate':1, 'non-hate':0})\n",
        "test_with_label['enc_label'] = test_with_label['label'].replace({'hate':1, 'non-hate':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.480893Z",
          "iopub.status.busy": "2023-12-11T01:03:15.480642Z",
          "iopub.status.idle": "2023-12-11T01:03:15.492264Z",
          "shell.execute_reply": "2023-12-11T01:03:15.491278Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.480871Z"
        },
        "id": "VwqmFsHt8jIl",
        "outputId": "837617d1-10ed-4606-94b7-812ebe9c8794",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "enc_label\n",
              "0    2061\n",
              "1    1939\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.enc_label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1WjlCul53-f"
      },
      "source": [
        "# Data Set Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:15.494269Z",
          "iopub.status.busy": "2023-12-11T01:03:15.493559Z",
          "iopub.status.idle": "2023-12-11T01:03:16.106644Z",
          "shell.execute_reply": "2023-12-11T01:03:16.105644Z",
          "shell.execute_reply.started": "2023-12-11T01:03:15.494209Z"
        },
        "id": "wfTnUG8Q53-f",
        "outputId": "4cba9f0f-6fe2-46fe-cb89-af21ec136bd2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
        "\n",
        "train_lengths = train_df[\"Comments\"].str.len()\n",
        "sns.histplot(ax=axes[0], data=train_lengths, bins=10).set(xlabel=\"Length of training text samples\")\n",
        "axes[0].axvline(train_lengths.mean(), c=\"k\", ls=\"--\", lw=2.5, label=\"Mean\")\n",
        "axes[0].legend()\n",
        "\n",
        "#dev_lengths = dev_df[\"text\"].str.len()\n",
        "#sns.histplot(ax=axes[1], data=dev_lengths, bins=10).set(xlabel=\"Length of dev text samples\")\n",
        "#axes[1].axvline(dev_lengths.mean(), c=\"k\", ls=\"--\", lw=2.5, label=\"Mean\")\n",
        "#axes[1].legend()\n",
        "\n",
        "test_lengths = test_with_label[\"text\"].str.len()\n",
        "sns.histplot(ax=axes[1], data=test_lengths, bins=10).set(xlabel=\"Length of test text samples\")\n",
        "axes[1].axvline(test_lengths.mean(), c=\"k\", ls=\"--\", lw=2.5, label=\"Mean\")\n",
        "axes[1].legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.108490Z",
          "iopub.status.busy": "2023-12-11T01:03:16.107947Z",
          "iopub.status.idle": "2023-12-11T01:03:16.113814Z",
          "shell.execute_reply": "2023-12-11T01:03:16.112944Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.108459Z"
        },
        "id": "mc8Y7Mge53-g",
        "outputId": "9132cbac-042a-4716-ba3e-0bff46ff9794",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66.8495\n",
            "46.996\n"
          ]
        }
      ],
      "source": [
        "print(train_lengths.mean());\n",
        "print(test_lengths.mean());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.115588Z",
          "iopub.status.busy": "2023-12-11T01:03:16.115279Z",
          "iopub.status.idle": "2023-12-11T01:03:16.306295Z",
          "shell.execute_reply": "2023-12-11T01:03:16.305263Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.115554Z"
        },
        "id": "nwMbvmB953-g",
        "outputId": "4077a382-92df-4e3d-f982-fd4d91daa699",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class Name :  non-hate\n",
            "Number of Comments:2061\n",
            "Number of Words:21565\n",
            "Number of Unique Words:9652\n",
            "Most Frequent Words:\n",
            "\n",
            "à°šà°¾à°²à°¾\t149\n",
            "lo\t131\n",
            "anna\t121\n",
            "à°ˆ\t118\n",
            "à°¸à±‚à°ªà°°à±\t105\n",
            "ki\t104\n",
            "à°—à°¾à°°à±\t104\n",
            "à°…à°¨à±à°¨\t93\n",
            "sir\t92\n",
            "ga\t89\n",
            "\n",
            "Class Name :  hate\n",
            "Number of Comments:1939\n",
            "Number of Words:18251\n",
            "Number of Unique Words:9178\n",
            "Most Frequent Words:\n",
            "\n",
            "ra\t142\n",
            "ki\t127\n",
            "ni\t126\n",
            "lo\t120\n",
            "ga\t79\n",
            "oka\t76\n",
            "na\t58\n",
            "kuda\t51\n",
            "nuvvu\t50\n",
            "à°¨à±à°µà±à°µà±\t50\n",
            "Total Number of Unique Words:16421\n"
          ]
        }
      ],
      "source": [
        "dataset = train_df.filter(['cleanText','Label'])\n",
        "def data_summary(dataset):\n",
        "\n",
        "    \"\"\"\n",
        "        Comments: Comments per class\n",
        "        words:  words per class\n",
        "        u_words: unique words per class\n",
        "    \"\"\"\n",
        "    Comments = []\n",
        "    words = []\n",
        "    u_words = []\n",
        "    total_u_words = [word.strip().lower() for t in list(dataset.cleanText) for word in t.strip().split()]\n",
        "    class_label= [k for k,v in dataset.Label.value_counts().to_dict().items()]\n",
        "  # find word list\n",
        "    for label in class_label:\n",
        "        word_list = [word.strip().lower() for t in list(dataset[dataset.Label==label].cleanText) for word in t.strip().split()]\n",
        "        counts = dict()\n",
        "        for word in word_list:\n",
        "                counts[word] = counts.get(word, 0)+1\n",
        "        # sort the dictionary of word list\n",
        "        ordered = sorted(counts.items(), key= lambda item: item[1],reverse = True)\n",
        "        # Documents per class\n",
        "        Comments.append(len(list(dataset[dataset.Label == label].cleanText)))\n",
        "        # Total Word per class\n",
        "        words.append(len(word_list))\n",
        "        # Unique words per class\n",
        "        u_words.append(len(np.unique(word_list)))\n",
        "\n",
        "        print(\"\\nClass Name : \",label)\n",
        "        print(\"Number of Comments:{}\".format(len(list(dataset[dataset.Label==label].cleanText))))\n",
        "        print(\"Number of Words:{}\".format(len(word_list)))\n",
        "        print(\"Number of Unique Words:{}\".format(len(np.unique(word_list))))\n",
        "        print(\"Most Frequent Words:\\n\")\n",
        "        for k,v in ordered[:10]:\n",
        "              print(\"{}\\t{}\".format(k,v))\n",
        "    print(\"Total Number of Unique Words:{}\".format(len(np.unique(total_u_words))))\n",
        "\n",
        "    return Comments,words,u_words,class_label\n",
        "\n",
        "#call the fucntion\n",
        "Comments,words,u_words,class_names = data_summary(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.308039Z",
          "iopub.status.busy": "2023-12-11T01:03:16.307717Z",
          "iopub.status.idle": "2023-12-11T01:03:16.614130Z",
          "shell.execute_reply": "2023-12-11T01:03:16.613145Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.308011Z"
        },
        "id": "pVxlGUhp53-g",
        "outputId": "636221c2-7ffc-4914-878a-603d917ce923",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_matrix = pd.DataFrame({'Total Text':Comments,\n",
        "                            'Total Words':words,\n",
        "                            'Unique Words':u_words,\n",
        "                            'Class Names':class_names})\n",
        "df = pd.melt(data_matrix, id_vars=\"Class Names\", var_name=\"Category\", value_name=\"Values\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = plt.subplot()\n",
        "\n",
        "sns.barplot(data=df,x='Class Names', y='Values' ,hue='Category')\n",
        "ax.set_xlabel('Class Names')\n",
        "ax.set_title('Data Statistics')\n",
        "\n",
        "ax.xaxis.set_ticklabels(class_names, rotation=45);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.615787Z",
          "iopub.status.busy": "2023-12-11T01:03:16.615428Z",
          "iopub.status.idle": "2023-12-11T01:03:16.916700Z",
          "shell.execute_reply": "2023-12-11T01:03:16.915787Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.615753Z"
        },
        "id": "0a9u3m2j53-h",
        "outputId": "38713240-14fa-45a6-d17d-6c34c7fb4e7e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length of a Comment: 71\n",
            "Minimum Length of a Comment: 0\n",
            "Average Length of a Comment: 10.0\n"
          ]
        }
      ],
      "source": [
        "train_df['Comment_length'] = train_df.cleanText.apply(lambda x:len(x.split()))\n",
        "frequency = dict()\n",
        "for i in train_df.Comment_length:\n",
        "    frequency[i] = frequency.get(i, 0)+1\n",
        "\n",
        "plt.bar(frequency.keys(), frequency.values(), color =\"b\")\n",
        "plt.xlim(1, 50)\n",
        "# in this notbook color is not working but it should work.\n",
        "plt.xlabel('Length of the Text')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Length-Frequency Distribution')\n",
        "plt.show()\n",
        "print(f\"Maximum Length of a Comment: {max(train_df.Comment_length)}\")\n",
        "print(f\"Minimum Length of a Comment: {min(train_df.Comment_length)}\")\n",
        "print(f\"Average Length of a Comment: {round(np.mean(train_df.Comment_length),0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.919823Z",
          "iopub.status.busy": "2023-12-11T01:03:16.919534Z",
          "iopub.status.idle": "2023-12-11T01:03:16.926884Z",
          "shell.execute_reply": "2023-12-11T01:03:16.925936Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.919797Z"
        },
        "id": "HnYvqqdn53-i",
        "outputId": "7d1c0c6c-852d-4f0e-bcb7-4be6bf1391e6",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22, 6)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.loc[train_df['Comment_length'] > 40].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:16.928224Z",
          "iopub.status.busy": "2023-12-11T01:03:16.927937Z",
          "iopub.status.idle": "2023-12-11T01:03:17.163432Z",
          "shell.execute_reply": "2023-12-11T01:03:17.162507Z",
          "shell.execute_reply.started": "2023-12-11T01:03:16.928180Z"
        },
        "id": "DVoR08rm53-i",
        "outputId": "d6f9becb-bdf4-49d8-f232-9e1d10317a31",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length of a Comment: 18\n",
            "Minimum Length of a Comment: 0\n",
            "Average Length of a Comment: 7.0\n"
          ]
        }
      ],
      "source": [
        "test_with_label['Comment_length'] = test_with_label.text.apply(lambda x:len(x.split()))\n",
        "frequency = dict()\n",
        "for i in test_with_label.Comment_length:\n",
        "    frequency[i] = frequency.get(i, 0)+1\n",
        "\n",
        "plt.bar(frequency.keys(), frequency.values(), color =\"b\")\n",
        "plt.xlim(1, 50)\n",
        "# in this notbook color is not working but it should work.\n",
        "plt.xlabel('Length of the Comment')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Length-Frequency Distribution')\n",
        "plt.show()\n",
        "print(f\"Maximum Length of a Comment: {max(test_with_label.Comment_length)}\")\n",
        "print(f\"Minimum Length of a Comment: {min(test_with_label.Comment_length)}\")\n",
        "print(f\"Average Length of a Comment: {round(np.mean(test_with_label.Comment_length),0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glhzaDgnxnKm"
      },
      "source": [
        "# Splitting Dataset for Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:17.164930Z",
          "iopub.status.busy": "2023-12-11T01:03:17.164641Z",
          "iopub.status.idle": "2023-12-11T01:03:17.174400Z",
          "shell.execute_reply": "2023-12-11T01:03:17.173442Z",
          "shell.execute_reply.started": "2023-12-11T01:03:17.164905Z"
        },
        "id": "Xsl0FYYwxqBX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xx_train, Xx_valid, yy_train, yy_valid = train_test_split(train_df['cleanText'], train_df['enc_label'], test_size=0.15, random_state=42, stratify = train_df['enc_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:20.494115Z",
          "iopub.status.busy": "2023-12-11T01:03:20.493153Z",
          "iopub.status.idle": "2023-12-11T01:03:20.499552Z",
          "shell.execute_reply": "2023-12-11T01:03:20.498626Z",
          "shell.execute_reply.started": "2023-12-11T01:03:20.494083Z"
        },
        "id": "LqbTPRK1xtoY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train = Xx_train.tolist()\n",
        "y_train = yy_train.tolist()\n",
        "\n",
        "X_valid = Xx_valid.tolist()\n",
        "y_valid = yy_valid.tolist()\n",
        "\n",
        "X_test = test_with_label['text'].tolist()\n",
        "y_data_with_label = test_with_label['enc_label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_6NB5_6wPbb"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqTGmilMByk5"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-06T03:46:14.808215Z",
          "iopub.status.busy": "2023-12-06T03:46:14.807276Z",
          "iopub.status.idle": "2023-12-06T03:46:53.170042Z",
          "shell.execute_reply": "2023-12-06T03:46:53.168877Z",
          "shell.execute_reply.started": "2023-12-06T03:46:14.808177Z"
        },
        "id": "bQxLoeHxBxm_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(n_estimators=1000)  #use class_weight='balanced'\n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "\n",
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSup3M0b2H7T",
        "outputId": "350f1a53-1e48-4490-d228-8653bd610e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5731462925851704\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.56      0.70      0.62       249\n",
            "\n",
            "           1       0.60      0.44      0.51       250\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.57       499\n",
            "\n",
            "   macro avg       0.58      0.57      0.57       499\n",
            "\n",
            "weighted avg       0.58      0.57      0.57       499\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_data_with_label, y_pred)\n",
        "report = classification_report(y_data_with_label, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPOel-Y-2rFn"
      },
      "source": [
        "## LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Ih8U_AOLzuYK",
        "outputId": "d268b1ff-3a82-4d06-8695-84fa3b7b86c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=1, solver='liblinear')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "model_lr = LogisticRegression(solver='liblinear', C=1)\n",
        "model_lr.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2ATLN3k25MI",
        "outputId": "60e54c4e-7649-411f-b5b1-dd3ac26a25d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.6332665330661322\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.63      0.63      0.63       249\n",
            "\n",
            "           1       0.63      0.64      0.64       250\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.63       499\n",
            "\n",
            "   macro avg       0.63      0.63      0.63       499\n",
            "\n",
            "weighted avg       0.63      0.63      0.63       499\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lr = model_lr.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lr = accuracy_score(y_data_with_label, y_pred_lr)\n",
        "classification_report_lr = classification_report(y_data_with_label, y_pred_lr)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
        "print('Classification Report for Logistic Regression:\\n', classification_report_lr) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4B05o7r0dzf"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV368gkj0f9n",
        "outputId": "738f9e7b-d0ea-44c7-fe84-86c2198cbd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.6492985971943888\n",
            "\n",
            "Classification Report for SVM:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.64      0.67      0.65       249\n",
            "\n",
            "           1       0.66      0.63      0.64       250\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.65       499\n",
            "\n",
            "   macro avg       0.65      0.65      0.65       499\n",
            "\n",
            "weighted avg       0.65      0.65      0.65       499\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, class_weight='balanced', kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svm = model_svm.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(y_data_with_label, y_pred_svm)\n",
        "classification_report_svm = classification_report(y_data_with_label, y_pred_svm)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm) # 0.65      0.65      0.65"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqAuQsJjMm25"
      },
      "source": [
        "## Ensemble Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "execution": {
          "iopub.execute_input": "2023-12-04T01:41:50.095429Z",
          "iopub.status.busy": "2023-12-04T01:41:50.095147Z",
          "iopub.status.idle": "2023-12-04T01:42:24.226349Z",
          "shell.execute_reply": "2023-12-04T01:42:24.225474Z",
          "shell.execute_reply.started": "2023-12-04T01:41:50.095406Z"
        },
        "id": "jCyZUA9sLiR3",
        "outputId": "83561afb-2491-4a8e-f727-efabc15dd82d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(n_estimators=1000)  #use class_weight='balanced' if classes are imbalanced\n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_lr = LogisticRegression(C = 1, class_weight = 'balanced', penalty = 'l2', solver = 'newton-cg', max_iter=1000)\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_svm = SVC(kernel='linear', C = 1, class_weight = 'balanced')    #kernel='poly'  kernel='rbf'   kernel='sigmoid'\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "execution": {
          "iopub.execute_input": "2023-12-04T01:42:24.227761Z",
          "iopub.status.busy": "2023-12-04T01:42:24.227493Z",
          "iopub.status.idle": "2023-12-04T01:42:58.698581Z",
          "shell.execute_reply": "2023-12-04T01:42:58.697669Z",
          "shell.execute_reply.started": "2023-12-04T01:42:24.227738Z"
        },
        "id": "KoE5Hu_fMy7W",
        "outputId": "2615effc-7d3f-438f-c8c0-c58c0eb30fe9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;,\n",
              "                              RandomForestClassifier(n_estimators=1000)),\n",
              "                             (&#x27;LogisticRegression&#x27;,\n",
              "                              LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                                 max_iter=1000,\n",
              "                                                 solver=&#x27;newton-cg&#x27;)),\n",
              "                             (&#x27;SVM&#x27;,\n",
              "                              SVC(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                  kernel=&#x27;linear&#x27;)),\n",
              "                             (&#x27;DecisionTree&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;,\n",
              "                              RandomForestClassifier(n_estimators=1000)),\n",
              "                             (&#x27;LogisticRegression&#x27;,\n",
              "                              LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                                 max_iter=1000,\n",
              "                                                 solver=&#x27;newton-cg&#x27;)),\n",
              "                             (&#x27;SVM&#x27;,\n",
              "                              SVC(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                  kernel=&#x27;linear&#x27;)),\n",
              "                             (&#x27;DecisionTree&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RandomForest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DecisionTree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('RandomForest',\n",
              "                              RandomForestClassifier(n_estimators=1000)),\n",
              "                             ('LogisticRegression',\n",
              "                              LogisticRegression(C=1, class_weight='balanced',\n",
              "                                                 max_iter=1000,\n",
              "                                                 solver='newton-cg')),\n",
              "                             ('SVM',\n",
              "                              SVC(C=1, class_weight='balanced',\n",
              "                                  kernel='linear')),\n",
              "                             ('DecisionTree', DecisionTreeClassifier())])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create a list of tuples with model names and trained models\n",
        "models = [\n",
        "    ('RandomForest', model_rf),\n",
        "    ('LogisticRegression', model_lr),\n",
        "    ('SVM', model_svm),\n",
        "    ('DecisionTree', model_dt)\n",
        "]\n",
        "\n",
        "# Create an ensemble model using VotingClassifier\n",
        "ensemble_model = VotingClassifier(estimators=models, voting='hard') # 'hard' voting for majority class\n",
        "ensemble_model.fit(X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-xp78GQ3-E1",
        "outputId": "657a6e23-3bc5-404d-baee-0dd3e9e7b85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5951903807615231\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "\n",
            "\n",
            "           0       0.57      0.73      0.64       249\n",
            "\n",
            "           1       0.63      0.46      0.53       250\n",
            "\n",
            "\n",
            "\n",
            "    accuracy                           0.60       499\n",
            "\n",
            "   macro avg       0.60      0.60      0.59       499\n",
            "\n",
            "weighted avg       0.60      0.60      0.59       499\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred = ensemble_model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_data_with_label, y_pred)\n",
        "report = classification_report(y_data_with_label, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uGKlKfM53--"
      },
      "source": [
        "# Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHo_4GOEf8Ln"
      },
      "source": [
        "## BiLSTM(Word2Vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:38.241675Z",
          "iopub.status.busy": "2023-12-11T01:03:38.241323Z",
          "iopub.status.idle": "2023-12-11T01:03:38.344702Z",
          "shell.execute_reply": "2023-12-11T01:03:38.343413Z",
          "shell.execute_reply.started": "2023-12-11T01:03:38.241646Z"
        },
        "id": "RABu7-nR53-_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM,GRU\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Flatten, Dense\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:41.493170Z",
          "iopub.status.busy": "2023-12-11T01:03:41.492814Z",
          "iopub.status.idle": "2023-12-11T01:03:41.601180Z",
          "shell.execute_reply": "2023-12-11T01:03:41.600404Z",
          "shell.execute_reply.started": "2023-12-11T01:03:41.493140Z"
        },
        "id": "N5DgERI953-_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = 20000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n-',\n",
        "                      split=' ', char_level=False, oov_token='<oov>', document_count=0)     #tokenization\n",
        "tokenizer.fit_on_texts(train_df['cleanText'])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:43.618258Z",
          "iopub.status.busy": "2023-12-11T01:03:43.617395Z",
          "iopub.status.idle": "2023-12-11T01:03:43.622964Z",
          "shell.execute_reply": "2023-12-11T01:03:43.621935Z",
          "shell.execute_reply.started": "2023-12-11T01:03:43.618224Z"
        },
        "id": "zYTLerKd53_A",
        "outputId": "5f3d8d4a-6fc6-45aa-a1a7-8c677bfceab7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15151\n"
          ]
        }
      ],
      "source": [
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr4tvf7IS6kn",
        "outputId": "9eb85d2b-bb55-4145-f692-951cde593ccc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "word2vec_model = Word2Vec(sentences=train_df['cleanText'], vector_size=300, window=5, min_count=1, workers=4)\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:03:46.119421Z",
          "iopub.status.busy": "2023-12-11T01:03:46.118991Z",
          "iopub.status.idle": "2023-12-11T01:03:46.227056Z",
          "shell.execute_reply": "2023-12-11T01:03:46.226073Z",
          "shell.execute_reply.started": "2023-12-11T01:03:46.119387Z"
        },
        "id": "MCEQWPte53_A",
        "outputId": "abc6eb5a-3c1b-47f2-b421-ef2c920d8612",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15150\n",
            "Number of Training Sequences : (4000, 100)\n",
            "Number of test Sequences : (500, 100)\n"
          ]
        }
      ],
      "source": [
        "max_len = 100\n",
        "# Training Sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['cleanText'])\n",
        "print(len(tokenizer.word_index))\n",
        "train_pad_sequences =  pad_sequences(train_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of Training Sequences :\" ,train_pad_sequences.shape)\n",
        "\n",
        "# # Validation Sequences\n",
        "# validation_sequences = tokenizer.texts_to_sequences(X_valid)\n",
        "# validation_pad_sequences =  pad_sequences(validation_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "# print(\"Number of Validation Sequences :\" ,validation_pad_sequences.shape)\n",
        "\n",
        "# Validation Sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_pad_sequences =  pad_sequences(test_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of test Sequences :\" ,test_pad_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:04:33.590654Z",
          "iopub.status.busy": "2023-12-11T01:04:33.589985Z",
          "iopub.status.idle": "2023-12-11T01:04:34.111490Z",
          "shell.execute_reply": "2023-12-11T01:04:34.110564Z",
          "shell.execute_reply.started": "2023-12-11T01:04:33.590620Z"
        },
        "id": "DP_aWEJZ53_B",
        "outputId": "84efc07f-5f5b-4d8c-9d3c-31b9e973722b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 100, 300)          4545300   \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 100, 400)          801600    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 40000)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 40001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5386901 (20.55 MB)\n",
            "Trainable params: 841601 (3.21 MB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/HOLD/\" + \"BiLSTM_One.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "    Bidirectional(LSTM(units=200, return_sequences=True, dropout=0.2)),\n",
        "    Flatten(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:05:26.583661Z",
          "iopub.status.busy": "2023-12-11T01:05:26.582823Z",
          "iopub.status.idle": "2023-12-11T01:06:26.203819Z",
          "shell.execute_reply": "2023-12-11T01:06:26.202882Z",
          "shell.execute_reply.started": "2023-12-11T01:05:26.583626Z"
        },
        "id": "wJ4Gh1ry53_C",
        "outputId": "f0437738-fabb-4eaa-b2d7-fbdc195f2a9c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.5098\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTM_One.h5\n",
            "125/125 [==============================] - 8s 25ms/step - loss: 0.6902 - accuracy: 0.5092 - val_loss: 0.6972 - val_accuracy: 0.5100\n",
            "Epoch 2/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.5266\n",
            "Epoch 2: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6880 - accuracy: 0.5260 - val_loss: 0.6955 - val_accuracy: 0.4940\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.5220\n",
            "Epoch 3: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6858 - accuracy: 0.5220 - val_loss: 0.6980 - val_accuracy: 0.5100\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.5182\n",
            "Epoch 4: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6841 - accuracy: 0.5182 - val_loss: 0.6977 - val_accuracy: 0.4900\n",
            "Epoch 5/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.5131\n",
            "Epoch 5: val_accuracy improved from 0.51000 to 0.51400, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTM_One.h5\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6831 - accuracy: 0.5145 - val_loss: 0.6957 - val_accuracy: 0.5140\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6832 - accuracy: 0.5190\n",
            "Epoch 6: val_accuracy improved from 0.51400 to 0.51600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTM_One.h5\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6832 - accuracy: 0.5190 - val_loss: 0.6960 - val_accuracy: 0.5160\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5113\n",
            "Epoch 7: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6794 - accuracy: 0.5113 - val_loss: 0.6966 - val_accuracy: 0.4940\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.5220\n",
            "Epoch 8: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6772 - accuracy: 0.5220 - val_loss: 0.6945 - val_accuracy: 0.5080\n",
            "Epoch 9/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.5236\n",
            "Epoch 9: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6759 - accuracy: 0.5235 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5126\n",
            "Epoch 10: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6743 - accuracy: 0.5138 - val_loss: 0.6943 - val_accuracy: 0.5160\n",
            "Epoch 11/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5196\n",
            "Epoch 11: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6735 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
            "Epoch 12/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5135\n",
            "Epoch 12: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6716 - accuracy: 0.5153 - val_loss: 0.6969 - val_accuracy: 0.5120\n",
            "Epoch 13/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5307\n",
            "Epoch 13: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6725 - accuracy: 0.5307 - val_loss: 0.7022 - val_accuracy: 0.4940\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5275\n",
            "Epoch 14: val_accuracy did not improve from 0.51600\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6707 - accuracy: 0.5275 - val_loss: 0.6970 - val_accuracy: 0.4960\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5383\n",
            "Epoch 15: val_accuracy improved from 0.51600 to 0.51800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTM_One.h5\n",
            "125/125 [==============================] - 3s 21ms/step - loss: 0.6703 - accuracy: 0.5383 - val_loss: 0.6947 - val_accuracy: 0.5180\n",
            "Epoch 16/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6683 - accuracy: 0.5323\n",
            "Epoch 16: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6687 - accuracy: 0.5310 - val_loss: 0.6951 - val_accuracy: 0.5060\n",
            "Epoch 17/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6682 - accuracy: 0.5261\n",
            "Epoch 17: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6684 - accuracy: 0.5260 - val_loss: 0.6970 - val_accuracy: 0.5140\n",
            "Epoch 18/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.5292\n",
            "Epoch 18: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6674 - accuracy: 0.5285 - val_loss: 0.6949 - val_accuracy: 0.4980\n",
            "Epoch 19/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6649 - accuracy: 0.5267\n",
            "Epoch 19: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6651 - accuracy: 0.5282 - val_loss: 0.6975 - val_accuracy: 0.5140\n",
            "Epoch 20/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.5204\n",
            "Epoch 20: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6662 - accuracy: 0.5215 - val_loss: 0.7061 - val_accuracy: 0.4980\n",
            "Epoch 21/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.5302\n",
            "Epoch 21: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6647 - accuracy: 0.5307 - val_loss: 0.7018 - val_accuracy: 0.4960\n",
            "Epoch 22/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6628 - accuracy: 0.5415\n",
            "Epoch 22: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6626 - accuracy: 0.5397 - val_loss: 0.7081 - val_accuracy: 0.5100\n",
            "Epoch 23/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6643 - accuracy: 0.5234\n",
            "Epoch 23: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6645 - accuracy: 0.5240 - val_loss: 0.7039 - val_accuracy: 0.4940\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.5332\n",
            "Epoch 24: val_accuracy improved from 0.51800 to 0.52000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTM_One.h5\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.6624 - accuracy: 0.5332 - val_loss: 0.6977 - val_accuracy: 0.5200\n",
            "Epoch 25/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.5295\n",
            "Epoch 25: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6619 - accuracy: 0.5288 - val_loss: 0.7024 - val_accuracy: 0.5100\n",
            "Epoch 26/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.5559\n",
            "Epoch 26: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6614 - accuracy: 0.5548 - val_loss: 0.7000 - val_accuracy: 0.5120\n",
            "Epoch 27/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6618 - accuracy: 0.5300\n",
            "Epoch 27: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6621 - accuracy: 0.5295 - val_loss: 0.7007 - val_accuracy: 0.5140\n",
            "Epoch 28/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6599 - accuracy: 0.5267\n",
            "Epoch 28: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.6598 - accuracy: 0.5268 - val_loss: 0.7078 - val_accuracy: 0.5100\n",
            "Epoch 29/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6608 - accuracy: 0.5159\n",
            "Epoch 29: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 19ms/step - loss: 0.6611 - accuracy: 0.5167 - val_loss: 0.7095 - val_accuracy: 0.5100\n",
            "Epoch 30/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.5198\n",
            "Epoch 30: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6595 - accuracy: 0.5207 - val_loss: 0.7020 - val_accuracy: 0.5200\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.5335\n",
            "Epoch 31: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6584 - accuracy: 0.5335 - val_loss: 0.7097 - val_accuracy: 0.5160\n",
            "Epoch 32/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6598 - accuracy: 0.5295\n",
            "Epoch 32: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6589 - accuracy: 0.5303 - val_loss: 0.7065 - val_accuracy: 0.5160\n",
            "Epoch 33/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6586 - accuracy: 0.5328\n",
            "Epoch 33: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6585 - accuracy: 0.5328 - val_loss: 0.7089 - val_accuracy: 0.4980\n",
            "Epoch 34/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6576 - accuracy: 0.5363\n",
            "Epoch 34: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6580 - accuracy: 0.5370 - val_loss: 0.7106 - val_accuracy: 0.5180\n",
            "Epoch 35/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6595 - accuracy: 0.5356\n",
            "Epoch 35: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6592 - accuracy: 0.5353 - val_loss: 0.7132 - val_accuracy: 0.4940\n",
            "Epoch 36/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6581 - accuracy: 0.5257\n",
            "Epoch 36: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6581 - accuracy: 0.5257 - val_loss: 0.7063 - val_accuracy: 0.5180\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.5188\n",
            "Epoch 37: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6577 - accuracy: 0.5188 - val_loss: 0.7076 - val_accuracy: 0.5140\n",
            "Epoch 38/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6566 - accuracy: 0.5407\n",
            "Epoch 38: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6565 - accuracy: 0.5418 - val_loss: 0.7060 - val_accuracy: 0.4940\n",
            "Epoch 39/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.5305\n",
            "Epoch 39: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6548 - accuracy: 0.5315 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6556 - accuracy: 0.5197\n",
            "Epoch 40: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6557 - accuracy: 0.5203 - val_loss: 0.7075 - val_accuracy: 0.4940\n",
            "Epoch 41/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6556 - accuracy: 0.5282\n",
            "Epoch 41: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6563 - accuracy: 0.5278 - val_loss: 0.7070 - val_accuracy: 0.4960\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.5282\n",
            "Epoch 42: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6552 - accuracy: 0.5282 - val_loss: 0.7130 - val_accuracy: 0.5100\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.5395\n",
            "Epoch 43: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6553 - accuracy: 0.5395 - val_loss: 0.7156 - val_accuracy: 0.4960\n",
            "Epoch 44/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.5445\n",
            "Epoch 44: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6542 - accuracy: 0.5433 - val_loss: 0.7062 - val_accuracy: 0.5080\n",
            "Epoch 45/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.5330\n",
            "Epoch 45: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6536 - accuracy: 0.5320 - val_loss: 0.7093 - val_accuracy: 0.5120\n",
            "Epoch 46/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.5318\n",
            "Epoch 46: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6539 - accuracy: 0.5322 - val_loss: 0.7115 - val_accuracy: 0.5100\n",
            "Epoch 47/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.5471\n",
            "Epoch 47: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6550 - accuracy: 0.5445 - val_loss: 0.7126 - val_accuracy: 0.4940\n",
            "Epoch 48/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.5441\n",
            "Epoch 48: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6554 - accuracy: 0.5440 - val_loss: 0.7125 - val_accuracy: 0.4940\n",
            "Epoch 49/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.5259\n",
            "Epoch 49: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6546 - accuracy: 0.5250 - val_loss: 0.7118 - val_accuracy: 0.4920\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.5385\n",
            "Epoch 50: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6533 - accuracy: 0.5385 - val_loss: 0.7140 - val_accuracy: 0.4940\n",
            "Epoch 51/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.5370\n",
            "Epoch 51: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6531 - accuracy: 0.5365 - val_loss: 0.7122 - val_accuracy: 0.5080\n",
            "Epoch 52/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.5315\n",
            "Epoch 52: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6541 - accuracy: 0.5303 - val_loss: 0.7080 - val_accuracy: 0.5080\n",
            "Epoch 53/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.5353\n",
            "Epoch 53: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6526 - accuracy: 0.5355 - val_loss: 0.7111 - val_accuracy: 0.4940\n",
            "Epoch 54/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.5382\n",
            "Epoch 54: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6540 - accuracy: 0.5383 - val_loss: 0.7084 - val_accuracy: 0.5100\n",
            "Epoch 55/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.5287\n",
            "Epoch 55: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6530 - accuracy: 0.5300 - val_loss: 0.7115 - val_accuracy: 0.5060\n",
            "Epoch 56/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.5409\n",
            "Epoch 56: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6524 - accuracy: 0.5422 - val_loss: 0.7106 - val_accuracy: 0.4960\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.5385\n",
            "Epoch 57: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6511 - accuracy: 0.5385 - val_loss: 0.7189 - val_accuracy: 0.4920\n",
            "Epoch 58/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.5338\n",
            "Epoch 58: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6517 - accuracy: 0.5343 - val_loss: 0.7172 - val_accuracy: 0.4900\n",
            "Epoch 59/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.5346\n",
            "Epoch 59: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6514 - accuracy: 0.5360 - val_loss: 0.7133 - val_accuracy: 0.5080\n",
            "Epoch 60/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6529 - accuracy: 0.5335\n",
            "Epoch 60: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6528 - accuracy: 0.5340 - val_loss: 0.7082 - val_accuracy: 0.5120\n",
            "Epoch 61/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6508 - accuracy: 0.5325\n",
            "Epoch 61: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6506 - accuracy: 0.5337 - val_loss: 0.7126 - val_accuracy: 0.5060\n",
            "Epoch 62/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.5382\n",
            "Epoch 62: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6507 - accuracy: 0.5397 - val_loss: 0.7206 - val_accuracy: 0.4940\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.5360\n",
            "Epoch 63: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6518 - accuracy: 0.5360 - val_loss: 0.7182 - val_accuracy: 0.4880\n",
            "Epoch 64/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.5300\n",
            "Epoch 64: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6499 - accuracy: 0.5303 - val_loss: 0.7152 - val_accuracy: 0.4880\n",
            "Epoch 65/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6503 - accuracy: 0.5368\n",
            "Epoch 65: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6506 - accuracy: 0.5343 - val_loss: 0.7159 - val_accuracy: 0.5120\n",
            "Epoch 66/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6505 - accuracy: 0.5242\n",
            "Epoch 66: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6505 - accuracy: 0.5240 - val_loss: 0.7200 - val_accuracy: 0.4920\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.5465\n",
            "Epoch 67: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.6511 - accuracy: 0.5465 - val_loss: 0.7186 - val_accuracy: 0.5060\n",
            "Epoch 68/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6592 - accuracy: 0.5485\n",
            "Epoch 68: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6601 - accuracy: 0.5483 - val_loss: 0.7361 - val_accuracy: 0.5100\n",
            "Epoch 69/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6563 - accuracy: 0.5323\n",
            "Epoch 69: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6570 - accuracy: 0.5318 - val_loss: 0.7141 - val_accuracy: 0.5060\n",
            "Epoch 70/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6537 - accuracy: 0.5369\n",
            "Epoch 70: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6529 - accuracy: 0.5362 - val_loss: 0.7136 - val_accuracy: 0.5020\n",
            "Epoch 71/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.5396\n",
            "Epoch 71: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6511 - accuracy: 0.5397 - val_loss: 0.7139 - val_accuracy: 0.4940\n",
            "Epoch 72/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6511 - accuracy: 0.5346\n",
            "Epoch 72: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6508 - accuracy: 0.5353 - val_loss: 0.7145 - val_accuracy: 0.5020\n",
            "Epoch 73/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.5396\n",
            "Epoch 73: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6507 - accuracy: 0.5403 - val_loss: 0.7178 - val_accuracy: 0.4880\n",
            "Epoch 74/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6500 - accuracy: 0.5459\n",
            "Epoch 74: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6507 - accuracy: 0.5462 - val_loss: 0.7379 - val_accuracy: 0.4960\n",
            "Epoch 75/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6508 - accuracy: 0.5445\n",
            "Epoch 75: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6511 - accuracy: 0.5452 - val_loss: 0.7194 - val_accuracy: 0.4940\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.5390\n",
            "Epoch 76: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6501 - accuracy: 0.5390 - val_loss: 0.7245 - val_accuracy: 0.4880\n",
            "Epoch 77/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.5343\n",
            "Epoch 77: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6492 - accuracy: 0.5357 - val_loss: 0.7213 - val_accuracy: 0.5060\n",
            "Epoch 78/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.5374\n",
            "Epoch 78: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6488 - accuracy: 0.5357 - val_loss: 0.7179 - val_accuracy: 0.5060\n",
            "Epoch 79/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.5474\n",
            "Epoch 79: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6491 - accuracy: 0.5470 - val_loss: 0.7223 - val_accuracy: 0.5040\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.5440\n",
            "Epoch 80: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6497 - accuracy: 0.5440 - val_loss: 0.7220 - val_accuracy: 0.5040\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.5523\n",
            "Epoch 81: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6490 - accuracy: 0.5523 - val_loss: 0.7209 - val_accuracy: 0.5020\n",
            "Epoch 82/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.5373\n",
            "Epoch 82: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6489 - accuracy: 0.5357 - val_loss: 0.7211 - val_accuracy: 0.4940\n",
            "Epoch 83/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6487 - accuracy: 0.5453\n",
            "Epoch 83: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6484 - accuracy: 0.5460 - val_loss: 0.7251 - val_accuracy: 0.4880\n",
            "Epoch 84/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.5445\n",
            "Epoch 84: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6487 - accuracy: 0.5465 - val_loss: 0.7209 - val_accuracy: 0.5040\n",
            "Epoch 85/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.5437\n",
            "Epoch 85: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6481 - accuracy: 0.5455 - val_loss: 0.7212 - val_accuracy: 0.4900\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.5325\n",
            "Epoch 86: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6482 - accuracy: 0.5325 - val_loss: 0.7177 - val_accuracy: 0.5040\n",
            "Epoch 87/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.5338\n",
            "Epoch 87: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6494 - accuracy: 0.5335 - val_loss: 0.7207 - val_accuracy: 0.5040\n",
            "Epoch 88/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.5424\n",
            "Epoch 88: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6496 - accuracy: 0.5408 - val_loss: 0.7207 - val_accuracy: 0.5060\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.5390\n",
            "Epoch 89: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.6486 - accuracy: 0.5390 - val_loss: 0.7172 - val_accuracy: 0.5100\n",
            "Epoch 90/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.5338\n",
            "Epoch 90: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.6483 - accuracy: 0.5347 - val_loss: 0.7188 - val_accuracy: 0.5040\n",
            "Epoch 91/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.5282\n",
            "Epoch 91: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6491 - accuracy: 0.5293 - val_loss: 0.7189 - val_accuracy: 0.5040\n",
            "Epoch 92/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6488 - accuracy: 0.5441\n",
            "Epoch 92: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6483 - accuracy: 0.5465 - val_loss: 0.7216 - val_accuracy: 0.4900\n",
            "Epoch 93/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.5546\n",
            "Epoch 93: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6488 - accuracy: 0.5520 - val_loss: 0.7204 - val_accuracy: 0.5060\n",
            "Epoch 94/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6486 - accuracy: 0.5414\n",
            "Epoch 94: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6489 - accuracy: 0.5428 - val_loss: 0.7171 - val_accuracy: 0.4960\n",
            "Epoch 95/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6491 - accuracy: 0.5290\n",
            "Epoch 95: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6486 - accuracy: 0.5290 - val_loss: 0.7226 - val_accuracy: 0.4900\n",
            "Epoch 96/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6484 - accuracy: 0.5262\n",
            "Epoch 96: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6485 - accuracy: 0.5263 - val_loss: 0.7205 - val_accuracy: 0.4880\n",
            "Epoch 97/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6481 - accuracy: 0.5353\n",
            "Epoch 97: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6483 - accuracy: 0.5353 - val_loss: 0.7207 - val_accuracy: 0.5040\n",
            "Epoch 98/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.5328\n",
            "Epoch 98: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6477 - accuracy: 0.5332 - val_loss: 0.7218 - val_accuracy: 0.5080\n",
            "Epoch 99/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6490 - accuracy: 0.5397\n",
            "Epoch 99: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6484 - accuracy: 0.5400 - val_loss: 0.7227 - val_accuracy: 0.5060\n",
            "Epoch 100/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.5412\n",
            "Epoch 100: val_accuracy did not improve from 0.52000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.6498 - accuracy: 0.5428 - val_loss: 0.7190 - val_accuracy: 0.5040\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:07:17.217120Z",
          "iopub.status.busy": "2023-12-11T01:07:17.216261Z",
          "iopub.status.idle": "2023-12-11T01:07:17.392630Z",
          "shell.execute_reply": "2023-12-11T01:07:17.391643Z",
          "shell.execute_reply.started": "2023-12-11T01:07:17.217090Z"
        },
        "id": "8DQ6ubTF5ucG",
        "outputId": "bba59d0b-7b37-442b-ec9e-452a936bc603",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 10ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6471    0.0880    0.1549       250\n",
            "           1     0.5107    0.9520    0.6648       250\n",
            "\n",
            "    accuracy                         0.5200       500\n",
            "   macro avg     0.5789    0.5200    0.4099       500\n",
            "weighted avg     0.5789    0.5200    0.4099       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHJNPjctXaJ3"
      },
      "source": [
        "## CNN(Word2Vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "eD0UztAwY0c9"
      },
      "outputs": [],
      "source": [
        "num_classes = 2            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/HOLD/\" + \"CNN_One.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzIJ-bLqXZkz",
        "outputId": "5bb0e0d9-c825-433e-bbd6-0fdac5d9bb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 100, 300)          4545300   \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 96, 128)           192128    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4737557 (18.07 MB)\n",
            "Trainable params: 192257 (751.00 KB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiQubmzSYexO",
        "outputId": "5b965365-8363-4aa7-bb36-0db05377c90b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(train_df['enc_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqo4GcvRXor1",
        "outputId": "c1ca02bc-117e-48ba-c5de-550947779416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6905 - accuracy: 0.5156\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_One.h5\n",
            "125/125 [==============================] - 3s 8ms/step - loss: 0.6905 - accuracy: 0.5153 - val_loss: 0.7004 - val_accuracy: 0.4980\n",
            "Epoch 2/100\n",
            "107/125 [========================>.....] - ETA: 0s - loss: 0.6859 - accuracy: 0.5225\n",
            "Epoch 2: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5155 - val_loss: 0.7057 - val_accuracy: 0.4980\n",
            "Epoch 3/100\n",
            "109/125 [=========================>....] - ETA: 0s - loss: 0.6836 - accuracy: 0.5106\n",
            "Epoch 3: val_accuracy improved from 0.49800 to 0.50200, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_One.h5\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.5105 - val_loss: 0.7060 - val_accuracy: 0.5020\n",
            "Epoch 4/100\n",
            "110/125 [=========================>....] - ETA: 0s - loss: 0.6849 - accuracy: 0.5179\n",
            "Epoch 4: val_accuracy improved from 0.50200 to 0.50600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_One.h5\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6847 - accuracy: 0.5173 - val_loss: 0.7121 - val_accuracy: 0.5060\n",
            "Epoch 5/100\n",
            "110/125 [=========================>....] - ETA: 0s - loss: 0.6851 - accuracy: 0.5176\n",
            "Epoch 5: val_accuracy did not improve from 0.50600\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5163 - val_loss: 0.7136 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.5111\n",
            "Epoch 6: val_accuracy did not improve from 0.50600\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5138 - val_loss: 0.7096 - val_accuracy: 0.5040\n",
            "Epoch 7/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.6848 - accuracy: 0.5301\n",
            "Epoch 7: val_accuracy did not improve from 0.50600\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5240 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6822 - accuracy: 0.5245\n",
            "Epoch 8: val_accuracy did not improve from 0.50600\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5255 - val_loss: 0.7074 - val_accuracy: 0.4980\n",
            "Epoch 9/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6824 - accuracy: 0.5237\n",
            "Epoch 9: val_accuracy improved from 0.50600 to 0.50800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_One.h5\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6824 - accuracy: 0.5232 - val_loss: 0.6988 - val_accuracy: 0.5080\n",
            "Epoch 10/100\n",
            "114/125 [==========================>...] - ETA: 0s - loss: 0.6819 - accuracy: 0.5159\n",
            "Epoch 10: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.5192 - val_loss: 0.7046 - val_accuracy: 0.5040\n",
            "Epoch 11/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6826 - accuracy: 0.5265\n",
            "Epoch 11: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5260 - val_loss: 0.7035 - val_accuracy: 0.4980\n",
            "Epoch 12/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.6826 - accuracy: 0.5242\n",
            "Epoch 12: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5275 - val_loss: 0.7128 - val_accuracy: 0.4940\n",
            "Epoch 13/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6818 - accuracy: 0.5213\n",
            "Epoch 13: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5175 - val_loss: 0.7123 - val_accuracy: 0.4960\n",
            "Epoch 14/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.5269\n",
            "Epoch 14: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5263 - val_loss: 0.7080 - val_accuracy: 0.5020\n",
            "Epoch 15/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6805 - accuracy: 0.5221\n",
            "Epoch 15: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5240 - val_loss: 0.7105 - val_accuracy: 0.5020\n",
            "Epoch 16/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.5272\n",
            "Epoch 16: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5257 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6806 - accuracy: 0.5265\n",
            "Epoch 17: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.5278 - val_loss: 0.7084 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.5275\n",
            "Epoch 18: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5275 - val_loss: 0.7063 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.5237\n",
            "Epoch 19: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6805 - accuracy: 0.5253 - val_loss: 0.7071 - val_accuracy: 0.5020\n",
            "Epoch 20/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.6808 - accuracy: 0.5178\n",
            "Epoch 20: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6800 - accuracy: 0.5182 - val_loss: 0.7094 - val_accuracy: 0.5040\n",
            "Epoch 21/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.6793 - accuracy: 0.5296\n",
            "Epoch 21: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6792 - accuracy: 0.5265 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6788 - accuracy: 0.5312\n",
            "Epoch 22: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6785 - accuracy: 0.5300 - val_loss: 0.7101 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.6787 - accuracy: 0.5315\n",
            "Epoch 23: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6790 - accuracy: 0.5257 - val_loss: 0.7075 - val_accuracy: 0.5060\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.5280\n",
            "Epoch 24: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.5280 - val_loss: 0.7025 - val_accuracy: 0.5080\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.5275\n",
            "Epoch 25: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6775 - accuracy: 0.5275 - val_loss: 0.7116 - val_accuracy: 0.5020\n",
            "Epoch 26/100\n",
            "114/125 [==========================>...] - ETA: 0s - loss: 0.6797 - accuracy: 0.5123\n",
            "Epoch 26: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.5140 - val_loss: 0.7096 - val_accuracy: 0.5040\n",
            "Epoch 27/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6781 - accuracy: 0.5263\n",
            "Epoch 27: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.5285 - val_loss: 0.7118 - val_accuracy: 0.4940\n",
            "Epoch 28/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6773 - accuracy: 0.5307\n",
            "Epoch 28: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.5297 - val_loss: 0.7137 - val_accuracy: 0.4980\n",
            "Epoch 29/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6796 - accuracy: 0.5244\n",
            "Epoch 29: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5265 - val_loss: 0.7123 - val_accuracy: 0.5020\n",
            "Epoch 30/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6777 - accuracy: 0.5310\n",
            "Epoch 30: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5285 - val_loss: 0.7070 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6774 - accuracy: 0.5247\n",
            "Epoch 31: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5265 - val_loss: 0.7110 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6782 - accuracy: 0.5265\n",
            "Epoch 32: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5288 - val_loss: 0.7104 - val_accuracy: 0.5040\n",
            "Epoch 33/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6806 - accuracy: 0.5266\n",
            "Epoch 33: val_accuracy did not improve from 0.50800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5275 - val_loss: 0.7076 - val_accuracy: 0.5020\n",
            "Epoch 34/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.5284\n",
            "Epoch 34: val_accuracy improved from 0.50800 to 0.51000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_One.h5\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6767 - accuracy: 0.5290 - val_loss: 0.7028 - val_accuracy: 0.5100\n",
            "Epoch 35/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6781 - accuracy: 0.5279\n",
            "Epoch 35: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5285 - val_loss: 0.7118 - val_accuracy: 0.4980\n",
            "Epoch 36/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.6753 - accuracy: 0.5315\n",
            "Epoch 36: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5318 - val_loss: 0.7156 - val_accuracy: 0.4980\n",
            "Epoch 37/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5085\n",
            "Epoch 37: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5102 - val_loss: 0.7140 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6756 - accuracy: 0.5305\n",
            "Epoch 38: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5293 - val_loss: 0.7090 - val_accuracy: 0.5040\n",
            "Epoch 39/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5305\n",
            "Epoch 39: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.5297 - val_loss: 0.7047 - val_accuracy: 0.5040\n",
            "Epoch 40/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6763 - accuracy: 0.5289\n",
            "Epoch 40: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5293 - val_loss: 0.7154 - val_accuracy: 0.4980\n",
            "Epoch 41/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6768 - accuracy: 0.5299\n",
            "Epoch 41: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.5290 - val_loss: 0.7138 - val_accuracy: 0.4960\n",
            "Epoch 42/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.5318\n",
            "Epoch 42: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5305 - val_loss: 0.7163 - val_accuracy: 0.4960\n",
            "Epoch 43/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6758 - accuracy: 0.5307\n",
            "Epoch 43: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.5282 - val_loss: 0.7119 - val_accuracy: 0.4960\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.5210\n",
            "Epoch 44: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5210 - val_loss: 0.7166 - val_accuracy: 0.4980\n",
            "Epoch 45/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6757 - accuracy: 0.5305\n",
            "Epoch 45: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.5285 - val_loss: 0.7081 - val_accuracy: 0.5020\n",
            "Epoch 46/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5300\n",
            "Epoch 46: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.5300 - val_loss: 0.7087 - val_accuracy: 0.5020\n",
            "Epoch 47/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.5287\n",
            "Epoch 47: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6754 - accuracy: 0.5300 - val_loss: 0.7041 - val_accuracy: 0.5060\n",
            "Epoch 48/100\n",
            "114/125 [==========================>...] - ETA: 0s - loss: 0.6747 - accuracy: 0.5351\n",
            "Epoch 48: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6759 - accuracy: 0.5290 - val_loss: 0.7146 - val_accuracy: 0.4980\n",
            "Epoch 49/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.6753 - accuracy: 0.5288\n",
            "Epoch 49: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6761 - accuracy: 0.5295 - val_loss: 0.7212 - val_accuracy: 0.4940\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.5270\n",
            "Epoch 50: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6773 - accuracy: 0.5270 - val_loss: 0.7114 - val_accuracy: 0.5060\n",
            "Epoch 51/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6755 - accuracy: 0.5328\n",
            "Epoch 51: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6758 - accuracy: 0.5290 - val_loss: 0.7139 - val_accuracy: 0.4980\n",
            "Epoch 52/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.6733 - accuracy: 0.5353\n",
            "Epoch 52: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6744 - accuracy: 0.5315 - val_loss: 0.7038 - val_accuracy: 0.5040\n",
            "Epoch 53/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.6760 - accuracy: 0.5318\n",
            "Epoch 53: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6753 - accuracy: 0.5288 - val_loss: 0.7039 - val_accuracy: 0.5060\n",
            "Epoch 54/100\n",
            "113/125 [==========================>...] - ETA: 0s - loss: 0.6760 - accuracy: 0.5282\n",
            "Epoch 54: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6754 - accuracy: 0.5300 - val_loss: 0.7008 - val_accuracy: 0.5060\n",
            "Epoch 55/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5199\n",
            "Epoch 55: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.5222 - val_loss: 0.7121 - val_accuracy: 0.4960\n",
            "Epoch 56/100\n",
            "111/125 [=========================>....] - ETA: 0s - loss: 0.6778 - accuracy: 0.5293\n",
            "Epoch 56: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5295 - val_loss: 0.7085 - val_accuracy: 0.5020\n",
            "Epoch 57/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6753 - accuracy: 0.5305\n",
            "Epoch 57: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.5303 - val_loss: 0.7161 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6758 - accuracy: 0.5334\n",
            "Epoch 58: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5288 - val_loss: 0.7139 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6748 - accuracy: 0.5227\n",
            "Epoch 59: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.5185 - val_loss: 0.7105 - val_accuracy: 0.5020\n",
            "Epoch 60/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.6736 - accuracy: 0.5139\n",
            "Epoch 60: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.5165 - val_loss: 0.7014 - val_accuracy: 0.5100\n",
            "Epoch 61/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6759 - accuracy: 0.5284\n",
            "Epoch 61: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5310 - val_loss: 0.7096 - val_accuracy: 0.5040\n",
            "Epoch 62/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.5328\n",
            "Epoch 62: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5310 - val_loss: 0.7083 - val_accuracy: 0.5060\n",
            "Epoch 63/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6757 - accuracy: 0.5289\n",
            "Epoch 63: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.5303 - val_loss: 0.7165 - val_accuracy: 0.5040\n",
            "Epoch 64/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6741 - accuracy: 0.5276\n",
            "Epoch 64: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.5285 - val_loss: 0.7078 - val_accuracy: 0.5060\n",
            "Epoch 65/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6738 - accuracy: 0.5347\n",
            "Epoch 65: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5307 - val_loss: 0.7097 - val_accuracy: 0.5020\n",
            "Epoch 66/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6750 - accuracy: 0.5284\n",
            "Epoch 66: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.5297 - val_loss: 0.7169 - val_accuracy: 0.4980\n",
            "Epoch 67/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6749 - accuracy: 0.5233\n",
            "Epoch 67: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.5290 - val_loss: 0.7134 - val_accuracy: 0.5040\n",
            "Epoch 68/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6743 - accuracy: 0.5227\n",
            "Epoch 68: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5228 - val_loss: 0.7107 - val_accuracy: 0.5060\n",
            "Epoch 69/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6721 - accuracy: 0.5297\n",
            "Epoch 69: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.5297 - val_loss: 0.7222 - val_accuracy: 0.4980\n",
            "Epoch 70/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6759 - accuracy: 0.5307\n",
            "Epoch 70: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5297 - val_loss: 0.7122 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6743 - accuracy: 0.5265\n",
            "Epoch 71: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.5300 - val_loss: 0.7131 - val_accuracy: 0.5060\n",
            "Epoch 72/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6745 - accuracy: 0.5229\n",
            "Epoch 72: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5235 - val_loss: 0.7122 - val_accuracy: 0.5040\n",
            "Epoch 73/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.5318\n",
            "Epoch 73: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.5312 - val_loss: 0.7112 - val_accuracy: 0.5040\n",
            "Epoch 74/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.5343\n",
            "Epoch 74: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5312 - val_loss: 0.7145 - val_accuracy: 0.5020\n",
            "Epoch 75/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6729 - accuracy: 0.5297\n",
            "Epoch 75: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.5297 - val_loss: 0.7171 - val_accuracy: 0.5080\n",
            "Epoch 76/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6744 - accuracy: 0.5271\n",
            "Epoch 76: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6750 - accuracy: 0.5255 - val_loss: 0.7161 - val_accuracy: 0.5020\n",
            "Epoch 77/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6739 - accuracy: 0.5272\n",
            "Epoch 77: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6738 - accuracy: 0.5305 - val_loss: 0.7183 - val_accuracy: 0.5060\n",
            "Epoch 78/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5325\n",
            "Epoch 78: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6758 - accuracy: 0.5322 - val_loss: 0.7142 - val_accuracy: 0.4980\n",
            "Epoch 79/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5254\n",
            "Epoch 79: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6740 - accuracy: 0.5260 - val_loss: 0.7164 - val_accuracy: 0.5040\n",
            "Epoch 80/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.5255\n",
            "Epoch 80: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6737 - accuracy: 0.5255 - val_loss: 0.7179 - val_accuracy: 0.4960\n",
            "Epoch 81/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6739 - accuracy: 0.5200\n",
            "Epoch 81: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6738 - accuracy: 0.5215 - val_loss: 0.7089 - val_accuracy: 0.5040\n",
            "Epoch 82/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.5266\n",
            "Epoch 82: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6741 - accuracy: 0.5280 - val_loss: 0.7123 - val_accuracy: 0.5040\n",
            "Epoch 83/100\n",
            "113/125 [==========================>...] - ETA: 0s - loss: 0.6753 - accuracy: 0.5332\n",
            "Epoch 83: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6744 - accuracy: 0.5293 - val_loss: 0.7147 - val_accuracy: 0.5020\n",
            "Epoch 84/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6746 - accuracy: 0.5176\n",
            "Epoch 84: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5220 - val_loss: 0.7149 - val_accuracy: 0.5080\n",
            "Epoch 85/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6725 - accuracy: 0.5297\n",
            "Epoch 85: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5293 - val_loss: 0.7185 - val_accuracy: 0.4980\n",
            "Epoch 86/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5287\n",
            "Epoch 86: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.5290 - val_loss: 0.7178 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6743 - accuracy: 0.5230\n",
            "Epoch 87: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.5228 - val_loss: 0.7193 - val_accuracy: 0.4980\n",
            "Epoch 88/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5305\n",
            "Epoch 88: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5290 - val_loss: 0.7141 - val_accuracy: 0.5040\n",
            "Epoch 89/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6718 - accuracy: 0.5334\n",
            "Epoch 89: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.5320 - val_loss: 0.7161 - val_accuracy: 0.5040\n",
            "Epoch 90/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.5312\n",
            "Epoch 90: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5320 - val_loss: 0.7164 - val_accuracy: 0.5020\n",
            "Epoch 91/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6732 - accuracy: 0.5291\n",
            "Epoch 91: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.5310 - val_loss: 0.7106 - val_accuracy: 0.5040\n",
            "Epoch 92/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6742 - accuracy: 0.5330\n",
            "Epoch 92: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5318 - val_loss: 0.7107 - val_accuracy: 0.5020\n",
            "Epoch 93/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.5126\n",
            "Epoch 93: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.5123 - val_loss: 0.7161 - val_accuracy: 0.5020\n",
            "Epoch 94/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6724 - accuracy: 0.5331\n",
            "Epoch 94: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.5312 - val_loss: 0.7140 - val_accuracy: 0.5020\n",
            "Epoch 95/100\n",
            "112/125 [=========================>....] - ETA: 0s - loss: 0.6749 - accuracy: 0.5285\n",
            "Epoch 95: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5295 - val_loss: 0.7171 - val_accuracy: 0.5060\n",
            "Epoch 96/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6716 - accuracy: 0.5334\n",
            "Epoch 96: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5318 - val_loss: 0.7161 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6730 - accuracy: 0.5273\n",
            "Epoch 97: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.5285 - val_loss: 0.7221 - val_accuracy: 0.5040\n",
            "Epoch 98/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6733 - accuracy: 0.5283\n",
            "Epoch 98: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.5322 - val_loss: 0.7113 - val_accuracy: 0.5060\n",
            "Epoch 99/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6740 - accuracy: 0.5292\n",
            "Epoch 99: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5297 - val_loss: 0.7074 - val_accuracy: 0.5080\n",
            "Epoch 100/100\n",
            "113/125 [==========================>...] - ETA: 0s - loss: 0.6724 - accuracy: 0.5227\n",
            "Epoch 100: val_accuracy did not improve from 0.51000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.5280 - val_loss: 0.7206 - val_accuracy: 0.5040\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX1Wg8LLZJy2",
        "outputId": "2e79e91a-6dff-4194-859a-9ce847c19b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5714    0.0800    0.1404       250\n",
            "           1     0.5054    0.9400    0.6573       250\n",
            "\n",
            "    accuracy                         0.5100       500\n",
            "   macro avg     0.5384    0.5100    0.3988       500\n",
            "weighted avg     0.5384    0.5100    0.3988       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjWAhNyoZSFX"
      },
      "source": [
        "## CNN + BiLSTM(Word2Vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "WR8yP5HzZhgm"
      },
      "outputs": [],
      "source": [
        "num_classes = 2            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/HOLD/\" + \"CNN_BiLSTM.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bCMx5ETZRbn",
        "outputId": "ae12dc8f-7fde-4385-b0c6-e04f6a1a8720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 100, 300)          4545300   \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 96, 128)           192128    \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 19, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 19, 400)           526400    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 7600)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 7601      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5271429 (20.11 MB)\n",
            "Trainable params: 726129 (2.77 MB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix],trainable=False, input_length = max_len),\n",
        "tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "tf.keras.layers.MaxPooling1D(5),\n",
        "tf.keras.layers.Bidirectional(LSTM(units = 200,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Dil1cSZpvG",
        "outputId": "03aa995a-20ae-4bd6-a8dd-e42e05e9c6b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5050\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51200, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 5s 15ms/step - loss: 0.6916 - accuracy: 0.5045 - val_loss: 0.6936 - val_accuracy: 0.5120\n",
            "Epoch 2/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6891 - accuracy: 0.5196\n",
            "Epoch 2: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6889 - accuracy: 0.5203 - val_loss: 0.6954 - val_accuracy: 0.4960\n",
            "Epoch 3/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.5202\n",
            "Epoch 3: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6875 - accuracy: 0.5200 - val_loss: 0.6973 - val_accuracy: 0.5100\n",
            "Epoch 4/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6859 - accuracy: 0.5062\n",
            "Epoch 4: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6853 - accuracy: 0.5060 - val_loss: 0.7087 - val_accuracy: 0.4920\n",
            "Epoch 5/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.5154\n",
            "Epoch 5: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6855 - accuracy: 0.5163 - val_loss: 0.6998 - val_accuracy: 0.5060\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.5090\n",
            "Epoch 6: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6828 - accuracy: 0.5090 - val_loss: 0.7004 - val_accuracy: 0.5100\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.5178\n",
            "Epoch 7: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.5178 - val_loss: 0.7015 - val_accuracy: 0.4940\n",
            "Epoch 8/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6795 - accuracy: 0.5242\n",
            "Epoch 8: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6790 - accuracy: 0.5247 - val_loss: 0.7050 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.5210\n",
            "Epoch 9: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6771 - accuracy: 0.5210 - val_loss: 0.6946 - val_accuracy: 0.4960\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.5232\n",
            "Epoch 10: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6768 - accuracy: 0.5232 - val_loss: 0.6995 - val_accuracy: 0.5080\n",
            "Epoch 11/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5240\n",
            "Epoch 11: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6751 - accuracy: 0.5238 - val_loss: 0.7084 - val_accuracy: 0.5060\n",
            "Epoch 12/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6730 - accuracy: 0.5275\n",
            "Epoch 12: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6731 - accuracy: 0.5300 - val_loss: 0.6985 - val_accuracy: 0.5100\n",
            "Epoch 13/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5259\n",
            "Epoch 13: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6733 - accuracy: 0.5268 - val_loss: 0.7031 - val_accuracy: 0.4920\n",
            "Epoch 14/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6704 - accuracy: 0.5244\n",
            "Epoch 14: val_accuracy did not improve from 0.51200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6714 - accuracy: 0.5232 - val_loss: 0.6987 - val_accuracy: 0.5100\n",
            "Epoch 15/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6679 - accuracy: 0.5368\n",
            "Epoch 15: val_accuracy improved from 0.51200 to 0.51800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6693 - accuracy: 0.5345 - val_loss: 0.6997 - val_accuracy: 0.5180\n",
            "Epoch 16/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6696 - accuracy: 0.5355\n",
            "Epoch 16: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6694 - accuracy: 0.5335 - val_loss: 0.7026 - val_accuracy: 0.5080\n",
            "Epoch 17/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6688 - accuracy: 0.5312\n",
            "Epoch 17: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6685 - accuracy: 0.5322 - val_loss: 0.7025 - val_accuracy: 0.5100\n",
            "Epoch 18/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6658 - accuracy: 0.5343\n",
            "Epoch 18: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6659 - accuracy: 0.5332 - val_loss: 0.7066 - val_accuracy: 0.4920\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.5318\n",
            "Epoch 19: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6656 - accuracy: 0.5318 - val_loss: 0.7039 - val_accuracy: 0.5140\n",
            "Epoch 20/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6656 - accuracy: 0.5325\n",
            "Epoch 20: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6645 - accuracy: 0.5343 - val_loss: 0.7165 - val_accuracy: 0.5140\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.5315\n",
            "Epoch 21: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6645 - accuracy: 0.5315 - val_loss: 0.7121 - val_accuracy: 0.5040\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.5362\n",
            "Epoch 22: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6636 - accuracy: 0.5362 - val_loss: 0.7121 - val_accuracy: 0.4900\n",
            "Epoch 23/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.5404\n",
            "Epoch 23: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6641 - accuracy: 0.5403 - val_loss: 0.7111 - val_accuracy: 0.5080\n",
            "Epoch 24/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6622 - accuracy: 0.5264\n",
            "Epoch 24: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6626 - accuracy: 0.5257 - val_loss: 0.7071 - val_accuracy: 0.5100\n",
            "Epoch 25/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6625 - accuracy: 0.5307\n",
            "Epoch 25: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6621 - accuracy: 0.5305 - val_loss: 0.7140 - val_accuracy: 0.5080\n",
            "Epoch 26/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6611 - accuracy: 0.5479\n",
            "Epoch 26: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6614 - accuracy: 0.5465 - val_loss: 0.7086 - val_accuracy: 0.5080\n",
            "Epoch 27/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.5384\n",
            "Epoch 27: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6626 - accuracy: 0.5383 - val_loss: 0.7117 - val_accuracy: 0.5100\n",
            "Epoch 28/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6589 - accuracy: 0.5252\n",
            "Epoch 28: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6594 - accuracy: 0.5245 - val_loss: 0.7202 - val_accuracy: 0.5080\n",
            "Epoch 29/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6607 - accuracy: 0.5347\n",
            "Epoch 29: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6607 - accuracy: 0.5345 - val_loss: 0.7191 - val_accuracy: 0.5020\n",
            "Epoch 30/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6587 - accuracy: 0.5378\n",
            "Epoch 30: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6584 - accuracy: 0.5380 - val_loss: 0.7138 - val_accuracy: 0.5120\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.5487\n",
            "Epoch 31: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6587 - accuracy: 0.5487 - val_loss: 0.7236 - val_accuracy: 0.5040\n",
            "Epoch 32/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6575 - accuracy: 0.5362\n",
            "Epoch 32: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6570 - accuracy: 0.5380 - val_loss: 0.7251 - val_accuracy: 0.5080\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.5330\n",
            "Epoch 33: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6589 - accuracy: 0.5330 - val_loss: 0.7117 - val_accuracy: 0.5120\n",
            "Epoch 34/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.5415\n",
            "Epoch 34: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6566 - accuracy: 0.5403 - val_loss: 0.7282 - val_accuracy: 0.5120\n",
            "Epoch 35/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6573 - accuracy: 0.5343\n",
            "Epoch 35: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6575 - accuracy: 0.5335 - val_loss: 0.7289 - val_accuracy: 0.4860\n",
            "Epoch 36/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6555 - accuracy: 0.5409\n",
            "Epoch 36: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6559 - accuracy: 0.5397 - val_loss: 0.7284 - val_accuracy: 0.5080\n",
            "Epoch 37/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6566 - accuracy: 0.5276\n",
            "Epoch 37: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6571 - accuracy: 0.5312 - val_loss: 0.7297 - val_accuracy: 0.5100\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6556 - accuracy: 0.5400\n",
            "Epoch 38: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6556 - accuracy: 0.5400 - val_loss: 0.7299 - val_accuracy: 0.4860\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.5460\n",
            "Epoch 39: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6553 - accuracy: 0.5460 - val_loss: 0.7134 - val_accuracy: 0.5140\n",
            "Epoch 40/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.5187\n",
            "Epoch 40: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6573 - accuracy: 0.5192 - val_loss: 0.7226 - val_accuracy: 0.5100\n",
            "Epoch 41/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6548 - accuracy: 0.5378\n",
            "Epoch 41: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6550 - accuracy: 0.5385 - val_loss: 0.7259 - val_accuracy: 0.5080\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.5293\n",
            "Epoch 42: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6557 - accuracy: 0.5293 - val_loss: 0.7313 - val_accuracy: 0.5060\n",
            "Epoch 43/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6558 - accuracy: 0.5394\n",
            "Epoch 43: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6558 - accuracy: 0.5418 - val_loss: 0.7342 - val_accuracy: 0.4900\n",
            "Epoch 44/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6547 - accuracy: 0.5376\n",
            "Epoch 44: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6548 - accuracy: 0.5365 - val_loss: 0.7383 - val_accuracy: 0.5100\n",
            "Epoch 45/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6552 - accuracy: 0.5385\n",
            "Epoch 45: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6545 - accuracy: 0.5410 - val_loss: 0.7393 - val_accuracy: 0.4940\n",
            "Epoch 46/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6544 - accuracy: 0.5429\n",
            "Epoch 46: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6534 - accuracy: 0.5435 - val_loss: 0.7401 - val_accuracy: 0.5100\n",
            "Epoch 47/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.5338\n",
            "Epoch 47: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6555 - accuracy: 0.5318 - val_loss: 0.7393 - val_accuracy: 0.4920\n",
            "Epoch 48/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.5240\n",
            "Epoch 48: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6542 - accuracy: 0.5257 - val_loss: 0.7463 - val_accuracy: 0.4940\n",
            "Epoch 49/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.5359\n",
            "Epoch 49: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6542 - accuracy: 0.5347 - val_loss: 0.7423 - val_accuracy: 0.4900\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.5370\n",
            "Epoch 50: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6545 - accuracy: 0.5370 - val_loss: 0.7399 - val_accuracy: 0.5120\n",
            "Epoch 51/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6563 - accuracy: 0.5382\n",
            "Epoch 51: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6563 - accuracy: 0.5347 - val_loss: 0.7387 - val_accuracy: 0.5100\n",
            "Epoch 52/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.5320\n",
            "Epoch 52: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6553 - accuracy: 0.5315 - val_loss: 0.7482 - val_accuracy: 0.5100\n",
            "Epoch 53/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.5370\n",
            "Epoch 53: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6525 - accuracy: 0.5375 - val_loss: 0.7499 - val_accuracy: 0.4940\n",
            "Epoch 54/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.5408\n",
            "Epoch 54: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6527 - accuracy: 0.5395 - val_loss: 0.7499 - val_accuracy: 0.5100\n",
            "Epoch 55/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.5387\n",
            "Epoch 55: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.5390 - val_loss: 0.7437 - val_accuracy: 0.5100\n",
            "Epoch 56/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6535 - accuracy: 0.5395\n",
            "Epoch 56: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6531 - accuracy: 0.5403 - val_loss: 0.7461 - val_accuracy: 0.4920\n",
            "Epoch 57/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.5372\n",
            "Epoch 57: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.5343 - val_loss: 0.7480 - val_accuracy: 0.4940\n",
            "Epoch 58/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6497 - accuracy: 0.5370\n",
            "Epoch 58: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6506 - accuracy: 0.5330 - val_loss: 0.7536 - val_accuracy: 0.5100\n",
            "Epoch 59/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6510 - accuracy: 0.5307\n",
            "Epoch 59: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.5345 - val_loss: 0.7452 - val_accuracy: 0.5120\n",
            "Epoch 60/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6509 - accuracy: 0.5315\n",
            "Epoch 60: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6517 - accuracy: 0.5312 - val_loss: 0.7434 - val_accuracy: 0.5160\n",
            "Epoch 61/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.5446\n",
            "Epoch 61: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6532 - accuracy: 0.5460 - val_loss: 0.7383 - val_accuracy: 0.5100\n",
            "Epoch 62/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6526 - accuracy: 0.5294\n",
            "Epoch 62: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6523 - accuracy: 0.5290 - val_loss: 0.7556 - val_accuracy: 0.4940\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.5297\n",
            "Epoch 63: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6526 - accuracy: 0.5297 - val_loss: 0.7526 - val_accuracy: 0.4920\n",
            "Epoch 64/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6517 - accuracy: 0.5331\n",
            "Epoch 64: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6510 - accuracy: 0.5335 - val_loss: 0.7462 - val_accuracy: 0.4940\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.5225\n",
            "Epoch 65: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6503 - accuracy: 0.5225 - val_loss: 0.7497 - val_accuracy: 0.5160\n",
            "Epoch 66/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6513 - accuracy: 0.5275\n",
            "Epoch 66: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6512 - accuracy: 0.5268 - val_loss: 0.7484 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.5442\n",
            "Epoch 67: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6514 - accuracy: 0.5428 - val_loss: 0.7580 - val_accuracy: 0.4920\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.5245\n",
            "Epoch 68: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.5245 - val_loss: 0.7544 - val_accuracy: 0.4960\n",
            "Epoch 69/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6486 - accuracy: 0.5431\n",
            "Epoch 69: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6493 - accuracy: 0.5420 - val_loss: 0.7507 - val_accuracy: 0.5080\n",
            "Epoch 70/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6517 - accuracy: 0.5354\n",
            "Epoch 70: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6510 - accuracy: 0.5368 - val_loss: 0.7588 - val_accuracy: 0.4960\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.5303\n",
            "Epoch 71: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6505 - accuracy: 0.5303 - val_loss: 0.7487 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6509 - accuracy: 0.5424\n",
            "Epoch 72: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.5420 - val_loss: 0.7505 - val_accuracy: 0.5100\n",
            "Epoch 73/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.5396\n",
            "Epoch 73: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6515 - accuracy: 0.5390 - val_loss: 0.7397 - val_accuracy: 0.5100\n",
            "Epoch 74/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.5434\n",
            "Epoch 74: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6508 - accuracy: 0.5433 - val_loss: 0.7480 - val_accuracy: 0.4960\n",
            "Epoch 75/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6493 - accuracy: 0.5354\n",
            "Epoch 75: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.5357 - val_loss: 0.7601 - val_accuracy: 0.5060\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.5282\n",
            "Epoch 76: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6506 - accuracy: 0.5282 - val_loss: 0.7452 - val_accuracy: 0.4940\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.5422\n",
            "Epoch 77: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.5422 - val_loss: 0.7504 - val_accuracy: 0.5120\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.5435\n",
            "Epoch 78: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6487 - accuracy: 0.5435 - val_loss: 0.7620 - val_accuracy: 0.5140\n",
            "Epoch 79/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.5364\n",
            "Epoch 79: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6494 - accuracy: 0.5383 - val_loss: 0.7595 - val_accuracy: 0.5120\n",
            "Epoch 80/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6488 - accuracy: 0.5401\n",
            "Epoch 80: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6497 - accuracy: 0.5393 - val_loss: 0.7514 - val_accuracy: 0.5120\n",
            "Epoch 81/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6502 - accuracy: 0.5461\n",
            "Epoch 81: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6503 - accuracy: 0.5480 - val_loss: 0.7592 - val_accuracy: 0.5120\n",
            "Epoch 82/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6492 - accuracy: 0.5414\n",
            "Epoch 82: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.5403 - val_loss: 0.7620 - val_accuracy: 0.4960\n",
            "Epoch 83/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6495 - accuracy: 0.5389\n",
            "Epoch 83: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6495 - accuracy: 0.5425 - val_loss: 0.7645 - val_accuracy: 0.4960\n",
            "Epoch 84/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6494 - accuracy: 0.5480\n",
            "Epoch 84: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6496 - accuracy: 0.5480 - val_loss: 0.7540 - val_accuracy: 0.5120\n",
            "Epoch 85/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.5398\n",
            "Epoch 85: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6485 - accuracy: 0.5397 - val_loss: 0.7652 - val_accuracy: 0.4940\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.5312\n",
            "Epoch 86: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.5312 - val_loss: 0.7586 - val_accuracy: 0.5100\n",
            "Epoch 87/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.6495 - accuracy: 0.5383\n",
            "Epoch 87: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6494 - accuracy: 0.5370 - val_loss: 0.7502 - val_accuracy: 0.5060\n",
            "Epoch 88/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.6497 - accuracy: 0.5368\n",
            "Epoch 88: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6499 - accuracy: 0.5368 - val_loss: 0.7536 - val_accuracy: 0.5100\n",
            "Epoch 89/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6482 - accuracy: 0.5369\n",
            "Epoch 89: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6491 - accuracy: 0.5355 - val_loss: 0.7590 - val_accuracy: 0.5080\n",
            "Epoch 90/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6484 - accuracy: 0.5315\n",
            "Epoch 90: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6487 - accuracy: 0.5343 - val_loss: 0.7538 - val_accuracy: 0.5080\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.5380\n",
            "Epoch 91: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6488 - accuracy: 0.5380 - val_loss: 0.7523 - val_accuracy: 0.5120\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6500 - accuracy: 0.5490\n",
            "Epoch 92: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6500 - accuracy: 0.5490 - val_loss: 0.7601 - val_accuracy: 0.4900\n",
            "Epoch 93/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6513 - accuracy: 0.5427\n",
            "Epoch 93: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.6531 - accuracy: 0.5403 - val_loss: 0.7527 - val_accuracy: 0.5020\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.5340\n",
            "Epoch 94: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6494 - accuracy: 0.5340 - val_loss: 0.7447 - val_accuracy: 0.5100\n",
            "Epoch 95/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6501 - accuracy: 0.5315\n",
            "Epoch 95: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6497 - accuracy: 0.5312 - val_loss: 0.7458 - val_accuracy: 0.4900\n",
            "Epoch 96/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6473 - accuracy: 0.5326\n",
            "Epoch 96: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.6476 - accuracy: 0.5328 - val_loss: 0.7628 - val_accuracy: 0.5040\n",
            "Epoch 97/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6484 - accuracy: 0.5448\n",
            "Epoch 97: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6489 - accuracy: 0.5435 - val_loss: 0.7412 - val_accuracy: 0.5040\n",
            "Epoch 98/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6492 - accuracy: 0.5343\n",
            "Epoch 98: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.5362 - val_loss: 0.7542 - val_accuracy: 0.5060\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.5368\n",
            "Epoch 99: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6505 - accuracy: 0.5368 - val_loss: 0.7380 - val_accuracy: 0.5100\n",
            "Epoch 100/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.6480 - accuracy: 0.5339\n",
            "Epoch 100: val_accuracy did not improve from 0.51800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6484 - accuracy: 0.5345 - val_loss: 0.7482 - val_accuracy: 0.5120\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF7HPTW2Z5gN",
        "outputId": "31b7f453-53ef-4acb-c4af-2182d3b675e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 4ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6098    0.1000    0.1718       250\n",
            "           1     0.5098    0.9360    0.6601       250\n",
            "\n",
            "    accuracy                         0.5180       500\n",
            "   macro avg     0.5598    0.5180    0.4160       500\n",
            "weighted avg     0.5598    0.5180    0.4160       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OmJBY9m53_D"
      },
      "source": [
        "## FastText CNN + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:09:08.580582Z",
          "iopub.status.busy": "2023-12-11T01:09:08.579889Z",
          "iopub.status.idle": "2023-12-11T01:09:09.392782Z",
          "shell.execute_reply": "2023-12-11T01:09:09.391793Z",
          "shell.execute_reply.started": "2023-12-11T01:09:08.580550Z"
        },
        "id": "0OGntAMr53_E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ml.300.vec.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:09:11.680453Z",
          "iopub.status.busy": "2023-12-11T01:09:11.680019Z",
          "iopub.status.idle": "2023-12-11T01:12:15.046100Z",
          "shell.execute_reply": "2023-12-11T01:12:15.045238Z",
          "shell.execute_reply.started": "2023-12-11T01:09:11.680421Z"
        },
        "id": "RtggwCbs53_F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "vocab_and_vectors = {}\n",
        "# put words as dict indexes and vectors as words values\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values [0].decode('utf-8')\n",
        "  vector = np.asarray(values[1:], dtype='float32')\n",
        "  vocab_and_vectors[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:13:59.898016Z",
          "iopub.status.busy": "2023-12-11T01:13:59.897072Z",
          "iopub.status.idle": "2023-12-11T01:13:59.925135Z",
          "shell.execute_reply": "2023-12-11T01:13:59.924177Z",
          "shell.execute_reply.started": "2023-12-11T01:13:59.897978Z"
        },
        "id": "FJHx88tX53_G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = vocab_and_vectors.get(word)\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:14:21.232818Z",
          "iopub.status.busy": "2023-12-11T01:14:21.232453Z",
          "iopub.status.idle": "2023-12-11T01:14:21.911194Z",
          "shell.execute_reply": "2023-12-11T01:14:21.910283Z",
          "shell.execute_reply.started": "2023-12-11T01:14:21.232787Z"
        },
        "id": "X2EkiS6h53_H",
        "outputId": "dcd863d9-8204-41b5-f614-b2a065ad16f2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 80, 300)           4545300   \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 76, 128)           192128    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 15, 128)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 15, 400)           526400    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6000)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 6001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5269829 (20.10 MB)\n",
            "Trainable params: 724529 (2.76 MB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "# filepath = '/content/drive/MyDrive/Colab Notebooks/HOLD/' +\"CNN_BiLSTMFastTExt.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model2 = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix],trainable=False, input_length = max_len),\n",
        "tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "tf.keras.layers.MaxPooling1D(5),\n",
        "tf.keras.layers.Bidirectional(LSTM(units = 200,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:14:30.704963Z",
          "iopub.status.busy": "2023-12-11T01:14:30.704271Z",
          "iopub.status.idle": "2023-12-11T01:15:04.531763Z",
          "shell.execute_reply": "2023-12-11T01:15:04.530934Z",
          "shell.execute_reply.started": "2023-12-11T01:14:30.704932Z"
        },
        "id": "5e0JhE9053_I",
        "outputId": "9e85893f-ad0e-45d4-95fa-e353c424d0a4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.6705 - accuracy: 0.5777\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 66s 20ms/step - loss: 0.6702 - accuracy: 0.5780 - val_loss: 0.6899 - val_accuracy: 0.4880\n",
            "Epoch 2/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.6686\n",
            "Epoch 2: val_accuracy did not improve from 0.48800\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.6025 - accuracy: 0.6675 - val_loss: 0.7301 - val_accuracy: 0.4720\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.7025\n",
            "Epoch 3: val_accuracy improved from 0.48800 to 0.49000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.7025 - val_loss: 0.7454 - val_accuracy: 0.4900\n",
            "Epoch 4/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.5209 - accuracy: 0.7221\n",
            "Epoch 4: val_accuracy improved from 0.49000 to 0.50200, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.5196 - accuracy: 0.7235 - val_loss: 0.7581 - val_accuracy: 0.5020\n",
            "Epoch 5/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.4609 - accuracy: 0.7529\n",
            "Epoch 5: val_accuracy improved from 0.50200 to 0.59600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_BiLSTM.h5\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.4600 - accuracy: 0.7515 - val_loss: 0.8289 - val_accuracy: 0.5960\n",
            "Epoch 6/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.7622\n",
            "Epoch 6: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.4333 - accuracy: 0.7615 - val_loss: 0.8278 - val_accuracy: 0.4780\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.7742\n",
            "Epoch 7: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.4060 - accuracy: 0.7742 - val_loss: 0.9541 - val_accuracy: 0.4800\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.7812\n",
            "Epoch 8: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3946 - accuracy: 0.7812 - val_loss: 0.9215 - val_accuracy: 0.4980\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.7937\n",
            "Epoch 9: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3705 - accuracy: 0.7937 - val_loss: 0.9926 - val_accuracy: 0.4740\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.7972\n",
            "Epoch 10: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3620 - accuracy: 0.7972 - val_loss: 1.0497 - val_accuracy: 0.5060\n",
            "Epoch 11/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.3555 - accuracy: 0.7975\n",
            "Epoch 11: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.3524 - accuracy: 0.7995 - val_loss: 1.2561 - val_accuracy: 0.4780\n",
            "Epoch 12/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.8024\n",
            "Epoch 12: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3491 - accuracy: 0.8027 - val_loss: 1.0418 - val_accuracy: 0.4800\n",
            "Epoch 13/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.8023\n",
            "Epoch 13: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3431 - accuracy: 0.8037 - val_loss: 1.0978 - val_accuracy: 0.4900\n",
            "Epoch 14/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.3310 - accuracy: 0.8096\n",
            "Epoch 14: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3318 - accuracy: 0.8083 - val_loss: 1.0239 - val_accuracy: 0.5060\n",
            "Epoch 15/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.3284 - accuracy: 0.8125\n",
            "Epoch 15: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3303 - accuracy: 0.8108 - val_loss: 1.0534 - val_accuracy: 0.5060\n",
            "Epoch 16/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8130\n",
            "Epoch 16: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3299 - accuracy: 0.8138 - val_loss: 1.3550 - val_accuracy: 0.4740\n",
            "Epoch 17/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8125\n",
            "Epoch 17: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3248 - accuracy: 0.8108 - val_loss: 0.9968 - val_accuracy: 0.5220\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8185\n",
            "Epoch 18: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3123 - accuracy: 0.8185 - val_loss: 1.0608 - val_accuracy: 0.4880\n",
            "Epoch 19/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8215\n",
            "Epoch 19: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3073 - accuracy: 0.8213 - val_loss: 1.1926 - val_accuracy: 0.4860\n",
            "Epoch 20/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.3117 - accuracy: 0.8191\n",
            "Epoch 20: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3142 - accuracy: 0.8180 - val_loss: 1.3199 - val_accuracy: 0.4760\n",
            "Epoch 21/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.8189\n",
            "Epoch 21: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3023 - accuracy: 0.8185 - val_loss: 1.2189 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8257\n",
            "Epoch 22: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2963 - accuracy: 0.8257 - val_loss: 1.2975 - val_accuracy: 0.5020\n",
            "Epoch 23/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8252\n",
            "Epoch 23: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3014 - accuracy: 0.8257 - val_loss: 1.9233 - val_accuracy: 0.4600\n",
            "Epoch 24/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.8233\n",
            "Epoch 24: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3024 - accuracy: 0.8235 - val_loss: 1.1431 - val_accuracy: 0.5020\n",
            "Epoch 25/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2976 - accuracy: 0.8186\n",
            "Epoch 25: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2990 - accuracy: 0.8155 - val_loss: 1.4507 - val_accuracy: 0.4820\n",
            "Epoch 26/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.8243\n",
            "Epoch 26: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3000 - accuracy: 0.8220 - val_loss: 1.4048 - val_accuracy: 0.4860\n",
            "Epoch 27/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2967 - accuracy: 0.8257\n",
            "Epoch 27: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2956 - accuracy: 0.8263 - val_loss: 1.3746 - val_accuracy: 0.4920\n",
            "Epoch 28/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.3012 - accuracy: 0.8245\n",
            "Epoch 28: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3007 - accuracy: 0.8242 - val_loss: 1.4569 - val_accuracy: 0.4780\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8232\n",
            "Epoch 29: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3068 - accuracy: 0.8232 - val_loss: 1.5779 - val_accuracy: 0.4740\n",
            "Epoch 30/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2951 - accuracy: 0.8237\n",
            "Epoch 30: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2937 - accuracy: 0.8248 - val_loss: 1.3708 - val_accuracy: 0.4720\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.8207\n",
            "Epoch 31: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3003 - accuracy: 0.8207 - val_loss: 1.4293 - val_accuracy: 0.4760\n",
            "Epoch 32/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.2891 - accuracy: 0.8268\n",
            "Epoch 32: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2899 - accuracy: 0.8263 - val_loss: 1.5470 - val_accuracy: 0.4840\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.8322\n",
            "Epoch 33: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2803 - accuracy: 0.8322 - val_loss: 1.6130 - val_accuracy: 0.4820\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.8298\n",
            "Epoch 34: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2824 - accuracy: 0.8298 - val_loss: 1.6639 - val_accuracy: 0.4740\n",
            "Epoch 35/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2957 - accuracy: 0.8254\n",
            "Epoch 35: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2941 - accuracy: 0.8267 - val_loss: 1.4523 - val_accuracy: 0.4960\n",
            "Epoch 36/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.8264\n",
            "Epoch 36: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2906 - accuracy: 0.8255 - val_loss: 1.5727 - val_accuracy: 0.4740\n",
            "Epoch 37/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8361\n",
            "Epoch 37: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2783 - accuracy: 0.8353 - val_loss: 2.0467 - val_accuracy: 0.4600\n",
            "Epoch 38/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8206\n",
            "Epoch 38: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.8215 - val_loss: 1.4919 - val_accuracy: 0.4640\n",
            "Epoch 39/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.8298\n",
            "Epoch 39: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2822 - accuracy: 0.8310 - val_loss: 1.4736 - val_accuracy: 0.4840\n",
            "Epoch 40/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.8290\n",
            "Epoch 40: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2864 - accuracy: 0.8275 - val_loss: 1.4187 - val_accuracy: 0.4780\n",
            "Epoch 41/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8347\n",
            "Epoch 41: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2776 - accuracy: 0.8330 - val_loss: 1.6840 - val_accuracy: 0.4800\n",
            "Epoch 42/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2732 - accuracy: 0.8331\n",
            "Epoch 42: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2740 - accuracy: 0.8330 - val_loss: 1.9377 - val_accuracy: 0.4600\n",
            "Epoch 43/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.8337\n",
            "Epoch 43: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2767 - accuracy: 0.8335 - val_loss: 1.8160 - val_accuracy: 0.4660\n",
            "Epoch 44/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2753 - accuracy: 0.8307\n",
            "Epoch 44: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2781 - accuracy: 0.8310 - val_loss: 1.6607 - val_accuracy: 0.4700\n",
            "Epoch 45/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.8309\n",
            "Epoch 45: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2815 - accuracy: 0.8313 - val_loss: 1.4642 - val_accuracy: 0.4680\n",
            "Epoch 46/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.8314\n",
            "Epoch 46: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2738 - accuracy: 0.8310 - val_loss: 1.7876 - val_accuracy: 0.4660\n",
            "Epoch 47/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2740 - accuracy: 0.8323\n",
            "Epoch 47: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2791 - accuracy: 0.8305 - val_loss: 1.9775 - val_accuracy: 0.4580\n",
            "Epoch 48/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.8291\n",
            "Epoch 48: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2841 - accuracy: 0.8292 - val_loss: 1.8172 - val_accuracy: 0.4700\n",
            "Epoch 49/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.8319\n",
            "Epoch 49: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2804 - accuracy: 0.8317 - val_loss: 1.9184 - val_accuracy: 0.4720\n",
            "Epoch 50/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2770 - accuracy: 0.8301\n",
            "Epoch 50: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2764 - accuracy: 0.8325 - val_loss: 1.5818 - val_accuracy: 0.4900\n",
            "Epoch 51/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.8288\n",
            "Epoch 51: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2810 - accuracy: 0.8300 - val_loss: 1.6167 - val_accuracy: 0.4780\n",
            "Epoch 52/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.8291\n",
            "Epoch 52: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2827 - accuracy: 0.8290 - val_loss: 1.4221 - val_accuracy: 0.4880\n",
            "Epoch 53/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2867 - accuracy: 0.8285\n",
            "Epoch 53: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2866 - accuracy: 0.8282 - val_loss: 1.7556 - val_accuracy: 0.4760\n",
            "Epoch 54/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.8337\n",
            "Epoch 54: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2755 - accuracy: 0.8345 - val_loss: 1.7040 - val_accuracy: 0.4780\n",
            "Epoch 55/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2790 - accuracy: 0.8310\n",
            "Epoch 55: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2792 - accuracy: 0.8303 - val_loss: 1.7618 - val_accuracy: 0.4740\n",
            "Epoch 56/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.8333\n",
            "Epoch 56: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2741 - accuracy: 0.8332 - val_loss: 1.4817 - val_accuracy: 0.4880\n",
            "Epoch 57/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2822 - accuracy: 0.8328\n",
            "Epoch 57: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2832 - accuracy: 0.8313 - val_loss: 1.5421 - val_accuracy: 0.4760\n",
            "Epoch 58/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2737 - accuracy: 0.8354\n",
            "Epoch 58: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2742 - accuracy: 0.8355 - val_loss: 1.5718 - val_accuracy: 0.4820\n",
            "Epoch 59/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.8349\n",
            "Epoch 59: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2734 - accuracy: 0.8342 - val_loss: 1.8267 - val_accuracy: 0.4720\n",
            "Epoch 60/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.2763 - accuracy: 0.8350\n",
            "Epoch 60: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2771 - accuracy: 0.8330 - val_loss: 1.5995 - val_accuracy: 0.4680\n",
            "Epoch 61/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.8386\n",
            "Epoch 61: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.8385 - val_loss: 2.0720 - val_accuracy: 0.4620\n",
            "Epoch 62/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.8300\n",
            "Epoch 62: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2691 - accuracy: 0.8298 - val_loss: 1.7937 - val_accuracy: 0.4780\n",
            "Epoch 63/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.8321\n",
            "Epoch 63: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2733 - accuracy: 0.8330 - val_loss: 1.8132 - val_accuracy: 0.4660\n",
            "Epoch 64/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.8332\n",
            "Epoch 64: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2703 - accuracy: 0.8332 - val_loss: 2.0300 - val_accuracy: 0.4660\n",
            "Epoch 65/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.8323\n",
            "Epoch 65: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2672 - accuracy: 0.8338 - val_loss: 1.9151 - val_accuracy: 0.4740\n",
            "Epoch 66/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.8367\n",
            "Epoch 66: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2649 - accuracy: 0.8363 - val_loss: 2.0026 - val_accuracy: 0.4700\n",
            "Epoch 67/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.8347\n",
            "Epoch 67: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.8340 - val_loss: 2.0495 - val_accuracy: 0.4740\n",
            "Epoch 68/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.8293\n",
            "Epoch 68: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2759 - accuracy: 0.8290 - val_loss: 1.7011 - val_accuracy: 0.4740\n",
            "Epoch 69/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8338\n",
            "Epoch 69: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2793 - accuracy: 0.8325 - val_loss: 1.6997 - val_accuracy: 0.4720\n",
            "Epoch 70/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.8349\n",
            "Epoch 70: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2691 - accuracy: 0.8350 - val_loss: 1.8405 - val_accuracy: 0.4820\n",
            "Epoch 71/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.8298\n",
            "Epoch 71: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2812 - accuracy: 0.8300 - val_loss: 1.6552 - val_accuracy: 0.4820\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2723 - accuracy: 0.8325\n",
            "Epoch 72: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2723 - accuracy: 0.8325 - val_loss: 1.6135 - val_accuracy: 0.4820\n",
            "Epoch 73/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8326\n",
            "Epoch 73: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2733 - accuracy: 0.8332 - val_loss: 1.6077 - val_accuracy: 0.4720\n",
            "Epoch 74/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2747 - accuracy: 0.8325\n",
            "Epoch 74: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2748 - accuracy: 0.8335 - val_loss: 1.9016 - val_accuracy: 0.4620\n",
            "Epoch 75/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.8340\n",
            "Epoch 75: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2655 - accuracy: 0.8350 - val_loss: 1.8535 - val_accuracy: 0.4760\n",
            "Epoch 76/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.8363\n",
            "Epoch 76: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2643 - accuracy: 0.8360 - val_loss: 2.0677 - val_accuracy: 0.4580\n",
            "Epoch 77/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2726 - accuracy: 0.8360\n",
            "Epoch 77: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2721 - accuracy: 0.8347 - val_loss: 1.7331 - val_accuracy: 0.4860\n",
            "Epoch 78/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.8317\n",
            "Epoch 78: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2723 - accuracy: 0.8322 - val_loss: 1.6680 - val_accuracy: 0.4920\n",
            "Epoch 79/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.8357\n",
            "Epoch 79: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2707 - accuracy: 0.8335 - val_loss: 1.8806 - val_accuracy: 0.4680\n",
            "Epoch 80/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.8352\n",
            "Epoch 80: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.8350 - val_loss: 1.5863 - val_accuracy: 0.4860\n",
            "Epoch 81/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2670 - accuracy: 0.8354\n",
            "Epoch 81: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2669 - accuracy: 0.8357 - val_loss: 1.8222 - val_accuracy: 0.4700\n",
            "Epoch 82/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.8364\n",
            "Epoch 82: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2658 - accuracy: 0.8347 - val_loss: 2.1886 - val_accuracy: 0.4620\n",
            "Epoch 83/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.8347\n",
            "Epoch 83: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2752 - accuracy: 0.8345 - val_loss: 1.4853 - val_accuracy: 0.4820\n",
            "Epoch 84/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.8342\n",
            "Epoch 84: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2674 - accuracy: 0.8345 - val_loss: 1.9069 - val_accuracy: 0.4560\n",
            "Epoch 85/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2688 - accuracy: 0.8351\n",
            "Epoch 85: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2667 - accuracy: 0.8363 - val_loss: 1.8931 - val_accuracy: 0.4780\n",
            "Epoch 86/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.8324\n",
            "Epoch 86: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2680 - accuracy: 0.8320 - val_loss: 1.7250 - val_accuracy: 0.4780\n",
            "Epoch 87/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2690 - accuracy: 0.8338\n",
            "Epoch 87: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2702 - accuracy: 0.8325 - val_loss: 1.8743 - val_accuracy: 0.4740\n",
            "Epoch 88/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.8369\n",
            "Epoch 88: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2660 - accuracy: 0.8363 - val_loss: 1.8762 - val_accuracy: 0.4760\n",
            "Epoch 89/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.8356\n",
            "Epoch 89: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2679 - accuracy: 0.8363 - val_loss: 1.5185 - val_accuracy: 0.5020\n",
            "Epoch 90/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2647 - accuracy: 0.8353\n",
            "Epoch 90: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2659 - accuracy: 0.8330 - val_loss: 1.7834 - val_accuracy: 0.4840\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.8363\n",
            "Epoch 91: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2637 - accuracy: 0.8363 - val_loss: 1.8142 - val_accuracy: 0.4900\n",
            "Epoch 92/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.8354\n",
            "Epoch 92: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2625 - accuracy: 0.8353 - val_loss: 1.9080 - val_accuracy: 0.4800\n",
            "Epoch 93/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.8345\n",
            "Epoch 93: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2671 - accuracy: 0.8347 - val_loss: 1.8411 - val_accuracy: 0.4760\n",
            "Epoch 94/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.8359\n",
            "Epoch 94: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2647 - accuracy: 0.8365 - val_loss: 1.9753 - val_accuracy: 0.4820\n",
            "Epoch 95/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.8362\n",
            "Epoch 95: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2677 - accuracy: 0.8357 - val_loss: 1.7146 - val_accuracy: 0.4860\n",
            "Epoch 96/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.8345\n",
            "Epoch 96: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2736 - accuracy: 0.8338 - val_loss: 1.6769 - val_accuracy: 0.4880\n",
            "Epoch 97/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.8382\n",
            "Epoch 97: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2654 - accuracy: 0.8375 - val_loss: 1.7643 - val_accuracy: 0.4880\n",
            "Epoch 98/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.8339\n",
            "Epoch 98: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2676 - accuracy: 0.8345 - val_loss: 1.7341 - val_accuracy: 0.4840\n",
            "Epoch 99/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.8359\n",
            "Epoch 99: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2652 - accuracy: 0.8365 - val_loss: 1.8077 - val_accuracy: 0.4800\n",
            "Epoch 100/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.8344\n",
            "Epoch 100: val_accuracy did not improve from 0.59600\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.8340 - val_loss: 1.7456 - val_accuracy: 0.4840\n"
          ]
        }
      ],
      "source": [
        "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:15:25.346101Z",
          "iopub.status.busy": "2023-12-11T01:15:25.345345Z",
          "iopub.status.idle": "2023-12-11T01:15:25.584290Z",
          "shell.execute_reply": "2023-12-11T01:15:25.583291Z",
          "shell.execute_reply.started": "2023-12-11T01:15:25.346070Z"
        },
        "id": "HeHqJGIi6hWd",
        "outputId": "5fd1c1e4-f663-4841-d936-87fb830f152b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 4ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7449    0.2920    0.4195       250\n",
            "           1     0.5597    0.9000    0.6902       250\n",
            "\n",
            "    accuracy                         0.5960       500\n",
            "   macro avg     0.6523    0.5960    0.5549       500\n",
            "weighted avg     0.6523    0.5960    0.5549       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHVI7E_AeeZZ"
      },
      "source": [
        "## FastText BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-TPQegjeg-z",
        "outputId": "f35054a4-7eb6-4f51-9468-02e698fb78f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 80, 300)           4545300   \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 80, 400)           801600    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 32000)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 32001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5378901 (20.52 MB)\n",
            "Trainable params: 833601 (3.18 MB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = '/content/drive/MyDrive/Colab Notebooks/HOLD/' +\"BiLSTMModel_FastText.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix],trainable=False, input_length = max_len),\n",
        "# tf.keras.layers.Conv1D(128, 2, activation='relu'),\n",
        "# tf.keras.layers.MaxPooling1D(2),\n",
        "tf.keras.layers.Bidirectional(LSTM(units = 200,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZK0w9a3eoKO",
        "outputId": "91462370-4ef7-454a-c473-ef6be97e404f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  5/125 [>.............................] - ETA: 3s - loss: 0.6844 - accuracy: 0.5312"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.0120s). Check your callbacks.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/125 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.5587\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTMModel_FastText.h5\n",
            "125/125 [==============================] - 10s 21ms/step - loss: 0.6742 - accuracy: 0.5583 - val_loss: 0.6928 - val_accuracy: 0.6060\n",
            "Epoch 2/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6369 - accuracy: 0.6245\n",
            "Epoch 2: val_accuracy did not improve from 0.60600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6368 - accuracy: 0.6237 - val_loss: 0.7152 - val_accuracy: 0.4480\n",
            "Epoch 3/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.6501\n",
            "Epoch 3: val_accuracy did not improve from 0.60600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.6139 - accuracy: 0.6525 - val_loss: 0.7114 - val_accuracy: 0.4780\n",
            "Epoch 4/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.6025 - accuracy: 0.6600\n",
            "Epoch 4: val_accuracy did not improve from 0.60600\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.6026 - accuracy: 0.6595 - val_loss: 0.7127 - val_accuracy: 0.4980\n",
            "Epoch 5/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.6676\n",
            "Epoch 5: val_accuracy improved from 0.60600 to 0.61000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTMModel_FastText.h5\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.5894 - accuracy: 0.6678 - val_loss: 0.6875 - val_accuracy: 0.6100\n",
            "Epoch 6/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.5741 - accuracy: 0.6743\n",
            "Epoch 6: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.5730 - accuracy: 0.6733 - val_loss: 0.6975 - val_accuracy: 0.5920\n",
            "Epoch 7/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.6790\n",
            "Epoch 7: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.5592 - accuracy: 0.6783 - val_loss: 0.7258 - val_accuracy: 0.4920\n",
            "Epoch 8/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.6875\n",
            "Epoch 8: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.5436 - accuracy: 0.6898 - val_loss: 0.7141 - val_accuracy: 0.5020\n",
            "Epoch 9/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.7052\n",
            "Epoch 9: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.5282 - accuracy: 0.7045 - val_loss: 0.7644 - val_accuracy: 0.4860\n",
            "Epoch 10/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.5340 - accuracy: 0.7048\n",
            "Epoch 10: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.5335 - accuracy: 0.7060 - val_loss: 0.7193 - val_accuracy: 0.4880\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7135\n",
            "Epoch 11: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.5108 - accuracy: 0.7135 - val_loss: 0.8360 - val_accuracy: 0.4640\n",
            "Epoch 12/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.7203\n",
            "Epoch 12: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.5029 - accuracy: 0.7197 - val_loss: 0.7792 - val_accuracy: 0.4840\n",
            "Epoch 13/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.4892 - accuracy: 0.7311\n",
            "Epoch 13: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 19ms/step - loss: 0.4888 - accuracy: 0.7315 - val_loss: 0.7820 - val_accuracy: 0.4940\n",
            "Epoch 14/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.4740 - accuracy: 0.7412\n",
            "Epoch 14: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.4737 - accuracy: 0.7415 - val_loss: 0.7815 - val_accuracy: 0.4920\n",
            "Epoch 15/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.7380\n",
            "Epoch 15: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4646 - accuracy: 0.7375 - val_loss: 0.7723 - val_accuracy: 0.4980\n",
            "Epoch 16/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.7384\n",
            "Epoch 16: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4573 - accuracy: 0.7398 - val_loss: 0.8841 - val_accuracy: 0.4860\n",
            "Epoch 17/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.7500\n",
            "Epoch 17: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4523 - accuracy: 0.7490 - val_loss: 0.8226 - val_accuracy: 0.4820\n",
            "Epoch 18/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.7518\n",
            "Epoch 18: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4481 - accuracy: 0.7502 - val_loss: 0.8283 - val_accuracy: 0.4820\n",
            "Epoch 19/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.4290 - accuracy: 0.7574\n",
            "Epoch 19: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4303 - accuracy: 0.7567 - val_loss: 0.8779 - val_accuracy: 0.4960\n",
            "Epoch 20/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.7588\n",
            "Epoch 20: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4307 - accuracy: 0.7582 - val_loss: 0.8384 - val_accuracy: 0.4860\n",
            "Epoch 21/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.4286 - accuracy: 0.7608\n",
            "Epoch 21: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4293 - accuracy: 0.7607 - val_loss: 0.8165 - val_accuracy: 0.5040\n",
            "Epoch 22/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.4206 - accuracy: 0.7702\n",
            "Epoch 22: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.4204 - accuracy: 0.7705 - val_loss: 0.9229 - val_accuracy: 0.4820\n",
            "Epoch 23/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.4221 - accuracy: 0.7601\n",
            "Epoch 23: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.4220 - accuracy: 0.7602 - val_loss: 0.8423 - val_accuracy: 0.4900\n",
            "Epoch 24/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.7696\n",
            "Epoch 24: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.4162 - accuracy: 0.7688 - val_loss: 0.8296 - val_accuracy: 0.4980\n",
            "Epoch 25/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.7741\n",
            "Epoch 25: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4016 - accuracy: 0.7738 - val_loss: 0.9089 - val_accuracy: 0.4980\n",
            "Epoch 26/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.7748\n",
            "Epoch 26: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4000 - accuracy: 0.7755 - val_loss: 0.8563 - val_accuracy: 0.5020\n",
            "Epoch 27/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.7818\n",
            "Epoch 27: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3887 - accuracy: 0.7805 - val_loss: 0.9706 - val_accuracy: 0.4880\n",
            "Epoch 28/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.7810\n",
            "Epoch 28: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3912 - accuracy: 0.7825 - val_loss: 0.9263 - val_accuracy: 0.5020\n",
            "Epoch 29/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.7905\n",
            "Epoch 29: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3828 - accuracy: 0.7903 - val_loss: 0.9085 - val_accuracy: 0.4980\n",
            "Epoch 30/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.7828\n",
            "Epoch 30: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3925 - accuracy: 0.7828 - val_loss: 0.8945 - val_accuracy: 0.4920\n",
            "Epoch 31/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.7772\n",
            "Epoch 31: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.3810 - accuracy: 0.7782 - val_loss: 0.9159 - val_accuracy: 0.5100\n",
            "Epoch 32/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.7957\n",
            "Epoch 32: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.3676 - accuracy: 0.7955 - val_loss: 0.9860 - val_accuracy: 0.4960\n",
            "Epoch 33/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.7894\n",
            "Epoch 33: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.3687 - accuracy: 0.7890 - val_loss: 0.9928 - val_accuracy: 0.4980\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.7952\n",
            "Epoch 34: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.3649 - accuracy: 0.7952 - val_loss: 0.9864 - val_accuracy: 0.5060\n",
            "Epoch 35/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.7986\n",
            "Epoch 35: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3504 - accuracy: 0.8000 - val_loss: 0.9852 - val_accuracy: 0.4960\n",
            "Epoch 36/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3544 - accuracy: 0.8015\n",
            "Epoch 36: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3552 - accuracy: 0.8002 - val_loss: 1.0572 - val_accuracy: 0.4840\n",
            "Epoch 37/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.8014\n",
            "Epoch 37: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3592 - accuracy: 0.7997 - val_loss: 1.0002 - val_accuracy: 0.6060\n",
            "Epoch 38/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.7910\n",
            "Epoch 38: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3597 - accuracy: 0.7922 - val_loss: 0.9102 - val_accuracy: 0.5100\n",
            "Epoch 39/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3544 - accuracy: 0.7987\n",
            "Epoch 39: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3548 - accuracy: 0.7993 - val_loss: 1.0605 - val_accuracy: 0.4840\n",
            "Epoch 40/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8089\n",
            "Epoch 40: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3389 - accuracy: 0.8080 - val_loss: 1.0014 - val_accuracy: 0.4940\n",
            "Epoch 41/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3443 - accuracy: 0.8036\n",
            "Epoch 41: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.3455 - accuracy: 0.8033 - val_loss: 1.1100 - val_accuracy: 0.4860\n",
            "Epoch 42/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.8023\n",
            "Epoch 42: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 3s 23ms/step - loss: 0.3385 - accuracy: 0.8027 - val_loss: 0.9300 - val_accuracy: 0.5140\n",
            "Epoch 43/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8032\n",
            "Epoch 43: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.3399 - accuracy: 0.8033 - val_loss: 1.0117 - val_accuracy: 0.5020\n",
            "Epoch 44/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3343 - accuracy: 0.8094\n",
            "Epoch 44: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.3343 - accuracy: 0.8100 - val_loss: 1.0333 - val_accuracy: 0.5020\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8095\n",
            "Epoch 45: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.3301 - accuracy: 0.8095 - val_loss: 1.0403 - val_accuracy: 0.5100\n",
            "Epoch 46/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3270 - accuracy: 0.8110\n",
            "Epoch 46: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 3s 22ms/step - loss: 0.3269 - accuracy: 0.8110 - val_loss: 1.1004 - val_accuracy: 0.5060\n",
            "Epoch 47/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8130\n",
            "Epoch 47: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 19ms/step - loss: 0.3287 - accuracy: 0.8130 - val_loss: 1.2443 - val_accuracy: 0.4840\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8050\n",
            "Epoch 48: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 3s 23ms/step - loss: 0.3411 - accuracy: 0.8050 - val_loss: 1.0693 - val_accuracy: 0.5040\n",
            "Epoch 49/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8145\n",
            "Epoch 49: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 3s 22ms/step - loss: 0.3243 - accuracy: 0.8150 - val_loss: 1.1153 - val_accuracy: 0.5020\n",
            "Epoch 50/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8161\n",
            "Epoch 50: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.3177 - accuracy: 0.8152 - val_loss: 1.1631 - val_accuracy: 0.5020\n",
            "Epoch 51/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8180\n",
            "Epoch 51: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.3167 - accuracy: 0.8177 - val_loss: 1.1064 - val_accuracy: 0.4980\n",
            "Epoch 52/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8133\n",
            "Epoch 52: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.3205 - accuracy: 0.8135 - val_loss: 1.0595 - val_accuracy: 0.5120\n",
            "Epoch 53/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.8155\n",
            "Epoch 53: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.3217 - accuracy: 0.8152 - val_loss: 1.2050 - val_accuracy: 0.5040\n",
            "Epoch 54/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.8199\n",
            "Epoch 54: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.3179 - accuracy: 0.8202 - val_loss: 1.1878 - val_accuracy: 0.5120\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8205\n",
            "Epoch 55: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.3168 - accuracy: 0.8205 - val_loss: 1.1629 - val_accuracy: 0.5040\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.8242\n",
            "Epoch 56: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3050 - accuracy: 0.8242 - val_loss: 1.1837 - val_accuracy: 0.5060\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.8140\n",
            "Epoch 57: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 3s 23ms/step - loss: 0.3127 - accuracy: 0.8140 - val_loss: 1.1506 - val_accuracy: 0.5100\n",
            "Epoch 58/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3066 - accuracy: 0.8231\n",
            "Epoch 58: val_accuracy did not improve from 0.61000\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.3071 - accuracy: 0.8227 - val_loss: 1.1032 - val_accuracy: 0.5060\n",
            "Epoch 59/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.8158\n",
            "Epoch 59: val_accuracy improved from 0.61000 to 0.61200, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTMModel_FastText.h5\n",
            "125/125 [==============================] - 3s 20ms/step - loss: 0.3258 - accuracy: 0.8150 - val_loss: 1.1144 - val_accuracy: 0.6120\n",
            "Epoch 60/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3066 - accuracy: 0.8222\n",
            "Epoch 60: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3070 - accuracy: 0.8207 - val_loss: 1.2112 - val_accuracy: 0.5100\n",
            "Epoch 61/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8192\n",
            "Epoch 61: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.3075 - accuracy: 0.8185 - val_loss: 1.2424 - val_accuracy: 0.4980\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8165\n",
            "Epoch 62: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.3079 - accuracy: 0.8165 - val_loss: 1.1822 - val_accuracy: 0.5060\n",
            "Epoch 63/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.8266\n",
            "Epoch 63: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2970 - accuracy: 0.8265 - val_loss: 1.2647 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.8240\n",
            "Epoch 64: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.3012 - accuracy: 0.8240 - val_loss: 1.3263 - val_accuracy: 0.5080\n",
            "Epoch 65/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.8264\n",
            "Epoch 65: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 18ms/step - loss: 0.3006 - accuracy: 0.8273 - val_loss: 1.4635 - val_accuracy: 0.4980\n",
            "Epoch 66/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.8220\n",
            "Epoch 66: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.3001 - accuracy: 0.8223 - val_loss: 1.2104 - val_accuracy: 0.5180\n",
            "Epoch 67/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8225\n",
            "Epoch 67: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 3s 20ms/step - loss: 0.2995 - accuracy: 0.8205 - val_loss: 1.2312 - val_accuracy: 0.5080\n",
            "Epoch 68/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8216\n",
            "Epoch 68: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 0.3051 - accuracy: 0.8220 - val_loss: 1.3153 - val_accuracy: 0.5040\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.8217\n",
            "Epoch 69: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2939 - accuracy: 0.8217 - val_loss: 1.2219 - val_accuracy: 0.5180\n",
            "Epoch 70/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8246\n",
            "Epoch 70: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2942 - accuracy: 0.8242 - val_loss: 1.2587 - val_accuracy: 0.5060\n",
            "Epoch 71/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.8281\n",
            "Epoch 71: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2943 - accuracy: 0.8280 - val_loss: 1.4216 - val_accuracy: 0.5040\n",
            "Epoch 72/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.8223\n",
            "Epoch 72: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2945 - accuracy: 0.8225 - val_loss: 1.3657 - val_accuracy: 0.5020\n",
            "Epoch 73/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.8275\n",
            "Epoch 73: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2917 - accuracy: 0.8282 - val_loss: 1.2953 - val_accuracy: 0.5060\n",
            "Epoch 74/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.8215\n",
            "Epoch 74: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2970 - accuracy: 0.8217 - val_loss: 1.4083 - val_accuracy: 0.5020\n",
            "Epoch 75/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.8298\n",
            "Epoch 75: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2897 - accuracy: 0.8300 - val_loss: 1.3241 - val_accuracy: 0.5160\n",
            "Epoch 76/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8244\n",
            "Epoch 76: val_accuracy did not improve from 0.61200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2965 - accuracy: 0.8245 - val_loss: 1.2629 - val_accuracy: 0.5080\n",
            "Epoch 77/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8290\n",
            "Epoch 77: val_accuracy improved from 0.61200 to 0.62600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/BiLSTMModel_FastText.h5\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.2900 - accuracy: 0.8298 - val_loss: 1.2452 - val_accuracy: 0.6260\n",
            "Epoch 78/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2913 - accuracy: 0.8233\n",
            "Epoch 78: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2907 - accuracy: 0.8230 - val_loss: 1.3834 - val_accuracy: 0.5140\n",
            "Epoch 79/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8276\n",
            "Epoch 79: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2897 - accuracy: 0.8280 - val_loss: 1.3049 - val_accuracy: 0.5080\n",
            "Epoch 80/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2887 - accuracy: 0.8262\n",
            "Epoch 80: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2889 - accuracy: 0.8263 - val_loss: 1.3528 - val_accuracy: 0.5080\n",
            "Epoch 81/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8227\n",
            "Epoch 81: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2941 - accuracy: 0.8223 - val_loss: 1.2925 - val_accuracy: 0.4980\n",
            "Epoch 82/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8290\n",
            "Epoch 82: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2919 - accuracy: 0.8278 - val_loss: 1.2422 - val_accuracy: 0.4880\n",
            "Epoch 83/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2890 - accuracy: 0.8249\n",
            "Epoch 83: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2890 - accuracy: 0.8260 - val_loss: 1.3614 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2794 - accuracy: 0.8301\n",
            "Epoch 84: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2805 - accuracy: 0.8292 - val_loss: 1.3134 - val_accuracy: 0.5140\n",
            "Epoch 85/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.8270\n",
            "Epoch 85: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2852 - accuracy: 0.8260 - val_loss: 1.4432 - val_accuracy: 0.5040\n",
            "Epoch 86/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.8279\n",
            "Epoch 86: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2839 - accuracy: 0.8285 - val_loss: 1.3781 - val_accuracy: 0.5080\n",
            "Epoch 87/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.8261\n",
            "Epoch 87: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2835 - accuracy: 0.8250 - val_loss: 1.4087 - val_accuracy: 0.5120\n",
            "Epoch 88/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8277\n",
            "Epoch 88: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2842 - accuracy: 0.8273 - val_loss: 1.4556 - val_accuracy: 0.6100\n",
            "Epoch 89/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.8255\n",
            "Epoch 89: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 0.2878 - accuracy: 0.8257 - val_loss: 1.4999 - val_accuracy: 0.4920\n",
            "Epoch 90/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.8347\n",
            "Epoch 90: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2794 - accuracy: 0.8338 - val_loss: 1.4353 - val_accuracy: 0.4960\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.8290\n",
            "Epoch 91: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.2792 - accuracy: 0.8290 - val_loss: 1.4574 - val_accuracy: 0.4980\n",
            "Epoch 92/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8304\n",
            "Epoch 92: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2878 - accuracy: 0.8305 - val_loss: 1.3724 - val_accuracy: 0.5060\n",
            "Epoch 93/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.8291\n",
            "Epoch 93: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2834 - accuracy: 0.8298 - val_loss: 1.3502 - val_accuracy: 0.5140\n",
            "Epoch 94/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8199\n",
            "Epoch 94: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2800 - accuracy: 0.8215 - val_loss: 1.4656 - val_accuracy: 0.5060\n",
            "Epoch 95/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.8315\n",
            "Epoch 95: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2790 - accuracy: 0.8310 - val_loss: 1.4174 - val_accuracy: 0.5100\n",
            "Epoch 96/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8315\n",
            "Epoch 96: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2831 - accuracy: 0.8305 - val_loss: 1.5021 - val_accuracy: 0.4960\n",
            "Epoch 97/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.8320\n",
            "Epoch 97: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2792 - accuracy: 0.8313 - val_loss: 1.5169 - val_accuracy: 0.4920\n",
            "Epoch 98/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.8291\n",
            "Epoch 98: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2857 - accuracy: 0.8292 - val_loss: 1.3354 - val_accuracy: 0.5220\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.8240\n",
            "Epoch 99: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2846 - accuracy: 0.8240 - val_loss: 1.6180 - val_accuracy: 0.4900\n",
            "Epoch 100/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.8218\n",
            "Epoch 100: val_accuracy did not improve from 0.62600\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2854 - accuracy: 0.8210 - val_loss: 1.3668 - val_accuracy: 0.6180\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlcDs0C8C1X",
        "outputId": "e2e2673d-9bab-4154-e30f-769116c7c9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 8ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7692    0.3600    0.4905       250\n",
            "           1     0.5822    0.8920    0.7046       250\n",
            "\n",
            "    accuracy                         0.6260       500\n",
            "   macro avg     0.6757    0.6260    0.5975       500\n",
            "weighted avg     0.6757    0.6260    0.5975       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmMby0LwbYzf"
      },
      "source": [
        "## FastText CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "JXFE7Ix4bYzg"
      },
      "outputs": [],
      "source": [
        "num_classes = 2            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/HOLD/\" + \"CNN_FastText.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHHTEHM9bYzh",
        "outputId": "8b7b6e10-487e-47b9-dcac-a3e1e9ced5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 80, 300)           4545300   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 76, 128)           192128    \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4737557 (18.07 MB)\n",
            "Trainable params: 192257 (751.00 KB)\n",
            "Non-trainable params: 4545300 (17.34 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtXcdQeybYzj",
        "outputId": "175e3722-caef-4aee-f794-b579092606c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(train_df['enc_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQmpWaDubYzk",
        "outputId": "074f0502-7985-4ec2-bd45-2c2242995652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.5972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47600, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 2s 7ms/step - loss: 0.6603 - accuracy: 0.5972 - val_loss: 0.6981 - val_accuracy: 0.4760\n",
            "Epoch 2/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.6079 - accuracy: 0.6623\n",
            "Epoch 2: val_accuracy did not improve from 0.47600\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.7273 - val_accuracy: 0.4640\n",
            "Epoch 3/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.5713 - accuracy: 0.6926\n",
            "Epoch 3: val_accuracy improved from 0.47600 to 0.47800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5706 - accuracy: 0.6950 - val_loss: 0.7233 - val_accuracy: 0.4780\n",
            "Epoch 4/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.5406 - accuracy: 0.7144\n",
            "Epoch 4: val_accuracy improved from 0.47800 to 0.48400, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7188 - val_loss: 0.7256 - val_accuracy: 0.4840\n",
            "Epoch 5/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.5062 - accuracy: 0.7332\n",
            "Epoch 5: val_accuracy improved from 0.48400 to 0.49000, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7340 - val_loss: 0.7094 - val_accuracy: 0.4900\n",
            "Epoch 6/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.4801 - accuracy: 0.7516\n",
            "Epoch 6: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7470 - val_loss: 0.7563 - val_accuracy: 0.4880\n",
            "Epoch 7/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.4629 - accuracy: 0.7561\n",
            "Epoch 7: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7570 - val_loss: 0.7781 - val_accuracy: 0.4820\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.7703\n",
            "Epoch 8: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7703 - val_loss: 0.7793 - val_accuracy: 0.4840\n",
            "Epoch 9/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.4207 - accuracy: 0.7810\n",
            "Epoch 9: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7805 - val_loss: 0.7803 - val_accuracy: 0.4780\n",
            "Epoch 10/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.7886\n",
            "Epoch 10: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.7890 - val_loss: 0.8015 - val_accuracy: 0.4880\n",
            "Epoch 11/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3957 - accuracy: 0.7956\n",
            "Epoch 11: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.7955 - val_loss: 0.8658 - val_accuracy: 0.4740\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.7983\n",
            "Epoch 12: val_accuracy did not improve from 0.49000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.7983 - val_loss: 0.8243 - val_accuracy: 0.4860\n",
            "Epoch 13/100\n",
            "109/125 [=========================>....] - ETA: 0s - loss: 0.3769 - accuracy: 0.7976\n",
            "Epoch 13: val_accuracy improved from 0.49000 to 0.49400, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3771 - accuracy: 0.7985 - val_loss: 0.8608 - val_accuracy: 0.4940\n",
            "Epoch 14/100\n",
            "109/125 [=========================>....] - ETA: 0s - loss: 0.3685 - accuracy: 0.8048\n",
            "Epoch 14: val_accuracy did not improve from 0.49400\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8015 - val_loss: 0.8860 - val_accuracy: 0.4820\n",
            "Epoch 15/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.8060\n",
            "Epoch 15: val_accuracy did not improve from 0.49400\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8070 - val_loss: 0.8554 - val_accuracy: 0.4880\n",
            "Epoch 16/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.3557 - accuracy: 0.8081\n",
            "Epoch 16: val_accuracy did not improve from 0.49400\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8092 - val_loss: 0.8844 - val_accuracy: 0.4820\n",
            "Epoch 17/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.8115\n",
            "Epoch 17: val_accuracy did not improve from 0.49400\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8098 - val_loss: 0.9001 - val_accuracy: 0.4800\n",
            "Epoch 18/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.3468 - accuracy: 0.8120\n",
            "Epoch 18: val_accuracy improved from 0.49400 to 0.49800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8112 - val_loss: 0.8548 - val_accuracy: 0.4980\n",
            "Epoch 19/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.8158\n",
            "Epoch 19: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8148 - val_loss: 0.9718 - val_accuracy: 0.4760\n",
            "Epoch 20/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.8130\n",
            "Epoch 20: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8117 - val_loss: 0.8961 - val_accuracy: 0.4720\n",
            "Epoch 21/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.3294 - accuracy: 0.8139\n",
            "Epoch 21: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8145 - val_loss: 0.9123 - val_accuracy: 0.4780\n",
            "Epoch 22/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.8191\n",
            "Epoch 22: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8192 - val_loss: 0.9485 - val_accuracy: 0.4780\n",
            "Epoch 23/100\n",
            "109/125 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.8179\n",
            "Epoch 23: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8170 - val_loss: 0.9381 - val_accuracy: 0.4740\n",
            "Epoch 24/100\n",
            "110/125 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.8159\n",
            "Epoch 24: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8165 - val_loss: 0.9280 - val_accuracy: 0.4720\n",
            "Epoch 25/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8117\n",
            "Epoch 25: val_accuracy did not improve from 0.49800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8123 - val_loss: 1.0018 - val_accuracy: 0.4660\n",
            "Epoch 26/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8270\n",
            "Epoch 26: val_accuracy improved from 0.49800 to 0.59800, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8192 - val_loss: 0.9570 - val_accuracy: 0.5980\n",
            "Epoch 27/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.3145 - accuracy: 0.8183\n",
            "Epoch 27: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.8177 - val_loss: 0.9734 - val_accuracy: 0.4760\n",
            "Epoch 28/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3150 - accuracy: 0.8206\n",
            "Epoch 28: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8217 - val_loss: 1.0839 - val_accuracy: 0.4580\n",
            "Epoch 29/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.3124 - accuracy: 0.8232\n",
            "Epoch 29: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3126 - accuracy: 0.8223 - val_loss: 0.9855 - val_accuracy: 0.4720\n",
            "Epoch 30/100\n",
            "112/125 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.8242\n",
            "Epoch 30: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.8215 - val_loss: 0.9893 - val_accuracy: 0.4740\n",
            "Epoch 31/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.3086 - accuracy: 0.8244\n",
            "Epoch 31: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3108 - accuracy: 0.8242 - val_loss: 1.0553 - val_accuracy: 0.4800\n",
            "Epoch 32/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.3120 - accuracy: 0.8231\n",
            "Epoch 32: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3131 - accuracy: 0.8225 - val_loss: 1.0488 - val_accuracy: 0.4680\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8245\n",
            "Epoch 33: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3100 - accuracy: 0.8245 - val_loss: 1.0390 - val_accuracy: 0.4820\n",
            "Epoch 34/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.3081 - accuracy: 0.8276\n",
            "Epoch 34: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3078 - accuracy: 0.8275 - val_loss: 0.9801 - val_accuracy: 0.4880\n",
            "Epoch 35/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.3062 - accuracy: 0.8242\n",
            "Epoch 35: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8260 - val_loss: 1.0201 - val_accuracy: 0.4880\n",
            "Epoch 36/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.3032 - accuracy: 0.8214\n",
            "Epoch 36: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8215 - val_loss: 1.1127 - val_accuracy: 0.4620\n",
            "Epoch 37/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.8275\n",
            "Epoch 37: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8275 - val_loss: 1.0232 - val_accuracy: 0.4740\n",
            "Epoch 38/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8221\n",
            "Epoch 38: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8230 - val_loss: 1.1664 - val_accuracy: 0.4540\n",
            "Epoch 39/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.2916 - accuracy: 0.8328\n",
            "Epoch 39: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8282 - val_loss: 1.0711 - val_accuracy: 0.4840\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8290\n",
            "Epoch 40: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8290 - val_loss: 1.0174 - val_accuracy: 0.4800\n",
            "Epoch 41/100\n",
            "114/125 [==========================>...] - ETA: 0s - loss: 0.2991 - accuracy: 0.8284\n",
            "Epoch 41: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8282 - val_loss: 1.0663 - val_accuracy: 0.4740\n",
            "Epoch 42/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2996 - accuracy: 0.8236\n",
            "Epoch 42: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8240 - val_loss: 1.0434 - val_accuracy: 0.4780\n",
            "Epoch 43/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.3050 - accuracy: 0.8257\n",
            "Epoch 43: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8260 - val_loss: 1.1057 - val_accuracy: 0.4800\n",
            "Epoch 44/100\n",
            "117/125 [===========================>..] - ETA: 0s - loss: 0.2927 - accuracy: 0.8307\n",
            "Epoch 44: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8292 - val_loss: 1.1997 - val_accuracy: 0.4580\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8267\n",
            "Epoch 45: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8267 - val_loss: 1.1355 - val_accuracy: 0.4700\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.8267\n",
            "Epoch 46: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8267 - val_loss: 1.1539 - val_accuracy: 0.4640\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.8290\n",
            "Epoch 47: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8290 - val_loss: 1.0910 - val_accuracy: 0.4880\n",
            "Epoch 48/100\n",
            "111/125 [=========================>....] - ETA: 0s - loss: 0.2957 - accuracy: 0.8285\n",
            "Epoch 48: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8278 - val_loss: 1.0830 - val_accuracy: 0.4740\n",
            "Epoch 49/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.2966 - accuracy: 0.8289\n",
            "Epoch 49: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8295 - val_loss: 1.2191 - val_accuracy: 0.4740\n",
            "Epoch 50/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.2966 - accuracy: 0.8261\n",
            "Epoch 50: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8282 - val_loss: 1.2494 - val_accuracy: 0.4660\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8313\n",
            "Epoch 51: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8313 - val_loss: 1.1730 - val_accuracy: 0.4780\n",
            "Epoch 52/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.8285\n",
            "Epoch 52: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8288 - val_loss: 1.2349 - val_accuracy: 0.4620\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.8292\n",
            "Epoch 53: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8292 - val_loss: 1.2293 - val_accuracy: 0.4620\n",
            "Epoch 54/100\n",
            "119/125 [===========================>..] - ETA: 0s - loss: 0.2935 - accuracy: 0.8277\n",
            "Epoch 54: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8292 - val_loss: 1.3619 - val_accuracy: 0.4720\n",
            "Epoch 55/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8288\n",
            "Epoch 55: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8280 - val_loss: 1.2223 - val_accuracy: 0.4660\n",
            "Epoch 56/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.8319\n",
            "Epoch 56: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.8325 - val_loss: 1.1724 - val_accuracy: 0.4720\n",
            "Epoch 57/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8317\n",
            "Epoch 57: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2943 - accuracy: 0.8298 - val_loss: 1.1264 - val_accuracy: 0.4820\n",
            "Epoch 58/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.8307\n",
            "Epoch 58: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2902 - accuracy: 0.8307 - val_loss: 1.3044 - val_accuracy: 0.4620\n",
            "Epoch 59/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2963 - accuracy: 0.8302\n",
            "Epoch 59: val_accuracy did not improve from 0.59800\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8278 - val_loss: 1.1593 - val_accuracy: 0.4780\n",
            "Epoch 60/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.8252\n",
            "Epoch 60: val_accuracy improved from 0.59800 to 0.60200, saving model to /content/drive/MyDrive/Colab Notebooks/HOLD/CNN_FastText.h5\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.2920 - accuracy: 0.8230 - val_loss: 1.1292 - val_accuracy: 0.6020\n",
            "Epoch 61/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.8310\n",
            "Epoch 61: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2913 - accuracy: 0.8305 - val_loss: 1.3553 - val_accuracy: 0.4580\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8280\n",
            "Epoch 62: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2895 - accuracy: 0.8280 - val_loss: 1.1315 - val_accuracy: 0.4840\n",
            "Epoch 63/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.2942 - accuracy: 0.8295\n",
            "Epoch 63: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2939 - accuracy: 0.8315 - val_loss: 1.1747 - val_accuracy: 0.4740\n",
            "Epoch 64/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2915 - accuracy: 0.8299\n",
            "Epoch 64: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8305 - val_loss: 1.2302 - val_accuracy: 0.4660\n",
            "Epoch 65/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.2897 - accuracy: 0.8302\n",
            "Epoch 65: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.8310 - val_loss: 1.3304 - val_accuracy: 0.4680\n",
            "Epoch 66/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.8281\n",
            "Epoch 66: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8282 - val_loss: 1.1479 - val_accuracy: 0.4880\n",
            "Epoch 67/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2925 - accuracy: 0.8273\n",
            "Epoch 67: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8265 - val_loss: 1.2940 - val_accuracy: 0.4620\n",
            "Epoch 68/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8283\n",
            "Epoch 68: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8280 - val_loss: 1.2215 - val_accuracy: 0.4740\n",
            "Epoch 69/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.8323\n",
            "Epoch 69: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8305 - val_loss: 1.2731 - val_accuracy: 0.4780\n",
            "Epoch 70/100\n",
            "115/125 [==========================>...] - ETA: 0s - loss: 0.2853 - accuracy: 0.8291\n",
            "Epoch 70: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8265 - val_loss: 1.1324 - val_accuracy: 0.4880\n",
            "Epoch 71/100\n",
            "116/125 [==========================>...] - ETA: 0s - loss: 0.2840 - accuracy: 0.8316\n",
            "Epoch 71: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8307 - val_loss: 1.3710 - val_accuracy: 0.4660\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.8313\n",
            "Epoch 72: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8313 - val_loss: 1.2337 - val_accuracy: 0.4700\n",
            "Epoch 73/100\n",
            "123/125 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.8328\n",
            "Epoch 73: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8335 - val_loss: 1.1831 - val_accuracy: 0.4840\n",
            "Epoch 74/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.8264\n",
            "Epoch 74: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8267 - val_loss: 1.2888 - val_accuracy: 0.4660\n",
            "Epoch 75/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.2853 - accuracy: 0.8322\n",
            "Epoch 75: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8320 - val_loss: 1.2387 - val_accuracy: 0.4800\n",
            "Epoch 76/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8264\n",
            "Epoch 76: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8267 - val_loss: 1.2987 - val_accuracy: 0.4760\n",
            "Epoch 77/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8322\n",
            "Epoch 77: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8313 - val_loss: 1.2798 - val_accuracy: 0.4720\n",
            "Epoch 78/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8303\n",
            "Epoch 78: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8305 - val_loss: 1.2517 - val_accuracy: 0.4880\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8310\n",
            "Epoch 79: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.8310 - val_loss: 1.3376 - val_accuracy: 0.4640\n",
            "Epoch 80/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.8330\n",
            "Epoch 80: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.8330 - val_loss: 1.3144 - val_accuracy: 0.4820\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8307\n",
            "Epoch 81: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8307 - val_loss: 1.2666 - val_accuracy: 0.4800\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8305\n",
            "Epoch 82: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8305 - val_loss: 1.3887 - val_accuracy: 0.4640\n",
            "Epoch 83/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2886 - accuracy: 0.8311\n",
            "Epoch 83: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8320 - val_loss: 1.2734 - val_accuracy: 0.4740\n",
            "Epoch 84/100\n",
            "108/125 [========================>.....] - ETA: 0s - loss: 0.2882 - accuracy: 0.8310\n",
            "Epoch 84: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8307 - val_loss: 1.2864 - val_accuracy: 0.4580\n",
            "Epoch 85/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2868 - accuracy: 0.8311\n",
            "Epoch 85: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.8317 - val_loss: 1.3577 - val_accuracy: 0.4640\n",
            "Epoch 86/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.8332\n",
            "Epoch 86: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2821 - accuracy: 0.8338 - val_loss: 1.4151 - val_accuracy: 0.4700\n",
            "Epoch 87/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2865 - accuracy: 0.8320\n",
            "Epoch 87: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.8298 - val_loss: 1.4235 - val_accuracy: 0.4560\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.8332\n",
            "Epoch 88: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2886 - accuracy: 0.8332 - val_loss: 1.3763 - val_accuracy: 0.4640\n",
            "Epoch 89/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.8310\n",
            "Epoch 89: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2861 - accuracy: 0.8315 - val_loss: 1.2822 - val_accuracy: 0.4760\n",
            "Epoch 90/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2895 - accuracy: 0.8317\n",
            "Epoch 90: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2887 - accuracy: 0.8322 - val_loss: 1.3550 - val_accuracy: 0.4700\n",
            "Epoch 91/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.8321\n",
            "Epoch 91: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2827 - accuracy: 0.8315 - val_loss: 1.4002 - val_accuracy: 0.4660\n",
            "Epoch 92/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.8312\n",
            "Epoch 92: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2850 - accuracy: 0.8317 - val_loss: 1.3080 - val_accuracy: 0.4740\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8307\n",
            "Epoch 93: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2864 - accuracy: 0.8307 - val_loss: 1.3115 - val_accuracy: 0.4720\n",
            "Epoch 94/100\n",
            "121/125 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.8285\n",
            "Epoch 94: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2872 - accuracy: 0.8300 - val_loss: 1.3412 - val_accuracy: 0.4780\n",
            "Epoch 95/100\n",
            "118/125 [===========================>..] - ETA: 0s - loss: 0.2869 - accuracy: 0.8313\n",
            "Epoch 95: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2864 - accuracy: 0.8315 - val_loss: 1.3278 - val_accuracy: 0.4620\n",
            "Epoch 96/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2904 - accuracy: 0.8307\n",
            "Epoch 96: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2895 - accuracy: 0.8310 - val_loss: 1.2931 - val_accuracy: 0.4640\n",
            "Epoch 97/100\n",
            "120/125 [===========================>..] - ETA: 0s - loss: 0.2804 - accuracy: 0.8349\n",
            "Epoch 97: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2818 - accuracy: 0.8338 - val_loss: 1.4711 - val_accuracy: 0.4620\n",
            "Epoch 98/100\n",
            "122/125 [============================>.] - ETA: 0s - loss: 0.2837 - accuracy: 0.8340\n",
            "Epoch 98: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2831 - accuracy: 0.8340 - val_loss: 1.3137 - val_accuracy: 0.4720\n",
            "Epoch 99/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8317\n",
            "Epoch 99: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2833 - accuracy: 0.8322 - val_loss: 1.2881 - val_accuracy: 0.4760\n",
            "Epoch 100/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.8324\n",
            "Epoch 100: val_accuracy did not improve from 0.60200\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2829 - accuracy: 0.8320 - val_loss: 1.4314 - val_accuracy: 0.4620\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    np.array(train_df['enc_label']),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_pad_sequences, np.array(y_data_with_label)),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")\n",
        " # as here weight is not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6bT1ksTbYzm",
        "outputId": "1c66ca1d-0556-4401-c4a7-93c3ecb79b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7179    0.3360    0.4578       250\n",
            "           1     0.5666    0.8680    0.6856       250\n",
            "\n",
            "    accuracy                         0.6020       500\n",
            "   macro avg     0.6423    0.6020    0.5717       500\n",
            "weighted avg     0.6423    0.6020    0.5717       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "y_pred_classes = (y_pred > threshold).astype(int)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(y_data_with_label, y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd-CAe8Ibyxb"
      },
      "source": [
        "# ktrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:19:42.364489Z",
          "iopub.status.busy": "2023-12-11T01:19:42.363789Z",
          "iopub.status.idle": "2023-12-11T01:20:27.074371Z",
          "shell.execute_reply": "2023-12-11T01:20:27.073133Z",
          "shell.execute_reply.started": "2023-12-11T01:19:42.364444Z"
        },
        "id": "caZBKu7Rb88A",
        "outputId": "b280d028-47e6-4dec-bd85-b2b49a6d698b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.39.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.2)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.35.2)\n",
            "Collecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.23.5)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.39.0-py3-none-any.whl size=25319737 sha256=91de8e2cb2c450ad669217e9c8a75570181fd95f7670add132f025223a15c467\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/fd/0a/ef6252223f3d2c49b06d18e71c74caa43bbf4c64a8c183a46e\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33499 sha256=12efea4bf9268af7cb6533e9496cce4bac4038fb66f444c9984bdabfe4d35473\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=f2625d200afca81b8c5daabe8f024e78f1975336e0076e1109debf4338595616\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=9d33a1785d9cba57412a16c9aa4654a131a622e7add2f2fbc00ee308d90b8964\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=43604f31b263438cbd7ee1a5807c885d9013de30657025a89755ef1bf2b23ff1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14975 sha256=5b42bf75e06109d3de8e4688f325c61f407dee18ed63db8544f0b3f2145b9b9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=fc4e30b2b6d2fbeb0f01f7d0cb4718a628f065903193352e9a3da372232227c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=29ab1655ab98657399a9f5e5a73d94877a5337d3cfcb59c11f2c538c90b4e967\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=ca75f78f68b28c0cf0e27f3709fa7943207d7a808975be282aae315ce1b0c2e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=65a47746b6a52e50f8dfb4226eeb66960cb37ec736609650baf69f0851de5299\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32622 sha256=ac163863fbff7683c3ebffa6dc976c1c1711ff1b07a761deb38c9fda9a1b301d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.39.0 langdetect-1.0.9 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:20:27.076720Z",
          "iopub.status.busy": "2023-12-11T01:20:27.076420Z",
          "iopub.status.idle": "2023-12-11T01:20:27.210358Z",
          "shell.execute_reply": "2023-12-11T01:20:27.209522Z",
          "shell.execute_reply.started": "2023-12-11T01:20:27.076693Z"
        },
        "id": "aEdORDT8b5OC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:20:27.211857Z",
          "iopub.status.busy": "2023-12-11T01:20:27.211572Z",
          "iopub.status.idle": "2023-12-11T01:20:28.090865Z",
          "shell.execute_reply": "2023-12-11T01:20:28.089822Z",
          "shell.execute_reply.started": "2023-12-11T01:20:27.211832Z"
        },
        "id": "KWkkVcSYciz0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:20:28.093244Z",
          "iopub.status.busy": "2023-12-11T01:20:28.092918Z",
          "iopub.status.idle": "2023-12-11T01:20:28.196861Z",
          "shell.execute_reply": "2023-12-11T01:20:28.195877Z",
          "shell.execute_reply.started": "2023-12-11T01:20:28.093189Z"
        },
        "id": "UE_nECS8cNcb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "categories=['hate','non-hate']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fS0VyeZgagd"
      },
      "source": [
        "# Ktrain indic-SBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "938517513c8c4e14b52c511f2a0612f3",
            "c688388d68a64f5e8144501168fa5187",
            "de2d126ecc2d4e0caede5ebbc72c4254",
            "2f1865d8de7d43388354ba71ca33ad14",
            "dd49ee5fc8ce402dad966a479349b56c",
            "4f421b33540847b680e0dd9816bd6214",
            "43447fdffb9045589b6848258e223168",
            "7030c955a87b499588498b197e72b5c8",
            "bc7a0c38b0264913bb1ceb376da22634",
            "12c0e33d3f7e458b85a92b92216bf2fe",
            "97319b171b754917b74a51a9a17d2367",
            "116ec33856f943838db735673a397cee",
            "56e8dc1790ea4de0baff2c3f206509b3",
            "eef1cb08bb634727b4179456d60f2492",
            "dd7cc3c53b5b4acf8ff7fb5fd8b4eca8",
            "6815b916de45414a9ccaf9ae8cddcac8",
            "ad6e8f1f119a4ceea9ddbc059f5d1f1b",
            "b8cef74c448a4cb6be9e7d963e571c8c",
            "4fed0e6097964903ba615f73ff21b908",
            "5dd74002727649f2a511b5e9b6a68de3",
            "c680e69a02484c05b5ea6ae7ac7e7b86",
            "cd388af043634bdd9bbae8490d6a3e6a",
            "e418fc3c035c4d249b576a97cd90d2ce",
            "6f8191816bf7405795f646abd288d67b"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T09:35:43.281500Z",
          "iopub.status.busy": "2023-12-10T09:35:43.280843Z",
          "iopub.status.idle": "2023-12-10T09:36:18.428041Z",
          "shell.execute_reply": "2023-12-10T09:36:18.427244Z",
          "shell.execute_reply.started": "2023-12-10T09:35:43.281465Z"
        },
        "id": "jAI0Dud2cQ0S",
        "outputId": "359f5922-ae77-440d-8590-cec31aa37dbe",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e418fc3c035c4d249b576a97cd90d2ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f8191816bf7405795f646abd288d67b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/950M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"l3cube-pune/indic-sentence-similarity-sbert\"\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)    #try with mxlen=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "d9accd8a952343999af2a2a86abfff8f",
            "69032b54ce3148f0a66b3f11b83609bf",
            "5fbad6a4354742e5aacd2c09b2fb5b55",
            "be90e1c80a6744d38957f90c6e7573e2",
            "a18bea97121d4b1094032979e7590934",
            "c6ce057e2fe746d0abac55bce48cad31",
            "d5a36bb5742c449ea0dfc0ca454fd201",
            "11a826b8951a439b9647e5fb3a18ee92",
            "3770457988554617932e39a50baccbb0",
            "a357f0cd7d164fb9a4b465731979d5d2",
            "d829bbcbeb6f45bcb721e3bb737bab2a",
            "8cf56fc9bc854403a78d599c92656b33",
            "b50e98b24dc04c0fb659e798550c1394",
            "2e9e3c2b61f64e699189fbb2bf14227d",
            "594598c1b6434e93bd349d8fa983265e",
            "c5a0410ddc8a4e899b21613f4d0a0fd8",
            "55ccdafe9c3e4a56ba2376e5fc4a9bc0",
            "0478335ae8a24f9f98584bae10c1c71f",
            "f9348ffcc0f0442093898ff02d8db534",
            "ac806f30bffc4544a23eee41d65dc024",
            "96c409a1135d45e49a4bff6566adc8ed",
            "4320ece9bf6b4c1ca74de04ccc1fd051",
            "925380a76fec43b2a589aceeaf0da6ed",
            "824f74239e53489aa6508e0b6a6d36ad",
            "948cede7a372446db2889375f3bee7ac",
            "529363f38ea047abb5da9d2c027b20d1",
            "be675bc0ab3b4dfe8298fc708aed8e73",
            "792a5f6336444c0d8c963a8e720e82b0",
            "7674c5fe51284b989bef685f9d6ab817",
            "d93ff724d1b44705a9c0c186b6772b65",
            "701fda7048694980a86ba82a6ef0fd04",
            "4da76e8ac6e342c1aec2db69a88f02b3",
            "9e0db7abffc04e68b2f01c07b491ec5f",
            "a89eb303612744949a5722c082fea59c",
            "af8675b5b57247d58eb97e0917ee32be",
            "10db4460729a4be88b95a2637808ec44",
            "54aa3efd6226408ba169e5ab419ea756",
            "685c3194e18c480594a858e303e2496a",
            "d7be3b72ed6644cf8d89b0488b0f5c60",
            "65de0f9f04034fb69bba8903a9196b31",
            "d71d267ed74a4ee8b8751fdf6a2385c5",
            "e0eedcb5960b4b77860f52fabb2ab4bf",
            "cdab9449ba294b87a0d23767f5d2292d",
            "b088013315874353872057ccc593debf",
            "b4a17b522f1f4286b502431449b16402",
            "da2b1a85494442fab3692735be644586",
            "b977e01f4cc34d88b34874182c47cc65",
            "9a6e9c0981674e2cac8c7773f3773fb6"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T09:37:59.503148Z",
          "iopub.status.busy": "2023-12-10T09:37:59.502759Z",
          "iopub.status.idle": "2023-12-10T09:38:06.861066Z",
          "shell.execute_reply": "2023-12-10T09:38:06.860314Z",
          "shell.execute_reply.started": "2023-12-10T09:37:59.503123Z"
        },
        "id": "2oHB_9PvcoPL",
        "outputId": "0226d5da-8487-4a83-e9ab-8eda26dd4271",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4a17b522f1f4286b502431449b16402",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da2b1a85494442fab3692735be644586",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b977e01f4cc34d88b34874182c47cc65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/6.41M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a6e9c0981674e2cac8c7773f3773fb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T10:01:43.546475Z",
          "iopub.status.busy": "2023-12-10T10:01:43.546069Z",
          "iopub.status.idle": "2023-12-10T10:01:48.210633Z",
          "shell.execute_reply": "2023-12-10T10:01:48.209845Z",
          "shell.execute_reply.started": "2023-12-10T10:01:43.546446Z"
        },
        "id": "WDX1PwovcrM0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = trans.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T01:46:19.943455Z",
          "iopub.status.busy": "2023-12-04T01:46:19.942478Z",
          "iopub.status.idle": "2023-12-04T01:52:24.726063Z",
          "shell.execute_reply": "2023-12-04T01:52:24.725114Z",
          "shell.execute_reply.started": "2023-12-04T01:46:19.943415Z"
        },
        "id": "WHGPTimg53_W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# learner.lr_find(show_plot = True,max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T10:01:56.709557Z",
          "iopub.status.busy": "2023-12-10T10:01:56.708685Z",
          "iopub.status.idle": "2023-12-10T10:22:43.021940Z",
          "shell.execute_reply": "2023-12-10T10:22:43.020943Z",
          "shell.execute_reply.started": "2023-12-10T10:01:56.709527Z"
        },
        "id": "arbcJdIXdxWG",
        "outputId": "969dec1f-5d3a-4327-de6e-0f602aef8da6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 83s 260ms/step - loss: 0.6803 - accuracy: 0.6693 - val_loss: 0.6886 - val_accuracy: 0.5260\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.6126 - accuracy: 0.7550 - val_loss: 0.6488 - val_accuracy: 0.6260\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.5323 - accuracy: 0.7958 - val_loss: 0.6054 - val_accuracy: 0.6900\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.4561 - accuracy: 0.8285 - val_loss: 0.6159 - val_accuracy: 0.6840\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.3951 - accuracy: 0.8530 - val_loss: 0.5858 - val_accuracy: 0.7280\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.3358 - accuracy: 0.8817 - val_loss: 0.6772 - val_accuracy: 0.6940\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.2803 - accuracy: 0.9068 - val_loss: 0.7015 - val_accuracy: 0.7080\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.2294 - accuracy: 0.9298 - val_loss: 0.7173 - val_accuracy: 0.7080\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.1996 - accuracy: 0.9375 - val_loss: 0.7831 - val_accuracy: 0.7060\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.1708 - accuracy: 0.9490 - val_loss: 0.7749 - val_accuracy: 0.7060\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.1409 - accuracy: 0.9607 - val_loss: 0.7340 - val_accuracy: 0.7240\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.1141 - accuracy: 0.9718 - val_loss: 0.8318 - val_accuracy: 0.7320\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0977 - accuracy: 0.9768 - val_loss: 0.9342 - val_accuracy: 0.7160\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 0.0872 - accuracy: 0.9785 - val_loss: 0.9779 - val_accuracy: 0.7160\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0765 - accuracy: 0.9800 - val_loss: 0.9450 - val_accuracy: 0.7300\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0707 - accuracy: 0.9830 - val_loss: 0.9147 - val_accuracy: 0.7320\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0633 - accuracy: 0.9850 - val_loss: 0.9777 - val_accuracy: 0.7240\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0545 - accuracy: 0.9887 - val_loss: 1.0631 - val_accuracy: 0.7180\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0529 - accuracy: 0.9880 - val_loss: 1.0211 - val_accuracy: 0.7200\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.0509 - accuracy: 0.9875 - val_loss: 1.0304 - val_accuracy: 0.7220\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cc1b5c9fd60>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learner.fit_onecycle(3e-5, 20)   # 15 epochs 70(macro) for 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T10:28:23.286486Z",
          "iopub.status.busy": "2023-12-10T10:28:23.286055Z",
          "iopub.status.idle": "2023-12-10T10:28:27.612090Z",
          "shell.execute_reply": "2023-12-10T10:28:27.611175Z",
          "shell.execute_reply.started": "2023-12-10T10:28:23.286454Z"
        },
        "id": "X7dm0bubep_k",
        "outputId": "3f07f75f-ed1a-4f6d-9d3e-11d1686fb402",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 4s 70ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.73      0.70      0.72       250\n",
            "    non-hate       0.71      0.74      0.73       250\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.72      0.72      0.72       500\n",
            "weighted avg       0.72      0.72      0.72       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[176,  74],\n",
              "       [ 65, 185]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T10:29:49.519404Z",
          "iopub.status.busy": "2023-12-10T10:29:49.518547Z",
          "iopub.status.idle": "2023-12-10T10:29:49.620180Z",
          "shell.execute_reply": "2023-12-10T10:29:49.619070Z",
          "shell.execute_reply.started": "2023-12-10T10:29:49.519375Z"
        },
        "id": "OE1guz_n53_X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T10:29:57.670509Z",
          "iopub.status.busy": "2023-12-10T10:29:57.669649Z",
          "iopub.status.idle": "2023-12-10T10:30:00.665699Z",
          "shell.execute_reply": "2023-12-10T10:30:00.664899Z",
          "shell.execute_reply.started": "2023-12-10T10:29:57.670478Z"
        },
        "id": "eNz-12Z653_Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "folder_path = \"/kaggle/working/\"\n",
        "\n",
        "predictor.save(folder_path+'Transformers_Models'+'/puneIndicSBERT_1eMinus5_16_20')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hiIJk0AQkxY"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.load_predictor(\"/content/drive/MyDrive/Colab Notebooks/HOLD/\"+'Transformers_Models'+'/puneIndicSBERT_1eMinus5_16_20')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:13:45.329273Z",
          "iopub.status.busy": "2023-12-04T02:13:45.327992Z",
          "iopub.status.idle": "2023-12-04T02:13:50.015647Z",
          "shell.execute_reply": "2023-12-04T02:13:50.014525Z",
          "shell.execute_reply.started": "2023-12-04T02:13:45.329223Z"
        },
        "id": "immEomdO53_Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:13:50.018719Z",
          "iopub.status.busy": "2023-12-04T02:13:50.017871Z",
          "iopub.status.idle": "2023-12-04T02:13:50.134142Z",
          "shell.execute_reply": "2023-12-04T02:13:50.133155Z",
          "shell.execute_reply.started": "2023-12-04T02:13:50.018677Z"
        },
        "id": "j6NOHlZm53_Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run = pd.DataFrame(test_df['text'])\n",
        "run['label'] = y_pred\n",
        "# run\n",
        "run['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:14:03.180855Z",
          "iopub.status.busy": "2023-12-04T02:14:03.180463Z",
          "iopub.status.idle": "2023-12-04T02:14:03.289790Z",
          "shell.execute_reply": "2023-12-04T02:14:03.288602Z",
          "shell.execute_reply.started": "2023-12-04T02:14:03.180824Z"
        },
        "id": "as_WTm6253_Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run.to_csv('/kaggle/working/' +'model1.csv',index = False) # for 3e-5, batch = 16, epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:14:56.216814Z",
          "iopub.status.busy": "2023-12-04T02:14:56.216437Z",
          "iopub.status.idle": "2023-12-04T02:14:56.324144Z",
          "shell.execute_reply": "2023-12-04T02:14:56.323111Z",
          "shell.execute_reply.started": "2023-12-04T02:14:56.216784Z"
        },
        "id": "UaT9VxIJ53_Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run.to_csv('/kaggle/working/' +'model1.tsv',index = False) # for 3e-5, batch = 16, epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T10:31:46.567731Z",
          "iopub.status.busy": "2023-12-10T10:31:46.567355Z",
          "iopub.status.idle": "2023-12-10T10:45:29.519565Z",
          "shell.execute_reply": "2023-12-10T10:45:29.518573Z",
          "shell.execute_reply.started": "2023-12-10T10:31:46.567691Z"
        },
        "id": "uTEz7nFl53_Z",
        "outputId": "701dd760-b00e-4c83-ca9e-da9e14705060",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/15\n",
            "125/125 [==============================] - 73s 444ms/step - loss: 0.6836 - accuracy: 0.6622 - val_loss: 0.6896 - val_accuracy: 0.5180\n",
            "Epoch 2/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.6250 - accuracy: 0.7415 - val_loss: 0.6461 - val_accuracy: 0.6400\n",
            "Epoch 3/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.5370 - accuracy: 0.7968 - val_loss: 0.5951 - val_accuracy: 0.7040\n",
            "Epoch 4/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.4635 - accuracy: 0.8210 - val_loss: 0.5785 - val_accuracy: 0.7180\n",
            "Epoch 5/15\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.3754 - accuracy: 0.8695 - val_loss: 0.6123 - val_accuracy: 0.7060\n",
            "Epoch 6/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.3175 - accuracy: 0.8910 - val_loss: 0.6079 - val_accuracy: 0.7200\n",
            "Epoch 7/15\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.2573 - accuracy: 0.9178 - val_loss: 0.6372 - val_accuracy: 0.7260\n",
            "Epoch 8/15\n",
            "125/125 [==============================] - 52s 415ms/step - loss: 0.2224 - accuracy: 0.9302 - val_loss: 0.6701 - val_accuracy: 0.7460\n",
            "Epoch 9/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.1733 - accuracy: 0.9503 - val_loss: 0.7459 - val_accuracy: 0.7340\n",
            "Epoch 10/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.1497 - accuracy: 0.9592 - val_loss: 0.7480 - val_accuracy: 0.7380\n",
            "Epoch 11/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.1322 - accuracy: 0.9638 - val_loss: 0.7719 - val_accuracy: 0.7160\n",
            "Epoch 12/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.1127 - accuracy: 0.9725 - val_loss: 0.8386 - val_accuracy: 0.7280\n",
            "Epoch 13/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.0976 - accuracy: 0.9778 - val_loss: 0.8601 - val_accuracy: 0.7240\n",
            "Epoch 14/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.0873 - accuracy: 0.9812 - val_loss: 0.8919 - val_accuracy: 0.7300\n",
            "Epoch 15/15\n",
            "125/125 [==============================] - 52s 414ms/step - loss: 0.0845 - accuracy: 0.9812 - val_loss: 0.8857 - val_accuracy: 0.7300\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cbdd26db760>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = trans.get_classifier()\n",
        "learner2 = ktrain.get_learner(model2, train_data=train,val_data=test, batch_size=32)\n",
        "learner2.fit_onecycle(3e-5,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T11:03:54.349694Z",
          "iopub.status.busy": "2023-12-10T11:03:54.349273Z",
          "iopub.status.idle": "2023-12-10T11:03:55.691445Z",
          "shell.execute_reply": "2023-12-10T11:03:55.690530Z",
          "shell.execute_reply.started": "2023-12-10T11:03:54.349664Z"
        },
        "id": "mfKT0nE-53_a",
        "outputId": "2c075d77-9452-4ec1-beb2-e66085f6e7ea",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 71ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.72      0.74      0.73       250\n",
            "    non-hate       0.74      0.72      0.73       250\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.73      0.73      0.73       500\n",
            "weighted avg       0.73      0.73      0.73       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[186,  64],\n",
              "       [ 71, 179]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "learner2.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:37:11.129760Z",
          "iopub.status.busy": "2023-12-04T02:37:11.129000Z",
          "iopub.status.idle": "2023-12-04T02:37:20.940562Z",
          "shell.execute_reply": "2023-12-04T02:37:20.939408Z",
          "shell.execute_reply.started": "2023-12-04T02:37:11.129728Z"
        },
        "id": "572N_1GI53_a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner2.model, preproc=trans)\n",
        "ffolder_path = \"/kaggle/working/\"\n",
        "\n",
        "predictor.save(folder_path+'Transformers_Models'+'/puneIndicSBERT_1eMinus5_32_15')\n",
        "\n",
        "predictor = ktrain.load_predictor(folder_path+'Transformers_Models'+'/puneIndicSBERT_1eMinus5_32_15')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6T1zPVSBJQ0"
      },
      "outputs": [],
      "source": [
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc-r16VcBGpy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(y_data_with_label, y_pred)\n",
        "report = classification_report(y_data_with_label, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2023-12-04T02:37:20.942498Z",
          "iopub.status.busy": "2023-12-04T02:37:20.942210Z",
          "iopub.status.idle": "2023-12-04T02:37:21.044211Z",
          "shell.execute_reply": "2023-12-04T02:37:21.043283Z",
          "shell.execute_reply.started": "2023-12-04T02:37:20.942474Z"
        },
        "id": "4Yg6pArW53_a",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = predictor.predict(X_test)\n",
        "run = pd.DataFrame(test_df['text'])\n",
        "run['label'] = y_pred\n",
        "# run\n",
        "run['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:37:24.429951Z",
          "iopub.status.busy": "2023-12-04T02:37:24.429078Z",
          "iopub.status.idle": "2023-12-04T02:37:24.534200Z",
          "shell.execute_reply": "2023-12-04T02:37:24.533306Z",
          "shell.execute_reply.started": "2023-12-04T02:37:24.429917Z"
        },
        "id": "wof04ciw53_a",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run.to_csv('/kaggle/working/' +'model2.csv',index = False) # for 3e-5, batch = 16, epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-04T02:37:28.626131Z",
          "iopub.status.busy": "2023-12-04T02:37:28.625256Z",
          "iopub.status.idle": "2023-12-04T02:37:28.737428Z",
          "shell.execute_reply": "2023-12-04T02:37:28.736682Z",
          "shell.execute_reply.started": "2023-12-04T02:37:28.626097Z"
        },
        "id": "H7p5WHar53_a",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run.to_csv('/kaggle/working/' +'model2.tsv',index = False) # for 3e-5, batch = 16, epochs = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNUm-9FO53_c"
      },
      "source": [
        "# Ktrain indicBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6518f29140904bb9ab3c988ca963ba63",
            "e0fa56ec6b764cf9b164e99c196d85f1",
            "2c8add1ad1fa4562a0c50436ac5eec9b"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-11T01:20:28.198786Z",
          "iopub.status.busy": "2023-12-11T01:20:28.198445Z",
          "iopub.status.idle": "2023-12-11T01:20:50.790647Z",
          "shell.execute_reply": "2023-12-11T01:20:50.789618Z",
          "shell.execute_reply.started": "2023-12-11T01:20:28.198739Z"
        },
        "id": "jM2dtDsG53_c",
        "outputId": "eceadf58-81dd-4167-f1d2-456fc2160dd5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6518f29140904bb9ab3c988ca963ba63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0fa56ec6b764cf9b164e99c196d85f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c8add1ad1fa4562a0c50436ac5eec9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'ai4bharat/indic-bert'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()\n",
        "Indiclearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.873945Z",
          "iopub.status.idle": "2023-12-04T01:40:12.874429Z",
          "shell.execute_reply": "2023-12-04T01:40:12.874203Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.874182Z"
        },
        "id": "Mu2Ffrpb53_d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Indiclearner.lr_find(show_plot = True,max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:20:50.792748Z",
          "iopub.status.busy": "2023-12-11T01:20:50.792014Z",
          "iopub.status.idle": "2023-12-11T01:30:32.736558Z",
          "shell.execute_reply": "2023-12-11T01:30:32.735467Z",
          "shell.execute_reply.started": "2023-12-11T01:20:50.792711Z"
        },
        "id": "d2T39qyA53_d",
        "outputId": "0fe7e002-43e9-4f5f-a524-95375050f6e0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 77s 227ms/step - loss: 0.6906 - accuracy: 0.5167 - val_loss: 0.7085 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.6724 - accuracy: 0.5895 - val_loss: 0.7527 - val_accuracy: 0.3860\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.6552 - accuracy: 0.6553 - val_loss: 0.6956 - val_accuracy: 0.5420\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.6153 - accuracy: 0.6875 - val_loss: 0.7141 - val_accuracy: 0.5420\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.5587 - accuracy: 0.7312 - val_loss: 0.6614 - val_accuracy: 0.6200\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.5096 - accuracy: 0.7697 - val_loss: 0.6815 - val_accuracy: 0.5980\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 52s 208ms/step - loss: 0.4467 - accuracy: 0.8055 - val_loss: 0.7328 - val_accuracy: 0.6240\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.3680 - accuracy: 0.8487 - val_loss: 0.7493 - val_accuracy: 0.6480\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.3045 - accuracy: 0.8890 - val_loss: 0.9021 - val_accuracy: 0.6380\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 52s 207ms/step - loss: 0.2608 - accuracy: 0.9147 - val_loss: 0.9228 - val_accuracy: 0.6360\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb8b25a5690>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Indiclearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-11T01:30:32.738286Z",
          "iopub.status.busy": "2023-12-11T01:30:32.737951Z",
          "iopub.status.idle": "2023-12-11T01:30:37.586237Z",
          "shell.execute_reply": "2023-12-11T01:30:37.585251Z",
          "shell.execute_reply.started": "2023-12-11T01:30:32.738258Z"
        },
        "id": "m-jMxvER53_e",
        "outputId": "8af7b2df-f9e7-4de7-ee7c-8d2a6735abd9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 5s 85ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.66      0.56      0.61       250\n",
            "    non-hate       0.62      0.71      0.66       250\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.64      0.64      0.63       500\n",
            "weighted avg       0.64      0.64      0.63       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[141, 109],\n",
              "       [ 73, 177]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Indiclearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.880548Z",
          "iopub.status.idle": "2023-12-04T01:40:12.880881Z",
          "shell.execute_reply": "2023-12-04T01:40:12.880735Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.880719Z"
        },
        "id": "ajLXNb9153_e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(Indiclearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.882031Z",
          "iopub.status.idle": "2023-12-04T01:40:12.882391Z",
          "shell.execute_reply": "2023-12-04T01:40:12.882213Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.882198Z"
        },
        "id": "Ug_2Nvew53_e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run = pd.DataFrame(test_df['text'])\n",
        "run['label'] = y_pred\n",
        "# run\n",
        "run['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.883466Z",
          "iopub.status.idle": "2023-12-04T01:40:12.883850Z",
          "shell.execute_reply": "2023-12-04T01:40:12.883659Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.883639Z"
        },
        "id": "80pzeZxd53_e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "run.to_csv('/kaggle/working/' +'Tamil_Hate_Indic_72_cw.csv',index = False) # for 3e-5, batch = 16, epochs = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtl_Lbo453_e"
      },
      "source": [
        "# Ktrain mBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "15276f5f0ed04aa0bc875e3d1c527346",
            "a56fc785279b4231af60e479ad69a802"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T06:52:07.800158Z",
          "iopub.status.busy": "2023-12-10T06:52:07.799757Z",
          "iopub.status.idle": "2023-12-10T06:52:22.240472Z",
          "shell.execute_reply": "2023-12-10T06:52:22.239474Z",
          "shell.execute_reply.started": "2023-12-10T06:52:07.800125Z"
        },
        "id": "q_uEfOPM53_f",
        "outputId": "7cdf90a8-1f64-405e-ca1d-51968450378a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15276f5f0ed04aa0bc875e3d1c527346",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a56fc785279b4231af60e479ad69a802",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T06:53:38.909788Z",
          "iopub.status.busy": "2023-12-10T06:53:38.909112Z",
          "iopub.status.idle": "2023-12-10T06:53:44.212319Z",
          "shell.execute_reply": "2023-12-10T06:53:44.211468Z",
          "shell.execute_reply.started": "2023-12-10T06:53:38.909754Z"
        },
        "id": "NRq3XXngQkxf",
        "outputId": "09f7eb42-2fc1-490b-a2df-1fbe053f8507",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: te\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: te\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()\n",
        "CasedmBertlearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.886408Z",
          "iopub.status.idle": "2023-12-04T01:40:12.886845Z",
          "shell.execute_reply": "2023-12-04T01:40:12.886641Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.886619Z"
        },
        "id": "VP5YMm9D53_f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# CasedmBertlearner.lr_find(show_plot = True,max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T06:54:29.047229Z",
          "iopub.status.busy": "2023-12-10T06:54:29.046692Z",
          "iopub.status.idle": "2023-12-10T07:05:14.225721Z",
          "shell.execute_reply": "2023-12-10T07:05:14.224702Z",
          "shell.execute_reply.started": "2023-12-10T06:54:29.047185Z"
        },
        "id": "tg_4uWrZ53_g",
        "outputId": "8e3c3bf0-4823-4da5-b075-ea2da9bfc955",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 87s 251ms/step - loss: 0.6647 - accuracy: 0.6020 - val_loss: 0.7843 - val_accuracy: 0.4140\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.5792 - accuracy: 0.6990 - val_loss: 0.7263 - val_accuracy: 0.5940\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.5001 - accuracy: 0.7588 - val_loss: 0.6011 - val_accuracy: 0.6860\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.4126 - accuracy: 0.8165 - val_loss: 0.8348 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 58s 234ms/step - loss: 0.3194 - accuracy: 0.8620 - val_loss: 0.6973 - val_accuracy: 0.7140\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 58s 234ms/step - loss: 0.2344 - accuracy: 0.9082 - val_loss: 0.9039 - val_accuracy: 0.6700\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.1433 - accuracy: 0.9465 - val_loss: 0.9420 - val_accuracy: 0.7140\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 58s 234ms/step - loss: 0.0905 - accuracy: 0.9690 - val_loss: 1.1401 - val_accuracy: 0.6860\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.0631 - accuracy: 0.9827 - val_loss: 1.2528 - val_accuracy: 0.6780\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 59s 234ms/step - loss: 0.0457 - accuracy: 0.9868 - val_loss: 1.2298 - val_accuracy: 0.6900\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b236babc7f0>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:05:21.215430Z",
          "iopub.status.busy": "2023-12-10T07:05:21.215071Z",
          "iopub.status.idle": "2023-12-10T07:05:22.918359Z",
          "shell.execute_reply": "2023-12-10T07:05:22.917384Z",
          "shell.execute_reply.started": "2023-12-10T07:05:21.215396Z"
        },
        "id": "AncG3TVX53_g",
        "outputId": "7a19fc0a-077a-48af-f0f9-52e6abb9d072",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 2s 94ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.68      0.70      0.69       250\n",
            "    non-hate       0.70      0.68      0.69       250\n",
            "\n",
            "    accuracy                           0.69       500\n",
            "   macro avg       0.69      0.69      0.69       500\n",
            "weighted avg       0.69      0.69      0.69       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[176,  74],\n",
              "       [ 81, 169]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:05:44.419920Z",
          "iopub.status.busy": "2023-12-10T07:05:44.419274Z",
          "iopub.status.idle": "2023-12-10T07:05:46.256735Z",
          "shell.execute_reply": "2023-12-10T07:05:46.255661Z",
          "shell.execute_reply.started": "2023-12-10T07:05:44.419891Z"
        },
        "id": "zZ-vbH3M53_h",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(CasedmBertlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6paYwL3y53_i"
      },
      "source": [
        "# Ktrain XLMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5f7cd72b9b294035837c66e381c471f4",
            "b5db9294beac45dfb79e0a0c228e8c6d",
            "4caccf3d3d03454abc939f37160b2b86",
            "64dbd14029244023907ecff75270329c"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T07:06:51.818436Z",
          "iopub.status.busy": "2023-12-10T07:06:51.818039Z",
          "iopub.status.idle": "2023-12-10T07:07:13.837162Z",
          "shell.execute_reply": "2023-12-10T07:07:13.836251Z",
          "shell.execute_reply.started": "2023-12-10T07:06:51.818406Z"
        },
        "id": "N6JwTmwc53_i",
        "outputId": "99cf5002-b0f2-46f8-e44c-bbaeef4f1a6c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7cd72b9b294035837c66e381c471f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5db9294beac45dfb79e0a0c228e8c6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4caccf3d3d03454abc939f37160b2b86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64dbd14029244023907ecff75270329c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (â€¦)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'xlm-roberta-base'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()\n",
        "XLlearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.897092Z",
          "iopub.status.idle": "2023-12-04T01:40:12.897589Z",
          "shell.execute_reply": "2023-12-04T01:40:12.897321Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.897300Z"
        },
        "id": "dkomN_cR53_i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "XLlearner.lr_find(show_plot = True,max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:07:13.864362Z",
          "iopub.status.busy": "2023-12-10T07:07:13.863960Z",
          "iopub.status.idle": "2023-12-10T07:18:18.675666Z",
          "shell.execute_reply": "2023-12-10T07:18:18.674840Z",
          "shell.execute_reply.started": "2023-12-10T07:07:13.864332Z"
        },
        "id": "IVnz6rQ553_j",
        "outputId": "ad6f4e50-8ad0-4033-ae38-3db50bbb1b17",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 90s 272ms/step - loss: 0.6669 - accuracy: 0.6030 - val_loss: 0.7457 - val_accuracy: 0.4860\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 64s 256ms/step - loss: 0.5913 - accuracy: 0.6890 - val_loss: 0.6905 - val_accuracy: 0.5460\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.5311 - accuracy: 0.7350 - val_loss: 0.5722 - val_accuracy: 0.7080\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.4924 - accuracy: 0.7648 - val_loss: 0.5981 - val_accuracy: 0.6700\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.4657 - accuracy: 0.7822 - val_loss: 0.6109 - val_accuracy: 0.6840\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.3971 - accuracy: 0.8195 - val_loss: 0.6864 - val_accuracy: 0.7100\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.3347 - accuracy: 0.8572 - val_loss: 0.7321 - val_accuracy: 0.6900\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 64s 256ms/step - loss: 0.2785 - accuracy: 0.8903 - val_loss: 0.8574 - val_accuracy: 0.7080\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.2206 - accuracy: 0.9170 - val_loss: 0.7511 - val_accuracy: 0.7300\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.1848 - accuracy: 0.9317 - val_loss: 0.8938 - val_accuracy: 0.7180\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b236b90ba00>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XLlearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:18:22.246233Z",
          "iopub.status.busy": "2023-12-10T07:18:22.245457Z",
          "iopub.status.idle": "2023-12-10T07:18:26.739723Z",
          "shell.execute_reply": "2023-12-10T07:18:26.738904Z",
          "shell.execute_reply.started": "2023-12-10T07:18:22.246199Z"
        },
        "id": "2ny7kHt253_j",
        "outputId": "9cd43ab0-326e-41a7-f2ad-4bb5c6758bd2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 4s 71ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.71      0.75      0.73       250\n",
            "    non-hate       0.73      0.69      0.71       250\n",
            "\n",
            "    accuracy                           0.72       500\n",
            "   macro avg       0.72      0.72      0.72       500\n",
            "weighted avg       0.72      0.72      0.72       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[187,  63],\n",
              "       [ 78, 172]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XLlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:18:46.072938Z",
          "iopub.status.busy": "2023-12-10T07:18:46.072516Z",
          "iopub.status.idle": "2023-12-10T07:18:47.563310Z",
          "shell.execute_reply": "2023-12-10T07:18:47.561983Z",
          "shell.execute_reply.started": "2023-12-10T07:18:46.072911Z"
        },
        "id": "ME_HiZYj53_j",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(XLlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkJ0caVu53_k"
      },
      "source": [
        "# Ktrain DistilmBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cc3a271c5f0b43f1b3dd458ade8ea73e",
            "07092145b5d8476baa2e9a86580098d2",
            "8934e96c911f4c2092df0da70322c5ff",
            "2c4caa25f8bd4db7b37f04d40468eb43",
            "13402fb38b2247d19e0e5f6afdcb28ee"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T07:19:15.959718Z",
          "iopub.status.busy": "2023-12-10T07:19:15.959312Z",
          "iopub.status.idle": "2023-12-10T07:19:27.173809Z",
          "shell.execute_reply": "2023-12-10T07:19:27.172635Z",
          "shell.execute_reply.started": "2023-12-10T07:19:15.959687Z"
        },
        "id": "gdlYign153_k",
        "outputId": "b7dd2351-ceab-464c-996b-0f82ff1d22bb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc3a271c5f0b43f1b3dd458ade8ea73e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07092145b5d8476baa2e9a86580098d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8934e96c911f4c2092df0da70322c5ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c4caa25f8bd4db7b37f04d40468eb43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13402fb38b2247d19e0e5f6afdcb28ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'distilbert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()\n",
        "Distillearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.906519Z",
          "iopub.status.idle": "2023-12-04T01:40:12.906822Z",
          "shell.execute_reply": "2023-12-04T01:40:12.906684Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.906670Z"
        },
        "id": "vC9mLiJa53_l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Distillearner.lr_find(show_plot = True,max_epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:19:27.326022Z",
          "iopub.status.busy": "2023-12-10T07:19:27.325111Z",
          "iopub.status.idle": "2023-12-10T07:25:07.406130Z",
          "shell.execute_reply": "2023-12-10T07:25:07.405226Z",
          "shell.execute_reply.started": "2023-12-10T07:19:27.325972Z"
        },
        "id": "h4YOGDt553_l",
        "outputId": "f57193ad-0de9-4c94-b7ef-93b5eb52b36d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 46s 140ms/step - loss: 0.6451 - accuracy: 0.6330 - val_loss: 0.7364 - val_accuracy: 0.4820\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.5459 - accuracy: 0.7303 - val_loss: 0.7180 - val_accuracy: 0.5960\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.4477 - accuracy: 0.7930 - val_loss: 0.7408 - val_accuracy: 0.6320\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.3794 - accuracy: 0.8365 - val_loss: 0.6946 - val_accuracy: 0.6680\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.2862 - accuracy: 0.8840 - val_loss: 0.7152 - val_accuracy: 0.7020\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.2029 - accuracy: 0.9200 - val_loss: 0.8195 - val_accuracy: 0.6800\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.1206 - accuracy: 0.9600 - val_loss: 1.0927 - val_accuracy: 0.6600\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.0866 - accuracy: 0.9728 - val_loss: 1.2232 - val_accuracy: 0.6640\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.0553 - accuracy: 0.9820 - val_loss: 1.2829 - val_accuracy: 0.6640\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.0438 - accuracy: 0.9880 - val_loss: 1.3067 - val_accuracy: 0.6700\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b236b433220>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:36:00.597407Z",
          "iopub.status.busy": "2023-12-10T07:36:00.596609Z",
          "iopub.status.idle": "2023-12-10T07:36:03.220547Z",
          "shell.execute_reply": "2023-12-10T07:36:03.219621Z",
          "shell.execute_reply.started": "2023-12-10T07:36:00.597363Z"
        },
        "id": "9Bu_frxa53_l",
        "outputId": "ed964a10-878c-4ad1-82bb-affdc9617529",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 2s 49ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.67      0.68      0.67       250\n",
            "    non-hate       0.67      0.66      0.67       250\n",
            "\n",
            "    accuracy                           0.67       500\n",
            "   macro avg       0.67      0.67      0.67       500\n",
            "weighted avg       0.67      0.67      0.67       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[170,  80],\n",
              "       [ 85, 165]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.912809Z",
          "iopub.status.idle": "2023-12-04T01:40:12.913147Z",
          "shell.execute_reply": "2023-12-04T01:40:12.912994Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.912978Z"
        },
        "id": "ORwYAlI753_m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(XLlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4g1qlDpQkxj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(test_with_label['label'], y_pred)\n",
        "report = classification_report(test_with_label['label'], y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG3tcNbW53_m"
      },
      "source": [
        "# Ktrain mBert Uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6ea838633e714beb948a41f732d3d29a",
            "9b4e9ca129c944ff9a64a628c47f9024",
            "06d9165c48974f75a0af6c570274c376",
            "1f5103c38bf343c6930346577f8446d5",
            "1122d0a2b7fc457d8ee4f3bb5df5c04a"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T07:37:10.716555Z",
          "iopub.status.busy": "2023-12-10T07:37:10.716164Z",
          "iopub.status.idle": "2023-12-10T07:37:24.907809Z",
          "shell.execute_reply": "2023-12-10T07:37:24.906830Z",
          "shell.execute_reply.started": "2023-12-10T07:37:10.716524Z"
        },
        "id": "IVtAuToe53_n",
        "outputId": "cb810341-6cba-4d8f-bea7-420e56d19cba",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ea838633e714beb948a41f732d3d29a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b4e9ca129c944ff9a64a628c47f9024",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06d9165c48974f75a0af6c570274c376",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f5103c38bf343c6930346577f8446d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1122d0a2b7fc457d8ee4f3bb5df5c04a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-uncased'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()\n",
        "mBertUncasedLearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.916103Z",
          "iopub.status.idle": "2023-12-04T01:40:12.916468Z",
          "shell.execute_reply": "2023-12-04T01:40:12.916288Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.916273Z"
        },
        "id": "6S5ZcHYP53_n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mBertUncasedLearner.lr_find(show_plot = True,max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:37:39.454825Z",
          "iopub.status.busy": "2023-12-10T07:37:39.453449Z",
          "iopub.status.idle": "2023-12-10T07:47:39.739963Z",
          "shell.execute_reply": "2023-12-10T07:47:39.738991Z",
          "shell.execute_reply.started": "2023-12-10T07:37:39.454773Z"
        },
        "id": "AmqNoW0A53_n",
        "outputId": "2beaa593-41b4-47fc-8faf-b8f352e06480",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 81s 246ms/step - loss: 0.6446 - accuracy: 0.6205 - val_loss: 0.7717 - val_accuracy: 0.5240\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.5361 - accuracy: 0.7260 - val_loss: 0.6612 - val_accuracy: 0.6380\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.4413 - accuracy: 0.7933 - val_loss: 0.6860 - val_accuracy: 0.6360\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.3387 - accuracy: 0.8550 - val_loss: 0.9592 - val_accuracy: 0.6160\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 58s 230ms/step - loss: 0.2607 - accuracy: 0.8920 - val_loss: 0.9953 - val_accuracy: 0.6520\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.1729 - accuracy: 0.9348 - val_loss: 0.9448 - val_accuracy: 0.6660\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.1048 - accuracy: 0.9615 - val_loss: 0.9309 - val_accuracy: 0.7280\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 1.2660 - val_accuracy: 0.6620\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.0420 - accuracy: 0.9862 - val_loss: 1.4176 - val_accuracy: 0.6560\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 58s 231ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 1.4342 - val_accuracy: 0.6500\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b236b90b730>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-10T07:47:39.741798Z",
          "iopub.status.busy": "2023-12-10T07:47:39.741510Z",
          "iopub.status.idle": "2023-12-10T07:47:44.436359Z",
          "shell.execute_reply": "2023-12-10T07:47:44.435428Z",
          "shell.execute_reply.started": "2023-12-10T07:47:39.741773Z"
        },
        "id": "JykVORpp53_n",
        "outputId": "e8e95d64-2d99-4187-e580-b2c35764149a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 5s 77ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.63      0.71      0.67       250\n",
            "    non-hate       0.67      0.59      0.63       250\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.65      0.65      0.65       500\n",
            "weighted avg       0.65      0.65      0.65       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[177,  73],\n",
              "       [102, 148]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.920668Z",
          "iopub.status.idle": "2023-12-04T01:40:12.920967Z",
          "shell.execute_reply": "2023-12-04T01:40:12.920831Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.920817Z"
        },
        "id": "ULLB0TN453_o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(XLlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64F6_rRR53_o"
      },
      "source": [
        "# Ktrain MuRIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T07:47:44.437656Z",
          "iopub.status.busy": "2023-12-10T07:47:44.437395Z",
          "iopub.status.idle": "2023-12-10T07:48:22.277714Z",
          "shell.execute_reply": "2023-12-10T07:48:22.276843Z",
          "shell.execute_reply.started": "2023-12-10T07:47:44.437633Z"
        },
        "id": "FSP3NScK53_o",
        "outputId": "bfc995e6-783e-49f1-93ba-827bd3858a79",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 10\n",
            "\t95percentile : 21\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 7\n",
            "\t95percentile : 13\n",
            "\t99percentile : 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'google/muril-base-cased'\n",
        "trans = text.Transformer(model_name,maxlen=100,class_names=categories)\n",
        "train = trans.preprocess_train(train_df['cleanText'].tolist(), train_df['enc_label'].tolist())\n",
        "test = trans.preprocess_test(X_test, y_data_with_label)\n",
        "model = trans.get_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "wFzuWox5euM4"
      },
      "outputs": [],
      "source": [
        "MuRILlearner = ktrain.get_learner(model, train_data=train,val_data=test, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-04T01:40:12.923647Z",
          "iopub.status.idle": "2023-12-04T01:40:12.924088Z",
          "shell.execute_reply": "2023-12-04T01:40:12.923879Z",
          "shell.execute_reply.started": "2023-12-04T01:40:12.923857Z"
        },
        "id": "MDozXfcY53_o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MuRILlearner.lr_find(show_plot = True,max_epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T07:48:22.280373Z",
          "iopub.status.busy": "2023-12-10T07:48:22.279992Z",
          "iopub.status.idle": "2023-12-10T08:00:02.007343Z",
          "shell.execute_reply": "2023-12-10T08:00:02.006341Z",
          "shell.execute_reply.started": "2023-12-10T07:48:22.280348Z"
        },
        "id": "92nHCRZ-Qkxm",
        "outputId": "c0810a41-ce5e-4f46-bb37-496d21b36950",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 128s 420ms/step - loss: 0.6895 - accuracy: 0.5525 - val_loss: 0.7041 - val_accuracy: 0.4020\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 0.6273 - accuracy: 0.6948 - val_loss: 0.6594 - val_accuracy: 0.6420\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 102s 408ms/step - loss: 0.5099 - accuracy: 0.7695 - val_loss: 0.5990 - val_accuracy: 0.6960\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 104s 416ms/step - loss: 0.3984 - accuracy: 0.8342 - val_loss: 0.6614 - val_accuracy: 0.6720\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 0.3083 - accuracy: 0.8835 - val_loss: 0.6732 - val_accuracy: 0.6920\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 101s 406ms/step - loss: 0.2395 - accuracy: 0.9140 - val_loss: 0.6287 - val_accuracy: 0.7360\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 0.1370 - accuracy: 0.9582 - val_loss: 0.7014 - val_accuracy: 0.7260\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 101s 402ms/step - loss: 0.0976 - accuracy: 0.9737 - val_loss: 0.9774 - val_accuracy: 0.7200\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 0.0696 - accuracy: 0.9835 - val_loss: 0.9164 - val_accuracy: 0.7480\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 0.0614 - accuracy: 0.9860 - val_loss: 0.9375 - val_accuracy: 0.7340\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7886c97ef400>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MuRILlearner.fit_onecycle(3e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-10T08:00:07.959802Z",
          "iopub.status.busy": "2023-12-10T08:00:07.959473Z",
          "iopub.status.idle": "2023-12-10T08:00:10.778089Z",
          "shell.execute_reply": "2023-12-10T08:00:10.777062Z",
          "shell.execute_reply.started": "2023-12-10T08:00:07.959775Z"
        },
        "id": "kTpAPHVKQkxm",
        "outputId": "a5676f4a-01f1-44b2-f356-aed43d530f21",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 6s 130ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.73      0.74      0.74       250\n",
            "    non-hate       0.74      0.72      0.73       250\n",
            "\n",
            "    accuracy                           0.73       500\n",
            "   macro avg       0.73      0.73      0.73       500\n",
            "weighted avg       0.73      0.73      0.73       500\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[186,  64],\n",
              "       [ 69, 181]])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MuRILlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dii04iMeQkxn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qtwRK3wRgIfv",
        "tn3ZdEkqwFuf",
        "cRU1aKz253-Q",
        "hphD1uHEv9_0",
        "H1WjlCul53-f",
        "glhzaDgnxnKm",
        "f_6NB5_6wPbb",
        "6uGKlKfM53--",
        "2OmJBY9m53_D",
        "MHVI7E_AeeZZ",
        "JmMby0LwbYzf"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 5003737,
          "sourceId": 46764,
          "sourceType": "competition"
        },
        {
          "datasetId": 4083861,
          "sourceId": 7087776,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4083854,
          "sourceId": 7087747,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4139580,
          "sourceId": 7165977,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4139667,
          "sourceId": 7166086,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0478335ae8a24f9f98584bae10c1c71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10db4460729a4be88b95a2637808ec44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71d267ed74a4ee8b8751fdf6a2385c5",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0eedcb5960b4b77860f52fabb2ab4bf",
            "value": 125
          }
        },
        "116ec33856f943838db735673a397cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56e8dc1790ea4de0baff2c3f206509b3",
              "IPY_MODEL_eef1cb08bb634727b4179456d60f2492",
              "IPY_MODEL_dd7cc3c53b5b4acf8ff7fb5fd8b4eca8"
            ],
            "layout": "IPY_MODEL_6815b916de45414a9ccaf9ae8cddcac8"
          }
        },
        "11a826b8951a439b9647e5fb3a18ee92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c0e33d3f7e458b85a92b92216bf2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e9e3c2b61f64e699189fbb2bf14227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9348ffcc0f0442093898ff02d8db534",
            "max": 3162999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac806f30bffc4544a23eee41d65dc024",
            "value": 3162999
          }
        },
        "2f1865d8de7d43388354ba71ca33ad14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c0e33d3f7e458b85a92b92216bf2fe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_97319b171b754917b74a51a9a17d2367",
            "value": " 676/676 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "3770457988554617932e39a50baccbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4320ece9bf6b4c1ca74de04ccc1fd051": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43447fdffb9045589b6848258e223168": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da76e8ac6e342c1aec2db69a88f02b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f421b33540847b680e0dd9816bd6214": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fed0e6097964903ba615f73ff21b908": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529363f38ea047abb5da9d2c027b20d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da76e8ac6e342c1aec2db69a88f02b3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e0db7abffc04e68b2f01c07b491ec5f",
            "value": " 6.41M/6.41M [00:00&lt;00:00, 27.8MB/s]"
          }
        },
        "54aa3efd6226408ba169e5ab419ea756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdab9449ba294b87a0d23767f5d2292d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b088013315874353872057ccc593debf",
            "value": " 125/125 [00:00&lt;00:00, 5.87kB/s]"
          }
        },
        "55ccdafe9c3e4a56ba2376e5fc4a9bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e8dc1790ea4de0baff2c3f206509b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6e8f1f119a4ceea9ddbc059f5d1f1b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8cef74c448a4cb6be9e7d963e571c8c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "594598c1b6434e93bd349d8fa983265e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c409a1135d45e49a4bff6566adc8ed",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4320ece9bf6b4c1ca74de04ccc1fd051",
            "value": " 3.16M/3.16M [00:00&lt;00:00, 6.00MB/s]"
          }
        },
        "5dd74002727649f2a511b5e9b6a68de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fbad6a4354742e5aacd2c09b2fb5b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a826b8951a439b9647e5fb3a18ee92",
            "max": 585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3770457988554617932e39a50baccbb0",
            "value": 585
          }
        },
        "65de0f9f04034fb69bba8903a9196b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6815b916de45414a9ccaf9ae8cddcac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685c3194e18c480594a858e303e2496a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69032b54ce3148f0a66b3f11b83609bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ce057e2fe746d0abac55bce48cad31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5a36bb5742c449ea0dfc0ca454fd201",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "701fda7048694980a86ba82a6ef0fd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7030c955a87b499588498b197e72b5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7674c5fe51284b989bef685f9d6ab817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "792a5f6336444c0d8c963a8e720e82b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824f74239e53489aa6508e0b6a6d36ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_792a5f6336444c0d8c963a8e720e82b0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7674c5fe51284b989bef685f9d6ab817",
            "value": "tokenizer.json: 100%"
          }
        },
        "8cf56fc9bc854403a78d599c92656b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b50e98b24dc04c0fb659e798550c1394",
              "IPY_MODEL_2e9e3c2b61f64e699189fbb2bf14227d",
              "IPY_MODEL_594598c1b6434e93bd349d8fa983265e"
            ],
            "layout": "IPY_MODEL_c5a0410ddc8a4e899b21613f4d0a0fd8"
          }
        },
        "925380a76fec43b2a589aceeaf0da6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824f74239e53489aa6508e0b6a6d36ad",
              "IPY_MODEL_948cede7a372446db2889375f3bee7ac",
              "IPY_MODEL_529363f38ea047abb5da9d2c027b20d1"
            ],
            "layout": "IPY_MODEL_be675bc0ab3b4dfe8298fc708aed8e73"
          }
        },
        "938517513c8c4e14b52c511f2a0612f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c688388d68a64f5e8144501168fa5187",
              "IPY_MODEL_de2d126ecc2d4e0caede5ebbc72c4254",
              "IPY_MODEL_2f1865d8de7d43388354ba71ca33ad14"
            ],
            "layout": "IPY_MODEL_dd49ee5fc8ce402dad966a479349b56c"
          }
        },
        "948cede7a372446db2889375f3bee7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93ff724d1b44705a9c0c186b6772b65",
            "max": 6408635,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_701fda7048694980a86ba82a6ef0fd04",
            "value": 6408635
          }
        },
        "96c409a1135d45e49a4bff6566adc8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97319b171b754917b74a51a9a17d2367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e0db7abffc04e68b2f01c07b491ec5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18bea97121d4b1094032979e7590934": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a357f0cd7d164fb9a4b465731979d5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89eb303612744949a5722c082fea59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af8675b5b57247d58eb97e0917ee32be",
              "IPY_MODEL_10db4460729a4be88b95a2637808ec44",
              "IPY_MODEL_54aa3efd6226408ba169e5ab419ea756"
            ],
            "layout": "IPY_MODEL_685c3194e18c480594a858e303e2496a"
          }
        },
        "ac806f30bffc4544a23eee41d65dc024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad6e8f1f119a4ceea9ddbc059f5d1f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8675b5b57247d58eb97e0917ee32be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7be3b72ed6644cf8d89b0488b0f5c60",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_65de0f9f04034fb69bba8903a9196b31",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b088013315874353872057ccc593debf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b50e98b24dc04c0fb659e798550c1394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ccdafe9c3e4a56ba2376e5fc4a9bc0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0478335ae8a24f9f98584bae10c1c71f",
            "value": "vocab.txt: 100%"
          }
        },
        "b8cef74c448a4cb6be9e7d963e571c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc7a0c38b0264913bb1ceb376da22634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be675bc0ab3b4dfe8298fc708aed8e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be90e1c80a6744d38957f90c6e7573e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a357f0cd7d164fb9a4b465731979d5d2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d829bbcbeb6f45bcb721e3bb737bab2a",
            "value": " 585/585 [00:00&lt;00:00, 22.9kB/s]"
          }
        },
        "c5a0410ddc8a4e899b21613f4d0a0fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c680e69a02484c05b5ea6ae7ac7e7b86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c688388d68a64f5e8144501168fa5187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f421b33540847b680e0dd9816bd6214",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_43447fdffb9045589b6848258e223168",
            "value": "config.json: 100%"
          }
        },
        "c6ce057e2fe746d0abac55bce48cad31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd388af043634bdd9bbae8490d6a3e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdab9449ba294b87a0d23767f5d2292d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a36bb5742c449ea0dfc0ca454fd201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d71d267ed74a4ee8b8751fdf6a2385c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7be3b72ed6644cf8d89b0488b0f5c60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d829bbcbeb6f45bcb721e3bb737bab2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93ff724d1b44705a9c0c186b6772b65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9accd8a952343999af2a2a86abfff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69032b54ce3148f0a66b3f11b83609bf",
              "IPY_MODEL_5fbad6a4354742e5aacd2c09b2fb5b55",
              "IPY_MODEL_be90e1c80a6744d38957f90c6e7573e2"
            ],
            "layout": "IPY_MODEL_a18bea97121d4b1094032979e7590934"
          }
        },
        "dd49ee5fc8ce402dad966a479349b56c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7cc3c53b5b4acf8ff7fb5fd8b4eca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c680e69a02484c05b5ea6ae7ac7e7b86",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cd388af043634bdd9bbae8490d6a3e6a",
            "value": " 950M/950M [00:17&lt;00:00, 72.4MB/s]"
          }
        },
        "de2d126ecc2d4e0caede5ebbc72c4254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7030c955a87b499588498b197e72b5c8",
            "max": 676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7a0c38b0264913bb1ceb376da22634",
            "value": 676
          }
        },
        "e0eedcb5960b4b77860f52fabb2ab4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eef1cb08bb634727b4179456d60f2492": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fed0e6097964903ba615f73ff21b908",
            "max": 950293293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dd74002727649f2a511b5e9b6a68de3",
            "value": 950293293
          }
        },
        "f9348ffcc0f0442093898ff02d8db534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
